{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "AP_T01_Ej02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgermanob/DeepLearning/blob/master/T01/AP_T01_Ej02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEoK1VHVzZ_9"
      },
      "source": [
        "# 2. Retropropagación en red densa\n",
        "Programa el algoritmo de retropropagación usando NumPy para una tarea de clasificación binaria presuponiendo una red densa con dos capas ocultas y la función de pérdida de entropía cruzada\n",
        "binaria. Describe las fórmulas y reglas de actualización de los pesos y sesgos de cada capa y entrena\n",
        "y evalúa la red en algún conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ951iyRzaAC"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxjiJ2OezaAD"
      },
      "source": [
        "Se define una red densa con $x_1,\\dots x_n$ entradas, dos capas ocultas con $a$ neuronas cada una y una capa de salida con una neurona. Como funciones de activación es posible utilizar la función sigmoide o la función ReLU, las cuales se utilizan tanto en las capas ocultas como en la capa de salida. Para el ejemplo con el conjunto de datos de calificaciones se tienen 2 entradas y 5 neuronas en cada capa oculta.\n",
        "\n",
        "La función sigmoide se define como:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "La derivada de la función sigmoide se define como:\n",
        "$$\n",
        "\\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma(z) (1 - \\sigma(z))\n",
        "$$\n",
        "\n",
        "Por su parte, la función ReLU se define como:\n",
        "$$\n",
        "ReLU(z) = \\max\\{0,z\\}\n",
        "$$\n",
        "\n",
        "La derivada de la función ReLU se define como:\n",
        "$$\n",
        "\\frac{\\partial ReLU(z)}{\\partial z} = \\begin{cases} \n",
        "0 & \\text{if  }  x \\leq 0 \\\\\n",
        "1 & \\text{if  }  x > 0 \\\\\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Se utiliza la entropía cruzada binaria como función de pérdida, la cual se define como:\n",
        "$$\n",
        "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
        "$$\n",
        "\n",
        "La propagación hacia adeltante se realiza con la función _forward_pass(), \n",
        "Se tienen 2 capas ocultas y 1 de salida, por lo que se tiene 3 matrices de pesos con sus sesgos correspondientes $\\{\\mathbf{W}^{\\{1\\}}, \\mathbf{b}^{\\{1\\}}\\}$, $\\{\\mathbf{W}^{\\{2\\}}, \\mathbf{b}^{\\{2\\}}\\}$ y $\\{\\mathbf{W}^{\\{3\\}}, \\mathbf{b}^{\\{3\\}}\\}$ La propagación hacia adeltante se lleva a cabo de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\t\\begin{split}\n",
        "\t\t\t\t\\mathbf{a}^{\\{1\\}} & =  \\mathbf{x}^{(i)} \\\\\n",
        "\t\t\t\t\\mathbf{z}^{\\{2\\}} & =  \\mathbf{W}^{\\{1\\}} \\cdot \\mathbf{a}^{\\{1\\}} + \\mathbf{b}^{\\{1\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{2\\}} & =  F_a(\\mathbf{z}^{\\{2\\}}) \\\\\n",
        "\t\t\t\t\\mathbf{z}^{\\{3\\}} & =  \\mathbf{W}^{\\{2\\}} \\cdot \\mathbf{a}^{\\{2\\}}  + \\mathbf{b}^{\\{2\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{3\\}} & =  F_a(\\mathbf{z}^{\\{3\\}})\\\\\n",
        "\t\t\t\t\\mathbf{z}^{\\{4\\}} & =  \\mathbf{W}^{\\{3\\}} \\cdot \\mathbf{a}^{\\{3\\}}  + \\mathbf{b}^{\\{3\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{4\\}} & =  F_a(\\mathbf{z}^{\\{4\\}})\\\\\n",
        "\t\t\t\t\\hat{y}^{(i)} & =  \\mathbf{a}^{\\{4\\}}\\\\\n",
        "\t\t\t\\end{split}\n",
        "$$\n",
        "\n",
        "Donde $F_a$ representa a la función de activación, que para este caso serán la función sigmoide y la función ReLU.\n",
        "\n",
        "Para la etapa de retropropagación se tienen:\n",
        "\n",
        "$$dz^{\\{4\\}} = \\hat{y_i} - y_i$$\n",
        "$$dW^{\\{3\\}} = a^{\\{3\\}} \\otimes dz^{\\{4\\}} $$\n",
        "$$db^{\\{3\\}} = dz^{\\{4\\}} \\\\ $$\n",
        "\n",
        "\n",
        "$$dz^{\\{3\\}} = W^{\\{3\\}} \\cdot dz^{\\{4\\}}  dF_a( z^{\\{3\\}} )$$\n",
        "$$dW^{\\{2\\}} = a^{\\{2\\}} \\otimes dz^{\\{3\\}}$$\n",
        "$$db^{\\{2\\}} = dz^{\\{3\\}} \\\\ $$\n",
        "\n",
        "\n",
        "$$dz^{\\{2\\}} = W^{\\{2\\}} \\cdot dz^{\\{3\\}}  dF_a( z^{\\{2\\}} ) $$\n",
        "$$dW^{\\{1\\}} = x_i \\otimes dz^{\\{2\\}} $$\n",
        "$$db^{\\{1\\}} = dz^{\\{2\\}} \\\\ $$\n",
        "\n",
        "La actualización de los parámetros es:\n",
        "\n",
        "$$ W^{\\{3\\}} = W^{\\{3\\}} - \\alpha dW^{\\{3\\}}$$\n",
        "$$ b^{\\{3\\}} = b^{\\{3\\}} - \\alpha db^{\\{3\\}} \\\\ $$\n",
        "\n",
        "$$ W^{\\{2\\}} = W^{\\{2\\}} - \\alpha dW^{\\{2\\}}$$\n",
        "$$ b^{\\{2\\}} = b^{\\{2\\}} - \\alpha db^{\\{2\\}} \\\\ $$\n",
        "\n",
        "$$ W^{\\{1\\}} = W^{\\{1\\}} - \\alpha dW^{\\{1\\}}$$\n",
        "$$ b^{\\{1\\}} = b^{\\{1\\}} - \\alpha db^{\\{1\\}} \\\\ $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agoDQLsSzaAE"
      },
      "source": [
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_units, activation='relu'):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_units = hidden_units\n",
        "        if activation=='sigmoid':\n",
        "            self.activation = self._sigmoid\n",
        "            self.derivative = self._derivative_sigmoid\n",
        "        else:\n",
        "            self.activation = self._relu\n",
        "            self.derivative = self._derivative_relu          \n",
        "    \n",
        "    def _weighted_sum(self, w, a, b):\n",
        "        return np.dot(w.T, a) + b\n",
        "    \n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def _relu(self, z):\n",
        "        return np.maximum(0,z)\n",
        "    \n",
        "    def _derivative_relu(self, x):\n",
        "        return np.heaviside(x,0)\n",
        "    \n",
        "    def _derivative_sigmoid(self, x):\n",
        "        return np.multiply(self._sigmoid(x), (1.0 - self._sigmoid(x)))\n",
        "    \n",
        "    def _binary_crossEntropy(self, y, p):\n",
        "        p[p == 0] = np.nextafter(0., 1.)\n",
        "        p[p == 1] = np.nextafter(1., 0.)\n",
        "        return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())\n",
        "    \n",
        "    def _accuracy(self, y, y_predicted):\n",
        "        return (y == y_predicted).mean() * 100\n",
        "    \n",
        "    def _forward_pass(self, x, w1, b1, w2, b2, w3, b3):\n",
        "        a1 = x[:, np.newaxis]\n",
        "        z2 = self._weighted_sum(w1, a1, b1)\n",
        "        a2 = self.activation(z2)\n",
        "        z3 = self._weighted_sum(w2, a2, b2)\n",
        "        a3 = self.activation(z3)\n",
        "        z4 = self._weighted_sum(w3, a3, b3)\n",
        "        y_hat = self.activation(z4)\n",
        "        return z2, a2, z3, a3, z4, y_hat\n",
        "    \n",
        "    def _backpropagation(self, x, y, learning_rate, epochs):\n",
        "        # Capa oculta 1 #\n",
        "        self.w1 = np.sqrt(1.0 / self.input_dim) * np.random.randn(self.input_dim, self.hidden_units)\n",
        "        self.b1 = np.zeros((self.hidden_units, 1))\n",
        "        \n",
        "        # Capa oculta 2 #\n",
        "        self.w2 = np.sqrt(1.0 / self.hidden_units) * np.random.randn(self.hidden_units, self.hidden_units)\n",
        "        self.b2 = np.zeros((self.hidden_units, 1))\n",
        "        \n",
        "        # Capa de salida #\n",
        "        self.w3 = np.sqrt(1.0 / self.hidden_units) * np.random.randn(self.hidden_units, 1)\n",
        "        self.b3 = np.zeros((1, 1))\n",
        "        \n",
        "        losses = np.zeros((epochs))\n",
        "        accuracies = np.zeros((epochs))\n",
        "        y_predicted = np.zeros((y.shape))\n",
        "        \n",
        "        for i in range(epochs):\n",
        "            for j in range(x.shape[0]):\n",
        "                z2, a2, z3, a3, z4, y_hat = self._forward_pass(x[j], self.w1, self.b1, self.w2, self.b2, self.w3, self.b3)\n",
        "                # Gradientes para w3 y b3 por retropropagación #\n",
        "                dz4 = y_hat - y[j]\n",
        "                dw3 = np.outer(a3, dz4)\n",
        "                db3 = dz4\n",
        "                \n",
        "                # Gradiente para w2 y b2 por retropropagación #\n",
        "                dz3 = np.dot(self.w3, dz4) * self.derivative(z3)\n",
        "                dw2 = np.outer(a2, dz3)\n",
        "                db2 = dz3\n",
        "                \n",
        "                # Gradiente para w1 y b1 por retropropagación #\n",
        "                dz2 = np.dot(self.w2, dz3) * self.derivative(z2)\n",
        "                dw1 = np.outer(x[j], dz2)\n",
        "                db1 = dz2\n",
        "                \n",
        "                # Actualización de parámetros #\n",
        "                self.w3 = self.w3 - learning_rate * dw3\n",
        "                self.b3 = self.b3 - learning_rate * db3\n",
        "                \n",
        "                self.w2 = self.w2 - learning_rate * dw2\n",
        "                self.b2 = self.b2 - learning_rate * db2\n",
        "                \n",
        "                self.w1 = self.w1 - learning_rate * dw1\n",
        "                self.b1 = self.b1 - learning_rate * db1\n",
        "                \n",
        "                y_predicted[j] = y_hat\n",
        "            \n",
        "            losses[i] = self._binary_crossEntropy(y, y_predicted)\n",
        "            accuracies[i] = self._accuracy(y, np.round(y_predicted))\n",
        "            print('Epoch {}: \\tLoss = {} \\tAccuracy = {}'.format(i, losses[i], accuracies[i]))\n",
        "        return losses, accuracies\n",
        "        \n",
        "    def fit(self, x, y, learning_rate=0.01, epochs=200):\n",
        "        loss, acc = self._backpropagation(x, y, learning_rate, epochs)\n",
        "        return loss, acc\n",
        "    \n",
        "    def predict(self, x):\n",
        "        y_pred = []\n",
        "        for i in range(x.shape[0]):\n",
        "            _, _, _, _, _, y_hat = self._forward_pass(x[i], self.w1, self.b1, \n",
        "                                                           self.w2, self.b2, \n",
        "                                                           self.w3, self.b3)\n",
        "            y_pred.append(np.round(y_hat[0]))\n",
        "        return np.array(y_pred)\n",
        "        \n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1E01dUuzaAF"
      },
      "source": [
        "def plot_loss_and_accuracy(loss, accuracy):\n",
        "    plt.plot(np.arange(loss.size), loss, label='Binary cross entropy')\n",
        "    plt.plot(np.arange(accuracy.size), accuracy, label='Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "New1VtGXzaAG"
      },
      "source": [
        "## Prueba en conjunto de datos de calificaciones\n",
        "Para utilizar el conjunto de datos de calificaciones para resolver un problema de clasificación binaria, se agregó una nueva columna *PASS*, la cual indica si un estudiante aprobó el curso o no. Para determinar el valor de cada instancia se toma el valor de la columna *CALIF*, si tiene un valor mayor a 7.0, entonces el alumno aprobó el curso, en caso contrario el alumno no aprobó."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Es9kxIKzaAG"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/gibranfp/CursoAprendizajeProfundo/2022-1/data/califs.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJR9ZI30zaAH"
      },
      "source": [
        "df = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxo5d0XVzaAI"
      },
      "source": [
        "pass_ = []\n",
        "for calif in df['calif']:\n",
        "    if calif > 7.0:\n",
        "        pass_.append(1)\n",
        "    else:\n",
        "        pass_.append(0)\n",
        "df['pass'] = pass_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8nZe2UbzaAI"
      },
      "source": [
        "X = df[['prev', 'horas']].to_numpy()\n",
        "y = df['pass'].to_numpy().reshape(50,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW1itsODzaAJ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31Si-x1DzaAJ"
      },
      "source": [
        "### Red densa con función de activación Sigmoide "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3euRX1zaAJ"
      },
      "source": [
        "mlp = MLP(input_dim=X.shape[1], hidden_units=5, activation='sigmoid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt3kFfS9zaAJ",
        "outputId": "a5ed270e-7719-480e-9c3f-19a9f85a0c32"
      },
      "source": [
        "np.random.seed(0)\n",
        "loss, acc = mlp.fit(X_train, y_train, learning_rate=0.001, epochs=400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: \tLoss = 26.20191236756616 \tAccuracy = 54.054054054054056\n",
            "Epoch 1: \tLoss = 26.169308231508516 \tAccuracy = 54.054054054054056\n",
            "Epoch 2: \tLoss = 26.138306682134818 \tAccuracy = 54.054054054054056\n",
            "Epoch 3: \tLoss = 26.108830447465426 \tAccuracy = 54.054054054054056\n",
            "Epoch 4: \tLoss = 26.080805816136692 \tAccuracy = 54.054054054054056\n",
            "Epoch 5: \tLoss = 26.054162490067526 \tAccuracy = 54.054054054054056\n",
            "Epoch 6: \tLoss = 26.028833441492708 \tAccuracy = 54.054054054054056\n",
            "Epoch 7: \tLoss = 26.004754774426594 \tAccuracy = 54.054054054054056\n",
            "Epoch 8: \tLoss = 25.98186559059245 \tAccuracy = 54.054054054054056\n",
            "Epoch 9: \tLoss = 25.960107859827993 \tAccuracy = 54.054054054054056\n",
            "Epoch 10: \tLoss = 25.93942629495602 \tAccuracy = 54.054054054054056\n",
            "Epoch 11: \tLoss = 25.91976823109019 \tAccuracy = 54.054054054054056\n",
            "Epoch 12: \tLoss = 25.90108350932973 \tAccuracy = 54.054054054054056\n",
            "Epoch 13: \tLoss = 25.8833243647831 \tAccuracy = 54.054054054054056\n",
            "Epoch 14: \tLoss = 25.866445318848434 \tAccuracy = 54.054054054054056\n",
            "Epoch 15: \tLoss = 25.850403075669135 \tAccuracy = 54.054054054054056\n",
            "Epoch 16: \tLoss = 25.835156422674395 \tAccuracy = 54.054054054054056\n",
            "Epoch 17: \tLoss = 25.820666135107814 \tAccuracy = 54.054054054054056\n",
            "Epoch 18: \tLoss = 25.80689488444193 \tAccuracy = 54.054054054054056\n",
            "Epoch 19: \tLoss = 25.79380715057225 \tAccuracy = 54.054054054054056\n",
            "Epoch 20: \tLoss = 25.78136913768123 \tAccuracy = 54.054054054054056\n",
            "Epoch 21: \tLoss = 25.769548693660635 \tAccuracy = 54.054054054054056\n",
            "Epoch 22: \tLoss = 25.75831523297896 \tAccuracy = 54.054054054054056\n",
            "Epoch 23: \tLoss = 25.747639662880417 \tAccuracy = 54.054054054054056\n",
            "Epoch 24: \tLoss = 25.73749431280166 \tAccuracy = 54.054054054054056\n",
            "Epoch 25: \tLoss = 25.727852866892945 \tAccuracy = 54.054054054054056\n",
            "Epoch 26: \tLoss = 25.71869029953161 \tAccuracy = 54.054054054054056\n",
            "Epoch 27: \tLoss = 25.709982813716824 \tAccuracy = 54.054054054054056\n",
            "Epoch 28: \tLoss = 25.701707782236653 \tAccuracy = 54.054054054054056\n",
            "Epoch 29: \tLoss = 25.693843691500078 \tAccuracy = 54.054054054054056\n",
            "Epoch 30: \tLoss = 25.68637008792917 \tAccuracy = 54.054054054054056\n",
            "Epoch 31: \tLoss = 25.679267526808843 \tAccuracy = 54.054054054054056\n",
            "Epoch 32: \tLoss = 25.67251752349429 \tAccuracy = 54.054054054054056\n",
            "Epoch 33: \tLoss = 25.66610250687882 \tAccuracy = 54.054054054054056\n",
            "Epoch 34: \tLoss = 25.660005775027713 \tAccuracy = 54.054054054054056\n",
            "Epoch 35: \tLoss = 25.6542114528864 \tAccuracy = 54.054054054054056\n",
            "Epoch 36: \tLoss = 25.648704451974375 \tAccuracy = 54.054054054054056\n",
            "Epoch 37: \tLoss = 25.643470431978926 \tAccuracy = 54.054054054054056\n",
            "Epoch 38: \tLoss = 25.638495764165903 \tAccuracy = 54.054054054054056\n",
            "Epoch 39: \tLoss = 25.633767496527568 \tAccuracy = 54.054054054054056\n",
            "Epoch 40: \tLoss = 25.629273320590343 \tAccuracy = 54.054054054054056\n",
            "Epoch 41: \tLoss = 25.625001539808334 \tAccuracy = 54.054054054054056\n",
            "Epoch 42: \tLoss = 25.62094103947122 \tAccuracy = 54.054054054054056\n",
            "Epoch 43: \tLoss = 25.61708125805781 \tAccuracy = 54.054054054054056\n",
            "Epoch 44: \tLoss = 25.61341215996932 \tAccuracy = 54.054054054054056\n",
            "Epoch 45: \tLoss = 25.60992420957912 \tAccuracy = 54.054054054054056\n",
            "Epoch 46: \tLoss = 25.606608346538188 \tAccuracy = 54.054054054054056\n",
            "Epoch 47: \tLoss = 25.603455962277994 \tAccuracy = 54.054054054054056\n",
            "Epoch 48: \tLoss = 25.600458877655182 \tAccuracy = 54.054054054054056\n",
            "Epoch 49: \tLoss = 25.59760932168447 \tAccuracy = 54.054054054054056\n",
            "Epoch 50: \tLoss = 25.59489991130866 \tAccuracy = 54.054054054054056\n",
            "Epoch 51: \tLoss = 25.592323632156976 \tAccuracy = 54.054054054054056\n",
            "Epoch 52: \tLoss = 25.589873820244694 \tAccuracy = 54.054054054054056\n",
            "Epoch 53: \tLoss = 25.58754414456958 \tAccuracy = 54.054054054054056\n",
            "Epoch 54: \tLoss = 25.585328590562234 \tAccuracy = 54.054054054054056\n",
            "Epoch 55: \tLoss = 25.583221444349586 \tAccuracy = 54.054054054054056\n",
            "Epoch 56: \tLoss = 25.581217277792565 \tAccuracy = 54.054054054054056\n",
            "Epoch 57: \tLoss = 25.57931093426064 \tAccuracy = 54.054054054054056\n",
            "Epoch 58: \tLoss = 25.57749751510786 \tAccuracy = 54.054054054054056\n",
            "Epoch 59: \tLoss = 25.575772366816373 \tAccuracy = 54.054054054054056\n",
            "Epoch 60: \tLoss = 25.574131068775174 \tAccuracy = 54.054054054054056\n",
            "Epoch 61: \tLoss = 25.57256942166323 \tAccuracy = 54.054054054054056\n",
            "Epoch 62: \tLoss = 25.571083436407662 \tAccuracy = 54.054054054054056\n",
            "Epoch 63: \tLoss = 25.569669323688885 \tAccuracy = 54.054054054054056\n",
            "Epoch 64: \tLoss = 25.56832348396606 \tAccuracy = 54.054054054054056\n",
            "Epoch 65: \tLoss = 25.567042497997495 \tAccuracy = 54.054054054054056\n",
            "Epoch 66: \tLoss = 25.5658231178316 \tAccuracy = 54.054054054054056\n",
            "Epoch 67: \tLoss = 25.564662258245555 \tAccuracy = 54.054054054054056\n",
            "Epoch 68: \tLoss = 25.563556988609506 \tAccuracy = 54.054054054054056\n",
            "Epoch 69: \tLoss = 25.562504525155475 \tAccuracy = 54.054054054054056\n",
            "Epoch 70: \tLoss = 25.561502223631102 \tAccuracy = 54.054054054054056\n",
            "Epoch 71: \tLoss = 25.560547572319116 \tAccuracy = 54.054054054054056\n",
            "Epoch 72: \tLoss = 25.559638185404715 \tAccuracy = 54.054054054054056\n",
            "Epoch 73: \tLoss = 25.558771796673412 \tAccuracy = 54.054054054054056\n",
            "Epoch 74: \tLoss = 25.55794625352324 \tAccuracy = 54.054054054054056\n",
            "Epoch 75: \tLoss = 25.55715951127567 \tAccuracy = 54.054054054054056\n",
            "Epoch 76: \tLoss = 25.556409627770414 \tAccuracy = 54.054054054054056\n",
            "Epoch 77: \tLoss = 25.555694758230125 \tAccuracy = 54.054054054054056\n",
            "Epoch 78: \tLoss = 25.55501315038158 \tAccuracy = 54.054054054054056\n",
            "Epoch 79: \tLoss = 25.554363139820573 \tAccuracy = 54.054054054054056\n",
            "Epoch 80: \tLoss = 25.55374314560852 \tAccuracy = 54.054054054054056\n",
            "Epoch 81: \tLoss = 25.55315166608911 \tAccuracy = 54.054054054054056\n",
            "Epoch 82: \tLoss = 25.552587274914224 \tAccuracy = 54.054054054054056\n",
            "Epoch 83: \tLoss = 25.55204861726858 \tAccuracy = 54.054054054054056\n",
            "Epoch 84: \tLoss = 25.551534406283295 \tAccuracy = 54.054054054054056\n",
            "Epoch 85: \tLoss = 25.551043419628897 \tAccuracy = 54.054054054054056\n",
            "Epoch 86: \tLoss = 25.550574496278912 \tAccuracy = 54.054054054054056\n",
            "Epoch 87: \tLoss = 25.550126533435417 \tAccuracy = 54.054054054054056\n",
            "Epoch 88: \tLoss = 25.54969848360861 \tAccuracy = 54.054054054054056\n",
            "Epoch 89: \tLoss = 25.549289351842603 \tAccuracy = 54.054054054054056\n",
            "Epoch 90: \tLoss = 25.548898193080205 \tAccuracy = 54.054054054054056\n",
            "Epoch 91: \tLoss = 25.548524109659727 \tAccuracy = 54.054054054054056\n",
            "Epoch 92: \tLoss = 25.54816624893723 \tAccuracy = 54.054054054054056\n",
            "Epoch 93: \tLoss = 25.54782380102791 \tAccuracy = 54.054054054054056\n",
            "Epoch 94: \tLoss = 25.54749599666072 \tAccuracy = 54.054054054054056\n",
            "Epoch 95: \tLoss = 25.547182105140564 \tAccuracy = 54.054054054054056\n",
            "Epoch 96: \tLoss = 25.546881432412583 \tAccuracy = 54.054054054054056\n",
            "Epoch 97: \tLoss = 25.546593319223575 \tAccuracy = 54.054054054054056\n",
            "Epoch 98: \tLoss = 25.546317139375596 \tAccuracy = 54.054054054054056\n",
            "Epoch 99: \tLoss = 25.546052298067146 \tAccuracy = 54.054054054054056\n",
            "Epoch 100: \tLoss = 25.54579823031755 \tAccuracy = 54.054054054054056\n",
            "Epoch 101: \tLoss = 25.545554399470383 \tAccuracy = 54.054054054054056\n",
            "Epoch 102: \tLoss = 25.545320295772008 \tAccuracy = 54.054054054054056\n",
            "Epoch 103: \tLoss = 25.54509543502135 \tAccuracy = 54.054054054054056\n",
            "Epoch 104: \tLoss = 25.54487935728752 \tAccuracy = 54.054054054054056\n",
            "Epoch 105: \tLoss = 25.54467162569172 \tAccuracy = 54.054054054054056\n",
            "Epoch 106: \tLoss = 25.544471825250266 \tAccuracy = 54.054054054054056\n",
            "Epoch 107: \tLoss = 25.544279561775763 \tAccuracy = 54.054054054054056\n",
            "Epoch 108: \tLoss = 25.544094460833314 \tAccuracy = 54.054054054054056\n",
            "Epoch 109: \tLoss = 25.5439161667492 \tAccuracy = 54.054054054054056\n",
            "Epoch 110: \tLoss = 25.543744341669267 \tAccuracy = 54.054054054054056\n",
            "Epoch 111: \tLoss = 25.543578664664658 \tAccuracy = 54.054054054054056\n",
            "Epoch 112: \tLoss = 25.543418830882324 \tAccuracy = 54.054054054054056\n",
            "Epoch 113: \tLoss = 25.543264550738265 \tAccuracy = 54.054054054054056\n",
            "Epoch 114: \tLoss = 25.543115549151253 \tAccuracy = 54.054054054054056\n",
            "Epoch 115: \tLoss = 25.542971564815012 \tAccuracy = 54.054054054054056\n",
            "Epoch 116: \tLoss = 25.54283234950696 \tAccuracy = 54.054054054054056\n",
            "Epoch 117: \tLoss = 25.542697667431604 \tAccuracy = 54.054054054054056\n",
            "Epoch 118: \tLoss = 25.542567294597013 \tAccuracy = 54.054054054054056\n",
            "Epoch 119: \tLoss = 25.542441018222476 \tAccuracy = 54.054054054054056\n",
            "Epoch 120: \tLoss = 25.54231863617597 \tAccuracy = 54.054054054054056\n",
            "Epoch 121: \tLoss = 25.542199956439873 \tAccuracy = 54.054054054054056\n",
            "Epoch 122: \tLoss = 25.542084796603493 \tAccuracy = 54.054054054054056\n",
            "Epoch 123: \tLoss = 25.541972983381065 \tAccuracy = 54.054054054054056\n",
            "Epoch 124: \tLoss = 25.54186435215397 \tAccuracy = 54.054054054054056\n",
            "Epoch 125: \tLoss = 25.54175874653597 \tAccuracy = 54.054054054054056\n",
            "Epoch 126: \tLoss = 25.54165601796019 \tAccuracy = 54.054054054054056\n",
            "Epoch 127: \tLoss = 25.54155602528696 \tAccuracy = 54.054054054054056\n",
            "Epoch 128: \tLoss = 25.54145863443121 \tAccuracy = 54.054054054054056\n",
            "Epoch 129: \tLoss = 25.541363718008718 \tAccuracy = 54.054054054054056\n",
            "Epoch 130: \tLoss = 25.541271155000025 \tAccuracy = 54.054054054054056\n",
            "Epoch 131: \tLoss = 25.54118083043125 \tAccuracy = 54.054054054054056\n",
            "Epoch 132: \tLoss = 25.541092635070946 \tAccuracy = 54.054054054054056\n",
            "Epoch 133: \tLoss = 25.541006465142182 \tAccuracy = 54.054054054054056\n",
            "Epoch 134: \tLoss = 25.540922222049062 \tAccuracy = 54.054054054054056\n",
            "Epoch 135: \tLoss = 25.540839812116992 \tAccuracy = 54.054054054054056\n",
            "Epoch 136: \tLoss = 25.540759146345998 \tAccuracy = 54.054054054054056\n",
            "Epoch 137: \tLoss = 25.540680140176384 \tAccuracy = 54.054054054054056\n",
            "Epoch 138: \tLoss = 25.540602713266253 \tAccuracy = 54.054054054054056\n",
            "Epoch 139: \tLoss = 25.540526789280065 \tAccuracy = 54.054054054054056\n",
            "Epoch 140: \tLoss = 25.540452295687928 \tAccuracy = 54.054054054054056\n",
            "Epoch 141: \tLoss = 25.540379163574926 \tAccuracy = 54.054054054054056\n",
            "Epoch 142: \tLoss = 25.540307327459985 \tAccuracy = 54.054054054054056\n",
            "Epoch 143: \tLoss = 25.5402367251239 \tAccuracy = 54.054054054054056\n",
            "Epoch 144: \tLoss = 25.540167297445954 \tAccuracy = 54.054054054054056\n",
            "Epoch 145: \tLoss = 25.540098988248715 \tAccuracy = 54.054054054054056\n",
            "Epoch 146: \tLoss = 25.5400317441507 \tAccuracy = 54.054054054054056\n",
            "Epoch 147: \tLoss = 25.53996551442636 \tAccuracy = 54.054054054054056\n",
            "Epoch 148: \tLoss = 25.539900250873153 \tAccuracy = 54.054054054054056\n",
            "Epoch 149: \tLoss = 25.53983590768523 \tAccuracy = 54.054054054054056\n",
            "Epoch 150: \tLoss = 25.539772441333515 \tAccuracy = 54.054054054054056\n",
            "Epoch 151: \tLoss = 25.539709810451775 \tAccuracy = 54.054054054054056\n",
            "Epoch 152: \tLoss = 25.539647975728407 \tAccuracy = 54.054054054054056\n",
            "Epoch 153: \tLoss = 25.539586899803698 \tAccuracy = 54.054054054054056\n",
            "Epoch 154: \tLoss = 25.539526547172144 \tAccuracy = 54.054054054054056\n",
            "Epoch 155: \tLoss = 25.53946688408979 \tAccuracy = 54.054054054054056\n",
            "Epoch 156: \tLoss = 25.539407878486145 \tAccuracy = 54.054054054054056\n",
            "Epoch 157: \tLoss = 25.539349499880522 \tAccuracy = 54.054054054054056\n",
            "Epoch 158: \tLoss = 25.53929171930261 \tAccuracy = 54.054054054054056\n",
            "Epoch 159: \tLoss = 25.539234509216982 \tAccuracy = 54.054054054054056\n",
            "Epoch 160: \tLoss = 25.53917784345145 \tAccuracy = 54.054054054054056\n",
            "Epoch 161: \tLoss = 25.539121697128945 \tAccuracy = 54.054054054054056\n",
            "Epoch 162: \tLoss = 25.53906604660288 \tAccuracy = 54.054054054054056\n",
            "Epoch 163: \tLoss = 25.539010869395707 \tAccuracy = 54.054054054054056\n",
            "Epoch 164: \tLoss = 25.538956144140577 \tAccuracy = 54.054054054054056\n",
            "Epoch 165: \tLoss = 25.538901850525924 \tAccuracy = 54.054054054054056\n",
            "Epoch 166: \tLoss = 25.53884796924281 \tAccuracy = 54.054054054054056\n",
            "Epoch 167: \tLoss = 25.538794481934957 \tAccuracy = 54.054054054054056\n",
            "Epoch 168: \tLoss = 25.538741371151218 \tAccuracy = 54.054054054054056\n",
            "Epoch 169: \tLoss = 25.538688620300476 \tAccuracy = 54.054054054054056\n",
            "Epoch 170: \tLoss = 25.538636213608797 \tAccuracy = 54.054054054054056\n",
            "Epoch 171: \tLoss = 25.53858413607872 \tAccuracy = 54.054054054054056\n",
            "Epoch 172: \tLoss = 25.538532373450586 \tAccuracy = 54.054054054054056\n",
            "Epoch 173: \tLoss = 25.538480912165817 \tAccuracy = 54.054054054054056\n",
            "Epoch 174: \tLoss = 25.538429739332045 \tAccuracy = 54.054054054054056\n",
            "Epoch 175: \tLoss = 25.53837884268993 \tAccuracy = 54.054054054054056\n",
            "Epoch 176: \tLoss = 25.538328210581717 \tAccuracy = 54.054054054054056\n",
            "Epoch 177: \tLoss = 25.53827783192131 \tAccuracy = 54.054054054054056\n",
            "Epoch 178: \tLoss = 25.53822769616588 \tAccuracy = 54.054054054054056\n",
            "Epoch 179: \tLoss = 25.53817779328887 \tAccuracy = 54.054054054054056\n",
            "Epoch 180: \tLoss = 25.538128113754368 \tAccuracy = 54.054054054054056\n",
            "Epoch 181: \tLoss = 25.538078648492753 \tAccuracy = 54.054054054054056\n",
            "Epoch 182: \tLoss = 25.53802938887756 \tAccuracy = 54.054054054054056\n",
            "Epoch 183: \tLoss = 25.537980326703515 \tAccuracy = 54.054054054054056\n",
            "Epoch 184: \tLoss = 25.537931454165637 \tAccuracy = 54.054054054054056\n",
            "Epoch 185: \tLoss = 25.53788276383945 \tAccuracy = 54.054054054054056\n",
            "Epoch 186: \tLoss = 25.53783424866208 \tAccuracy = 54.054054054054056\n",
            "Epoch 187: \tLoss = 25.537785901914425 \tAccuracy = 54.054054054054056\n",
            "Epoch 188: \tLoss = 25.537737717204095 \tAccuracy = 54.054054054054056\n",
            "Epoch 189: \tLoss = 25.53768968844931 \tAccuracy = 54.054054054054056\n",
            "Epoch 190: \tLoss = 25.53764180986349 \tAccuracy = 54.054054054054056\n",
            "Epoch 191: \tLoss = 25.537594075940753 \tAccuracy = 54.054054054054056\n",
            "Epoch 192: \tLoss = 25.537546481441986 \tAccuracy = 54.054054054054056\n",
            "Epoch 193: \tLoss = 25.537499021381755 \tAccuracy = 54.054054054054056\n",
            "Epoch 194: \tLoss = 25.537451691015743 \tAccuracy = 54.054054054054056\n",
            "Epoch 195: \tLoss = 25.53740448582891 \tAccuracy = 54.054054054054056\n",
            "Epoch 196: \tLoss = 25.537357401524204 \tAccuracy = 54.054054054054056\n",
            "Epoch 197: \tLoss = 25.537310434011808 \tAccuracy = 54.054054054054056\n",
            "Epoch 198: \tLoss = 25.537263579398992 \tAccuracy = 54.054054054054056\n",
            "Epoch 199: \tLoss = 25.537216833980402 \tAccuracy = 54.054054054054056\n",
            "Epoch 200: \tLoss = 25.537170194228878 \tAccuracy = 54.054054054054056\n",
            "Epoch 201: \tLoss = 25.537123656786715 \tAccuracy = 54.054054054054056\n",
            "Epoch 202: \tLoss = 25.537077218457352 \tAccuracy = 54.054054054054056\n",
            "Epoch 203: \tLoss = 25.53703087619748 \tAccuracy = 54.054054054054056\n",
            "Epoch 204: \tLoss = 25.536984627109554 \tAccuracy = 54.054054054054056\n",
            "Epoch 205: \tLoss = 25.536938468434666 \tAccuracy = 54.054054054054056\n",
            "Epoch 206: \tLoss = 25.53689239754577 \tAccuracy = 54.054054054054056\n",
            "Epoch 207: \tLoss = 25.536846411941248 \tAccuracy = 54.054054054054056\n",
            "Epoch 208: \tLoss = 25.53680050923881 \tAccuracy = 54.054054054054056\n",
            "Epoch 209: \tLoss = 25.53675468716966 \tAccuracy = 54.054054054054056\n",
            "Epoch 210: \tLoss = 25.536708943573004 \tAccuracy = 54.054054054054056\n",
            "Epoch 211: \tLoss = 25.536663276390787 \tAccuracy = 54.054054054054056\n",
            "Epoch 212: \tLoss = 25.536617683662698 \tAccuracy = 54.054054054054056\n",
            "Epoch 213: \tLoss = 25.53657216352146 \tAccuracy = 54.054054054054056\n",
            "Epoch 214: \tLoss = 25.536526714188287 \tAccuracy = 54.054054054054056\n",
            "Epoch 215: \tLoss = 25.536481333968645 \tAccuracy = 54.054054054054056\n",
            "Epoch 216: \tLoss = 25.536436021248157 \tAccuracy = 54.054054054054056\n",
            "Epoch 217: \tLoss = 25.53639077448873 \tAccuracy = 54.054054054054056\n",
            "Epoch 218: \tLoss = 25.536345592224908 \tAccuracy = 54.054054054054056\n",
            "Epoch 219: \tLoss = 25.536300473060365 \tAccuracy = 54.054054054054056\n",
            "Epoch 220: \tLoss = 25.53625541566457 \tAccuracy = 54.054054054054056\n",
            "Epoch 221: \tLoss = 25.53621041876966 \tAccuracy = 54.054054054054056\n",
            "Epoch 222: \tLoss = 25.536165481167394 \tAccuracy = 54.054054054054056\n",
            "Epoch 223: \tLoss = 25.536120601706354 \tAccuracy = 54.054054054054056\n",
            "Epoch 224: \tLoss = 25.53607577928921 \tAccuracy = 54.054054054054056\n",
            "Epoch 225: \tLoss = 25.53603101287011 \tAccuracy = 54.054054054054056\n",
            "Epoch 226: \tLoss = 25.53598630145231 \tAccuracy = 54.054054054054056\n",
            "Epoch 227: \tLoss = 25.535941644085753 \tAccuracy = 54.054054054054056\n",
            "Epoch 228: \tLoss = 25.535897039864906 \tAccuracy = 54.054054054054056\n",
            "Epoch 229: \tLoss = 25.535852487926643 \tAccuracy = 54.054054054054056\n",
            "Epoch 230: \tLoss = 25.535807987448248 \tAccuracy = 54.054054054054056\n",
            "Epoch 231: \tLoss = 25.535763537645494 \tAccuracy = 54.054054054054056\n",
            "Epoch 232: \tLoss = 25.53571913777086 \tAccuracy = 54.054054054054056\n",
            "Epoch 233: \tLoss = 25.535674787111773 \tAccuracy = 54.054054054054056\n",
            "Epoch 234: \tLoss = 25.535630484988992 \tAccuracy = 54.054054054054056\n",
            "Epoch 235: \tLoss = 25.535586230755065 \tAccuracy = 54.054054054054056\n",
            "Epoch 236: \tLoss = 25.53554202379281 \tAccuracy = 54.054054054054056\n",
            "Epoch 237: \tLoss = 25.53549786351394 \tAccuracy = 54.054054054054056\n",
            "Epoch 238: \tLoss = 25.535453749357707 \tAccuracy = 54.054054054054056\n",
            "Epoch 239: \tLoss = 25.53540968078963 \tAccuracy = 54.054054054054056\n",
            "Epoch 240: \tLoss = 25.53536565730029 \tAccuracy = 54.054054054054056\n",
            "Epoch 241: \tLoss = 25.535321678404166 \tAccuracy = 54.054054054054056\n",
            "Epoch 242: \tLoss = 25.535277743638538 \tAccuracy = 54.054054054054056\n",
            "Epoch 243: \tLoss = 25.535233852562467 \tAccuracy = 54.054054054054056\n",
            "Epoch 244: \tLoss = 25.535190004755762 \tAccuracy = 54.054054054054056\n",
            "Epoch 245: \tLoss = 25.535146199818072 \tAccuracy = 54.054054054054056\n",
            "Epoch 246: \tLoss = 25.53510243736796 \tAccuracy = 54.054054054054056\n",
            "Epoch 247: \tLoss = 25.53505871704208 \tAccuracy = 54.054054054054056\n",
            "Epoch 248: \tLoss = 25.535015038494315 \tAccuracy = 54.054054054054056\n",
            "Epoch 249: \tLoss = 25.534971401395055 \tAccuracy = 54.054054054054056\n",
            "Epoch 250: \tLoss = 25.53492780543042 \tAccuracy = 54.054054054054056\n",
            "Epoch 251: \tLoss = 25.534884250301577 \tAccuracy = 54.054054054054056\n",
            "Epoch 252: \tLoss = 25.53484073572408 \tAccuracy = 54.054054054054056\n",
            "Epoch 253: \tLoss = 25.5347972614272 \tAccuracy = 54.054054054054056\n",
            "Epoch 254: \tLoss = 25.534753827153367 \tAccuracy = 54.054054054054056\n",
            "Epoch 255: \tLoss = 25.534710432657555 \tAccuracy = 54.054054054054056\n",
            "Epoch 256: \tLoss = 25.534667077706743 \tAccuracy = 54.054054054054056\n",
            "Epoch 257: \tLoss = 25.534623762079413 \tAccuracy = 54.054054054054056\n",
            "Epoch 258: \tLoss = 25.534580485565016 \tAccuracy = 54.054054054054056\n",
            "Epoch 259: \tLoss = 25.53453724796355 \tAccuracy = 54.054054054054056\n",
            "Epoch 260: \tLoss = 25.534494049085044 \tAccuracy = 54.054054054054056\n",
            "Epoch 261: \tLoss = 25.534450888749188 \tAccuracy = 54.054054054054056\n",
            "Epoch 262: \tLoss = 25.534407766784874 \tAccuracy = 54.054054054054056\n",
            "Epoch 263: \tLoss = 25.534364683029857 \tAccuracy = 54.054054054054056\n",
            "Epoch 264: \tLoss = 25.534321637330322 \tAccuracy = 54.054054054054056\n",
            "Epoch 265: \tLoss = 25.53427862954059 \tAccuracy = 54.054054054054056\n",
            "Epoch 266: \tLoss = 25.534235659522757 \tAccuracy = 54.054054054054056\n",
            "Epoch 267: \tLoss = 25.53419272714634 \tAccuracy = 54.054054054054056\n",
            "Epoch 268: \tLoss = 25.534149832288033 \tAccuracy = 54.054054054054056\n",
            "Epoch 269: \tLoss = 25.534106974831364 \tAccuracy = 54.054054054054056\n",
            "Epoch 270: \tLoss = 25.53406415466644 \tAccuracy = 54.054054054054056\n",
            "Epoch 271: \tLoss = 25.53402137168966 \tAccuracy = 54.054054054054056\n",
            "Epoch 272: \tLoss = 25.53397862580351 \tAccuracy = 54.054054054054056\n",
            "Epoch 273: \tLoss = 25.53393591691626 \tAccuracy = 54.054054054054056\n",
            "Epoch 274: \tLoss = 25.53389324494177 \tAccuracy = 54.054054054054056\n",
            "Epoch 275: \tLoss = 25.533850609799263 \tAccuracy = 54.054054054054056\n",
            "Epoch 276: \tLoss = 25.533808011413125 \tAccuracy = 54.054054054054056\n",
            "Epoch 277: \tLoss = 25.533765449712675 \tAccuracy = 54.054054054054056\n",
            "Epoch 278: \tLoss = 25.533722924632016 \tAccuracy = 54.054054054054056\n",
            "Epoch 279: \tLoss = 25.53368043610981 \tAccuracy = 54.054054054054056\n",
            "Epoch 280: \tLoss = 25.533637984089133 \tAccuracy = 54.054054054054056\n",
            "Epoch 281: \tLoss = 25.533595568517306 \tAccuracy = 54.054054054054056\n",
            "Epoch 282: \tLoss = 25.533553189345724 \tAccuracy = 54.054054054054056\n",
            "Epoch 283: \tLoss = 25.5335108465297 \tAccuracy = 54.054054054054056\n",
            "Epoch 284: \tLoss = 25.533468540028363 \tAccuracy = 54.054054054054056\n",
            "Epoch 285: \tLoss = 25.53342626980445 \tAccuracy = 54.054054054054056\n",
            "Epoch 286: \tLoss = 25.53338403582424 \tAccuracy = 54.054054054054056\n",
            "Epoch 287: \tLoss = 25.533341838057385 \tAccuracy = 54.054054054054056\n",
            "Epoch 288: \tLoss = 25.533299676476815 \tAccuracy = 54.054054054054056\n",
            "Epoch 289: \tLoss = 25.53325755105859 \tAccuracy = 54.054054054054056\n",
            "Epoch 290: \tLoss = 25.533215461781836 \tAccuracy = 54.054054054054056\n",
            "Epoch 291: \tLoss = 25.533173408628603 \tAccuracy = 54.054054054054056\n",
            "Epoch 292: \tLoss = 25.533131391583765 \tAccuracy = 54.054054054054056\n",
            "Epoch 293: \tLoss = 25.533089410634958 \tAccuracy = 54.054054054054056\n",
            "Epoch 294: \tLoss = 25.533047465772437 \tAccuracy = 54.054054054054056\n",
            "Epoch 295: \tLoss = 25.53300555698902 \tAccuracy = 54.054054054054056\n",
            "Epoch 296: \tLoss = 25.532963684280013 \tAccuracy = 54.054054054054056\n",
            "Epoch 297: \tLoss = 25.53292184764309 \tAccuracy = 54.054054054054056\n",
            "Epoch 298: \tLoss = 25.53288004707825 \tAccuracy = 54.054054054054056\n",
            "Epoch 299: \tLoss = 25.53283828258772 \tAccuracy = 54.054054054054056\n",
            "Epoch 300: \tLoss = 25.532796554175903 \tAccuracy = 54.054054054054056\n",
            "Epoch 301: \tLoss = 25.53275486184929 \tAccuracy = 54.054054054054056\n",
            "Epoch 302: \tLoss = 25.532713205616403 \tAccuracy = 54.054054054054056\n",
            "Epoch 303: \tLoss = 25.532671585487744 \tAccuracy = 54.054054054054056\n",
            "Epoch 304: \tLoss = 25.532630001475702 \tAccuracy = 54.054054054054056\n",
            "Epoch 305: \tLoss = 25.532588453594535 \tAccuracy = 54.054054054054056\n",
            "Epoch 306: \tLoss = 25.532546941860282 \tAccuracy = 54.054054054054056\n",
            "Epoch 307: \tLoss = 25.53250546629073 \tAccuracy = 54.054054054054056\n",
            "Epoch 308: \tLoss = 25.532464026905338 \tAccuracy = 54.054054054054056\n",
            "Epoch 309: \tLoss = 25.532422623725218 \tAccuracy = 54.054054054054056\n",
            "Epoch 310: \tLoss = 25.532381256773068 \tAccuracy = 54.054054054054056\n",
            "Epoch 311: \tLoss = 25.532339926073124 \tAccuracy = 54.054054054054056\n",
            "Epoch 312: \tLoss = 25.53229863165114 \tAccuracy = 54.054054054054056\n",
            "Epoch 313: \tLoss = 25.5322573735343 \tAccuracy = 54.054054054054056\n",
            "Epoch 314: \tLoss = 25.53221615175122 \tAccuracy = 54.054054054054056\n",
            "Epoch 315: \tLoss = 25.5321749663319 \tAccuracy = 54.054054054054056\n",
            "Epoch 316: \tLoss = 25.532133817307667 \tAccuracy = 54.054054054054056\n",
            "Epoch 317: \tLoss = 25.53209270471115 \tAccuracy = 54.054054054054056\n",
            "Epoch 318: \tLoss = 25.53205162857625 \tAccuracy = 54.054054054054056\n",
            "Epoch 319: \tLoss = 25.5320105889381 \tAccuracy = 54.054054054054056\n",
            "Epoch 320: \tLoss = 25.531969585833018 \tAccuracy = 54.054054054054056\n",
            "Epoch 321: \tLoss = 25.531928619298522 \tAccuracy = 54.054054054054056\n",
            "Epoch 322: \tLoss = 25.531887689373228 \tAccuracy = 54.054054054054056\n",
            "Epoch 323: \tLoss = 25.53184679609688 \tAccuracy = 54.054054054054056\n",
            "Epoch 324: \tLoss = 25.5318059395103 \tAccuracy = 54.054054054054056\n",
            "Epoch 325: \tLoss = 25.531765119655354 \tAccuracy = 54.054054054054056\n",
            "Epoch 326: \tLoss = 25.531724336574932 \tAccuracy = 54.054054054054056\n",
            "Epoch 327: \tLoss = 25.531683590312916 \tAccuracy = 54.054054054054056\n",
            "Epoch 328: \tLoss = 25.531642880914177 \tAccuracy = 54.054054054054056\n",
            "Epoch 329: \tLoss = 25.531602208424506 \tAccuracy = 54.054054054054056\n",
            "Epoch 330: \tLoss = 25.531561572890638 \tAccuracy = 54.054054054054056\n",
            "Epoch 331: \tLoss = 25.53152097436019 \tAccuracy = 54.054054054054056\n",
            "Epoch 332: \tLoss = 25.531480412881677 \tAccuracy = 54.054054054054056\n",
            "Epoch 333: \tLoss = 25.53143988850445 \tAccuracy = 54.054054054054056\n",
            "Epoch 334: \tLoss = 25.531399401278705 \tAccuracy = 54.054054054054056\n",
            "Epoch 335: \tLoss = 25.53135895125544 \tAccuracy = 54.054054054054056\n",
            "Epoch 336: \tLoss = 25.531318538486452 \tAccuracy = 54.054054054054056\n",
            "Epoch 337: \tLoss = 25.531278163024325 \tAccuracy = 54.054054054054056\n",
            "Epoch 338: \tLoss = 25.531237824922368 \tAccuracy = 54.054054054054056\n",
            "Epoch 339: \tLoss = 25.531197524234646 \tAccuracy = 54.054054054054056\n",
            "Epoch 340: \tLoss = 25.531157261015938 \tAccuracy = 54.054054054054056\n",
            "Epoch 341: \tLoss = 25.53111703532172 \tAccuracy = 54.054054054054056\n",
            "Epoch 342: \tLoss = 25.53107684720815 \tAccuracy = 54.054054054054056\n",
            "Epoch 343: \tLoss = 25.531036696732063 \tAccuracy = 54.054054054054056\n",
            "Epoch 344: \tLoss = 25.53099658395091 \tAccuracy = 54.054054054054056\n",
            "Epoch 345: \tLoss = 25.530956508922813 \tAccuracy = 54.054054054054056\n",
            "Epoch 346: \tLoss = 25.53091647170649 \tAccuracy = 54.054054054054056\n",
            "Epoch 347: \tLoss = 25.530876472361264 \tAccuracy = 54.054054054054056\n",
            "Epoch 348: \tLoss = 25.530836510947047 \tAccuracy = 54.054054054054056\n",
            "Epoch 349: \tLoss = 25.530796587524314 \tAccuracy = 54.054054054054056\n",
            "Epoch 350: \tLoss = 25.530756702154108 \tAccuracy = 54.054054054054056\n",
            "Epoch 351: \tLoss = 25.530716854898017 \tAccuracy = 54.054054054054056\n",
            "Epoch 352: \tLoss = 25.53067704581813 \tAccuracy = 54.054054054054056\n",
            "Epoch 353: \tLoss = 25.530637274977096 \tAccuracy = 54.054054054054056\n",
            "Epoch 354: \tLoss = 25.530597542438016 \tAccuracy = 54.054054054054056\n",
            "Epoch 355: \tLoss = 25.53055784826452 \tAccuracy = 54.054054054054056\n",
            "Epoch 356: \tLoss = 25.53051819252069 \tAccuracy = 54.054054054054056\n",
            "Epoch 357: \tLoss = 25.530478575271076 \tAccuracy = 54.054054054054056\n",
            "Epoch 358: \tLoss = 25.530438996580674 \tAccuracy = 54.054054054054056\n",
            "Epoch 359: \tLoss = 25.530399456514935 \tAccuracy = 54.054054054054056\n",
            "Epoch 360: \tLoss = 25.5303599551397 \tAccuracy = 54.054054054054056\n",
            "Epoch 361: \tLoss = 25.530320492521263 \tAccuracy = 54.054054054054056\n",
            "Epoch 362: \tLoss = 25.53028106872629 \tAccuracy = 54.054054054054056\n",
            "Epoch 363: \tLoss = 25.530241683821842 \tAccuracy = 54.054054054054056\n",
            "Epoch 364: \tLoss = 25.530202337875373 \tAccuracy = 54.054054054054056\n",
            "Epoch 365: \tLoss = 25.530163030954686 \tAccuracy = 54.054054054054056\n",
            "Epoch 366: \tLoss = 25.530123763127946 \tAccuracy = 54.054054054054056\n",
            "Epoch 367: \tLoss = 25.53008453446366 \tAccuracy = 54.054054054054056\n",
            "Epoch 368: \tLoss = 25.530045345030672 \tAccuracy = 54.054054054054056\n",
            "Epoch 369: \tLoss = 25.53000619489815 \tAccuracy = 54.054054054054056\n",
            "Epoch 370: \tLoss = 25.52996708413555 \tAccuracy = 54.054054054054056\n",
            "Epoch 371: \tLoss = 25.529928012812675 \tAccuracy = 54.054054054054056\n",
            "Epoch 372: \tLoss = 25.529888980999573 \tAccuracy = 54.054054054054056\n",
            "Epoch 373: \tLoss = 25.5298499887666 \tAccuracy = 54.054054054054056\n",
            "Epoch 374: \tLoss = 25.529811036184366 \tAccuracy = 54.054054054054056\n",
            "Epoch 375: \tLoss = 25.529772123323752 \tAccuracy = 54.054054054054056\n",
            "Epoch 376: \tLoss = 25.529733250255887 \tAccuracy = 54.054054054054056\n",
            "Epoch 377: \tLoss = 25.529694417052127 \tAccuracy = 54.054054054054056\n",
            "Epoch 378: \tLoss = 25.52965562378408 \tAccuracy = 54.054054054054056\n",
            "Epoch 379: \tLoss = 25.529616870523558 \tAccuracy = 54.054054054054056\n",
            "Epoch 380: \tLoss = 25.52957815734258 \tAccuracy = 54.054054054054056\n",
            "Epoch 381: \tLoss = 25.529539484313382 \tAccuracy = 54.054054054054056\n",
            "Epoch 382: \tLoss = 25.52950085150838 \tAccuracy = 54.054054054054056\n",
            "Epoch 383: \tLoss = 25.52946225900018 \tAccuracy = 54.054054054054056\n",
            "Epoch 384: \tLoss = 25.529423706861543 \tAccuracy = 54.054054054054056\n",
            "Epoch 385: \tLoss = 25.52938519516542 \tAccuracy = 54.054054054054056\n",
            "Epoch 386: \tLoss = 25.529346723984894 \tAccuracy = 54.054054054054056\n",
            "Epoch 387: \tLoss = 25.529308293393207 \tAccuracy = 54.054054054054056\n",
            "Epoch 388: \tLoss = 25.529269903463724 \tAccuracy = 54.054054054054056\n",
            "Epoch 389: \tLoss = 25.52923155426995 \tAccuracy = 54.054054054054056\n",
            "Epoch 390: \tLoss = 25.529193245885494 \tAccuracy = 54.054054054054056\n",
            "Epoch 391: \tLoss = 25.52915497838409 \tAccuracy = 54.054054054054056\n",
            "Epoch 392: \tLoss = 25.529116751839563 \tAccuracy = 54.054054054054056\n",
            "Epoch 393: \tLoss = 25.52907856632583 \tAccuracy = 54.054054054054056\n",
            "Epoch 394: \tLoss = 25.529040421916886 \tAccuracy = 54.054054054054056\n",
            "Epoch 395: \tLoss = 25.529002318686814 \tAccuracy = 54.054054054054056\n",
            "Epoch 396: \tLoss = 25.528964256709756 \tAccuracy = 54.054054054054056\n",
            "Epoch 397: \tLoss = 25.528926236059903 \tAccuracy = 54.054054054054056\n",
            "Epoch 398: \tLoss = 25.52888825681151 \tAccuracy = 54.054054054054056\n",
            "Epoch 399: \tLoss = 25.528850319038852 \tAccuracy = 54.054054054054056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "xVl5IY2UzaAK",
        "outputId": "5a342fef-982b-4f71-c9e1-6166e7684d4d"
      },
      "source": [
        "plot_loss_and_accuracy(loss, acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkRs6di1zaAL"
      },
      "source": [
        "y_pred = mlp.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIyQ_YA7zaAL",
        "outputId": "81e2dfcc-15d9-4a27-998b-b8f71503ca23"
      },
      "source": [
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.62      1.00      0.76         8\n",
            "\n",
            "    accuracy                           0.62        13\n",
            "   macro avg       0.31      0.50      0.38        13\n",
            "weighted avg       0.38      0.62      0.47        13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiRWn13VzaAL"
      },
      "source": [
        "### Red densa con función de activación ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fwrqp-EzaAL"
      },
      "source": [
        "mlp = MLP(input_dim=X.shape[1], hidden_units=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAcsQDaAzaAM",
        "outputId": "204f6b17-b2e6-49e7-9a91-3494e469f6ed"
      },
      "source": [
        "np.random.seed(0)\n",
        "loss, acc = mlp.fit(X_train, y_train, learning_rate=0.001, epochs=400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: \tLoss = nan \tAccuracy = 45.94594594594595\n",
            "Epoch 1: \tLoss = nan \tAccuracy = 51.35135135135135\n",
            "Epoch 2: \tLoss = nan \tAccuracy = 51.35135135135135\n",
            "Epoch 3: \tLoss = nan \tAccuracy = 51.35135135135135\n",
            "Epoch 4: \tLoss = nan \tAccuracy = 54.054054054054056\n",
            "Epoch 5: \tLoss = 29.360052973300498 \tAccuracy = 54.054054054054056\n",
            "Epoch 6: \tLoss = 28.19240665317443 \tAccuracy = 54.054054054054056\n",
            "Epoch 7: \tLoss = 27.589028022486417 \tAccuracy = 54.054054054054056\n",
            "Epoch 8: \tLoss = 27.177969848346955 \tAccuracy = 54.054054054054056\n",
            "Epoch 9: \tLoss = 26.869391058262067 \tAccuracy = 48.64864864864865\n",
            "Epoch 10: \tLoss = 26.66126389112389 \tAccuracy = 51.35135135135135\n",
            "Epoch 11: \tLoss = 26.48159286165557 \tAccuracy = 56.75675675675676\n",
            "Epoch 12: \tLoss = 26.32890129916719 \tAccuracy = 56.75675675675676\n",
            "Epoch 13: \tLoss = 26.19684042387339 \tAccuracy = 56.75675675675676\n",
            "Epoch 14: \tLoss = 26.080951278758036 \tAccuracy = 54.054054054054056\n",
            "Epoch 15: \tLoss = 25.977982167763233 \tAccuracy = 54.054054054054056\n",
            "Epoch 16: \tLoss = 25.88549484865814 \tAccuracy = 54.054054054054056\n",
            "Epoch 17: \tLoss = 25.801620839009225 \tAccuracy = 54.054054054054056\n",
            "Epoch 18: \tLoss = 25.72490309049591 \tAccuracy = 54.054054054054056\n",
            "Epoch 19: \tLoss = 25.654189022435446 \tAccuracy = 54.054054054054056\n",
            "Epoch 20: \tLoss = 25.58855591062625 \tAccuracy = 54.054054054054056\n",
            "Epoch 21: \tLoss = 25.52725745459167 \tAccuracy = 54.054054054054056\n",
            "Epoch 22: \tLoss = 25.469684660158794 \tAccuracy = 54.054054054054056\n",
            "Epoch 23: \tLoss = 25.415336665634605 \tAccuracy = 56.75675675675676\n",
            "Epoch 24: \tLoss = 25.363798637556123 \tAccuracy = 56.75675675675676\n",
            "Epoch 25: \tLoss = 25.314724794283627 \tAccuracy = 56.75675675675676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: \tLoss = 25.267825213985688 \tAccuracy = 56.75675675675676\n",
            "Epoch 27: \tLoss = 25.22285547793453 \tAccuracy = 56.75675675675676\n",
            "Epoch 28: \tLoss = 25.179608466233883 \tAccuracy = 59.45945945945946\n",
            "Epoch 29: \tLoss = 25.137907806624085 \tAccuracy = 59.45945945945946\n",
            "Epoch 30: \tLoss = 25.09760260593722 \tAccuracy = 56.75675675675676\n",
            "Epoch 31: \tLoss = 25.058563185889227 \tAccuracy = 62.16216216216216\n",
            "Epoch 32: \tLoss = 25.02067761171149 \tAccuracy = 62.16216216216216\n",
            "Epoch 33: \tLoss = 24.98384885125354 \tAccuracy = 62.16216216216216\n",
            "Epoch 34: \tLoss = 24.947992438759783 \tAccuracy = 64.86486486486487\n",
            "Epoch 35: \tLoss = 24.91303454504952 \tAccuracy = 64.86486486486487\n",
            "Epoch 36: \tLoss = 24.87891037675759 \tAccuracy = 64.86486486486487\n",
            "Epoch 37: \tLoss = 24.84556284334979 \tAccuracy = 64.86486486486487\n",
            "Epoch 38: \tLoss = 24.81294144304959 \tAccuracy = 64.86486486486487\n",
            "Epoch 39: \tLoss = 24.77321425122468 \tAccuracy = 64.86486486486487\n",
            "Epoch 40: \tLoss = 24.743325534544766 \tAccuracy = 64.86486486486487\n",
            "Epoch 41: \tLoss = 24.723955957285433 \tAccuracy = 64.86486486486487\n",
            "Epoch 42: \tLoss = 24.688330346592842 \tAccuracy = 64.86486486486487\n",
            "Epoch 43: \tLoss = 24.6611795664612 \tAccuracy = 64.86486486486487\n",
            "Epoch 44: \tLoss = 24.634908263105444 \tAccuracy = 67.56756756756756\n",
            "Epoch 45: \tLoss = 24.609453248195514 \tAccuracy = 67.56756756756756\n",
            "Epoch 46: \tLoss = 24.58474016461988 \tAccuracy = 67.56756756756756\n",
            "Epoch 47: \tLoss = 24.56070387654013 \tAccuracy = 67.56756756756756\n",
            "Epoch 48: \tLoss = 24.53728728004058 \tAccuracy = 67.56756756756756\n",
            "Epoch 49: \tLoss = 24.514440180927245 \tAccuracy = 67.56756756756756\n",
            "Epoch 50: \tLoss = 24.492118342792153 \tAccuracy = 67.56756756756756\n",
            "Epoch 51: \tLoss = 24.470282678029484 \tAccuracy = 67.56756756756756\n",
            "Epoch 52: \tLoss = 24.448898558622815 \tAccuracy = 67.56756756756756\n",
            "Epoch 53: \tLoss = 24.427935227576626 \tAccuracy = 67.56756756756756\n",
            "Epoch 54: \tLoss = 24.407365295153596 \tAccuracy = 67.56756756756756\n",
            "Epoch 55: \tLoss = 24.387164306760408 \tAccuracy = 67.56756756756756\n",
            "Epoch 56: \tLoss = 24.367310371515572 \tAccuracy = 67.56756756756756\n",
            "Epoch 57: \tLoss = 24.34778384233244 \tAccuracy = 67.56756756756756\n",
            "Epoch 58: \tLoss = 24.328567039833306 \tAccuracy = 67.56756756756756\n",
            "Epoch 59: \tLoss = 24.30964401363626 \tAccuracy = 67.56756756756756\n",
            "Epoch 60: \tLoss = 24.291000335573486 \tAccuracy = 64.86486486486487\n",
            "Epoch 61: \tLoss = 24.27262292024573 \tAccuracy = 64.86486486486487\n",
            "Epoch 62: \tLoss = 24.254499869023007 \tAccuracy = 64.86486486486487\n",
            "Epoch 63: \tLoss = 24.23662033419241 \tAccuracy = 64.86486486486487\n",
            "Epoch 64: \tLoss = 24.218974400448523 \tAccuracy = 64.86486486486487\n",
            "Epoch 65: \tLoss = 24.201552981338466 \tAccuracy = 64.86486486486487\n",
            "Epoch 66: \tLoss = 24.184347728623514 \tAccuracy = 64.86486486486487\n",
            "Epoch 67: \tLoss = 24.167350952815937 \tAccuracy = 64.86486486486487\n",
            "Epoch 68: \tLoss = 24.15055555339926 \tAccuracy = 64.86486486486487\n",
            "Epoch 69: \tLoss = 24.133954957453078 \tAccuracy = 64.86486486486487\n",
            "Epoch 70: \tLoss = 24.1175430655833 \tAccuracy = 64.86486486486487\n",
            "Epoch 71: \tLoss = 24.101314204212265 \tAccuracy = 64.86486486486487\n",
            "Epoch 72: \tLoss = 24.085263083413615 \tAccuracy = 64.86486486486487\n",
            "Epoch 73: \tLoss = 24.069384759588736 \tAccuracy = 64.86486486486487\n",
            "Epoch 74: \tLoss = 24.05367460237649 \tAccuracy = 64.86486486486487\n",
            "Epoch 75: \tLoss = 24.038128265270032 \tAccuracy = 64.86486486486487\n",
            "Epoch 76: \tLoss = 24.022741659484435 \tAccuracy = 64.86486486486487\n",
            "Epoch 77: \tLoss = 24.007510930678897 \tAccuracy = 64.86486486486487\n",
            "Epoch 78: \tLoss = 23.992432438189358 \tAccuracy = 64.86486486486487\n",
            "Epoch 79: \tLoss = 23.977502736471727 \tAccuracy = 64.86486486486487\n",
            "Epoch 80: \tLoss = 23.962718558494437 \tAccuracy = 64.86486486486487\n",
            "Epoch 81: \tLoss = 23.948076800852483 \tAccuracy = 64.86486486486487\n",
            "Epoch 82: \tLoss = 23.933574510403425 \tAccuracy = 64.86486486486487\n",
            "Epoch 83: \tLoss = 23.919208872251318 \tAccuracy = 64.86486486486487\n",
            "Epoch 84: \tLoss = 23.904977198925508 \tAccuracy = 64.86486486486487\n",
            "Epoch 85: \tLoss = 23.890876920620478 \tAccuracy = 64.86486486486487\n",
            "Epoch 86: \tLoss = 23.876905576379023 \tAccuracy = 64.86486486486487\n",
            "Epoch 87: \tLoss = 23.863060806115108 \tAccuracy = 64.86486486486487\n",
            "Epoch 88: \tLoss = 23.84934034338541 \tAccuracy = 64.86486486486487\n",
            "Epoch 89: \tLoss = 23.835742008829058 \tAccuracy = 64.86486486486487\n",
            "Epoch 90: \tLoss = 23.822263704204794 \tAccuracy = 64.86486486486487\n",
            "Epoch 91: \tLoss = 23.808903406962603 \tAccuracy = 64.86486486486487\n",
            "Epoch 92: \tLoss = 23.795659165294722 \tAccuracy = 64.86486486486487\n",
            "Epoch 93: \tLoss = 23.785338328662874 \tAccuracy = 64.86486486486487\n",
            "Epoch 94: \tLoss = 23.771705197265707 \tAccuracy = 64.86486486486487\n",
            "Epoch 95: \tLoss = 23.7601031583584 \tAccuracy = 64.86486486486487\n",
            "Epoch 96: \tLoss = 23.74683890288546 \tAccuracy = 64.86486486486487\n",
            "Epoch 97: \tLoss = 23.735566510711692 \tAccuracy = 64.86486486486487\n",
            "Epoch 98: \tLoss = 23.72250094136592 \tAccuracy = 64.86486486486487\n",
            "Epoch 99: \tLoss = 23.71169093621549 \tAccuracy = 64.86486486486487\n",
            "Epoch 100: \tLoss = 23.698649322510413 \tAccuracy = 64.86486486486487\n",
            "Epoch 101: \tLoss = 23.688417162101196 \tAccuracy = 64.86486486486487\n",
            "Epoch 102: \tLoss = 23.675248428454132 \tAccuracy = 64.86486486486487\n",
            "Epoch 103: \tLoss = 23.665694778640727 \tAccuracy = 64.86486486486487\n",
            "Epoch 104: \tLoss = 23.6549858136566 \tAccuracy = 64.86486486486487\n",
            "Epoch 105: \tLoss = 23.641558660242126 \tAccuracy = 64.86486486486487\n",
            "Epoch 106: \tLoss = 23.631839318255462 \tAccuracy = 64.86486486486487\n",
            "Epoch 107: \tLoss = 23.621589124286018 \tAccuracy = 64.86486486486487\n",
            "Epoch 108: \tLoss = 23.608771615359828 \tAccuracy = 64.86486486486487\n",
            "Epoch 109: \tLoss = 23.599206047848966 \tAccuracy = 64.86486486486487\n",
            "Epoch 110: \tLoss = 23.58934000612128 \tAccuracy = 64.86486486486487\n",
            "Epoch 111: \tLoss = 23.576820288368346 \tAccuracy = 64.86486486486487\n",
            "Epoch 112: \tLoss = 23.56764594112407 \tAccuracy = 64.86486486486487\n",
            "Epoch 113: \tLoss = 23.55810432855541 \tAccuracy = 64.86486486486487\n",
            "Epoch 114: \tLoss = 23.545627510545202 \tAccuracy = 64.86486486486487\n",
            "Epoch 115: \tLoss = 23.537039986755666 \tAccuracy = 64.86486486486487\n",
            "Epoch 116: \tLoss = 23.527775173199988 \tAccuracy = 64.86486486486487\n",
            "Epoch 117: \tLoss = 23.517533588769716 \tAccuracy = 64.86486486486487\n",
            "Epoch 118: \tLoss = 23.50558370408765 \tAccuracy = 67.56756756756756\n",
            "Epoch 119: \tLoss = 23.497206760970748 \tAccuracy = 67.56756756756756\n",
            "Epoch 120: \tLoss = 23.48832335629269 \tAccuracy = 67.56756756756756\n",
            "Epoch 121: \tLoss = 23.478473224282993 \tAccuracy = 67.56756756756756\n",
            "Epoch 122: \tLoss = 23.466691144811158 \tAccuracy = 67.56756756756756\n",
            "Epoch 123: \tLoss = 23.458841805794478 \tAccuracy = 67.56756756756756\n",
            "Epoch 124: \tLoss = 23.450271528888948 \tAccuracy = 67.56756756756756\n",
            "Epoch 125: \tLoss = 23.44076327745504 \tAccuracy = 67.56756756756756\n",
            "Epoch 126: \tLoss = 23.431319832699163 \tAccuracy = 67.56756756756756\n",
            "Epoch 127: \tLoss = 23.419906056773172 \tAccuracy = 67.56756756756756\n",
            "Epoch 128: \tLoss = 23.41247152546984 \tAccuracy = 67.56756756756756\n",
            "Epoch 129: \tLoss = 23.404266589699155 \tAccuracy = 67.56756756756756\n",
            "Epoch 130: \tLoss = 23.39515072709397 \tAccuracy = 67.56756756756756\n",
            "Epoch 131: \tLoss = 23.38608549206354 \tAccuracy = 67.56756756756756\n",
            "Epoch 132: \tLoss = 23.377103484662783 \tAccuracy = 67.56756756756756\n",
            "Epoch 133: \tLoss = 23.36820277520648 \tAccuracy = 67.56756756756756\n",
            "Epoch 134: \tLoss = 23.357476445200838 \tAccuracy = 67.56756756756756\n",
            "Epoch 135: \tLoss = 23.350315707808427 \tAccuracy = 67.56756756756756\n",
            "Epoch 136: \tLoss = 23.342571435079854 \tAccuracy = 67.56756756756756\n",
            "Epoch 137: \tLoss = 23.333944379830193 \tAccuracy = 67.56756756756756\n",
            "Epoch 138: \tLoss = 23.325351437327704 \tAccuracy = 67.56756756756756\n",
            "Epoch 139: \tLoss = 23.31682726172179 \tAccuracy = 67.56756756756756\n",
            "Epoch 140: \tLoss = 23.308371005516683 \tAccuracy = 67.56756756756756\n",
            "Epoch 141: \tLoss = 23.299980529018598 \tAccuracy = 67.56756756756756\n",
            "Epoch 142: \tLoss = 23.291653774661178 \tAccuracy = 67.56756756756756\n",
            "Epoch 143: \tLoss = 23.283388812044088 \tAccuracy = 67.56756756756756\n",
            "Epoch 144: \tLoss = 23.27331864083997 \tAccuracy = 67.56756756756756\n",
            "Epoch 145: \tLoss = 23.266661844068835 \tAccuracy = 67.56756756756756\n",
            "Epoch 146: \tLoss = 23.25944957004709 \tAccuracy = 67.56756756756756\n",
            "Epoch 147: \tLoss = 23.251404967051034 \tAccuracy = 67.56756756756756\n",
            "Epoch 148: \tLoss = 23.24337797046149 \tAccuracy = 67.56756756756756\n",
            "Epoch 149: \tLoss = 23.235405006652925 \tAccuracy = 67.56756756756756\n",
            "Epoch 150: \tLoss = 23.22748626042604 \tAccuracy = 67.56756756756756\n",
            "Epoch 151: \tLoss = 23.219620377017577 \tAccuracy = 67.56756756756756\n",
            "Epoch 152: \tLoss = 23.211806007926462 \tAccuracy = 67.56756756756756\n",
            "Epoch 153: \tLoss = 23.20404187485696 \tAccuracy = 67.56756756756756\n",
            "Epoch 154: \tLoss = 23.196326767329076 \tAccuracy = 67.56756756756756\n",
            "Epoch 155: \tLoss = 23.188659537730203 \tAccuracy = 67.56756756756756\n",
            "Epoch 156: \tLoss = 23.181039096666094 \tAccuracy = 67.56756756756756\n",
            "Epoch 157: \tLoss = 23.173464408703552 \tAccuracy = 67.56756756756756\n",
            "Epoch 158: \tLoss = 23.16593448847378 \tAccuracy = 67.56756756756756\n",
            "Epoch 159: \tLoss = 23.15844839710376 \tAccuracy = 67.56756756756756\n",
            "Epoch 160: \tLoss = 23.15100523894533 \tAccuracy = 67.56756756756756\n",
            "Epoch 161: \tLoss = 23.14360415857503 \tAccuracy = 67.56756756756756\n",
            "Epoch 162: \tLoss = 23.136244338040218 \tAccuracy = 67.56756756756756\n",
            "Epoch 163: \tLoss = 23.128924994329306 \tAccuracy = 67.56756756756756\n",
            "Epoch 164: \tLoss = 23.12164537704618 \tAccuracy = 67.56756756756756\n",
            "Epoch 165: \tLoss = 23.11440476627066 \tAccuracy = 67.56756756756756\n",
            "Epoch 166: \tLoss = 23.107202470588682 \tAccuracy = 67.56756756756756\n",
            "Epoch 167: \tLoss = 23.10003782527733 \tAccuracy = 67.56756756756756\n",
            "Epoch 168: \tLoss = 23.092910190631216 \tAccuracy = 67.56756756756756\n",
            "Epoch 169: \tLoss = 23.085818950418172 \tAccuracy = 67.56756756756756\n",
            "Epoch 170: \tLoss = 23.078763510453047 \tAccuracy = 67.56756756756756\n",
            "Epoch 171: \tLoss = 23.071743297279504 \tAccuracy = 67.56756756756756\n",
            "Epoch 172: \tLoss = 23.064757756950943 \tAccuracy = 67.56756756756756\n",
            "Epoch 173: \tLoss = 23.05780635390192 \tAccuracy = 67.56756756756756\n",
            "Epoch 174: \tLoss = 23.050888569902796 \tAccuracy = 67.56756756756756\n",
            "Epoch 175: \tLoss = 23.044003903090456 \tAccuracy = 67.56756756756756\n",
            "Epoch 176: \tLoss = 23.03715186706917 \tAccuracy = 67.56756756756756\n",
            "Epoch 177: \tLoss = 23.030331990075574 \tAccuracy = 67.56756756756756\n",
            "Epoch 178: \tLoss = 23.02354381420274 \tAccuracy = 67.56756756756756\n",
            "Epoch 179: \tLoss = 23.016786894678525 \tAccuracy = 67.56756756756756\n",
            "Epoch 180: \tLoss = 23.01006079919403 \tAccuracy = 67.56756756756756\n",
            "Epoch 181: \tLoss = 23.003365107277805 \tAccuracy = 67.56756756756756\n",
            "Epoch 182: \tLoss = 22.9966994097127 \tAccuracy = 67.56756756756756\n",
            "Epoch 183: \tLoss = 22.99006330799169 \tAccuracy = 67.56756756756756\n",
            "Epoch 184: \tLoss = 22.983456413809737 \tAccuracy = 67.56756756756756\n",
            "Epoch 185: \tLoss = 22.97687834858902 \tAccuracy = 67.56756756756756\n",
            "Epoch 186: \tLoss = 22.970328743034827 \tAccuracy = 67.56756756756756\n",
            "Epoch 187: \tLoss = 22.96380723671995 \tAccuracy = 67.56756756756756\n",
            "Epoch 188: \tLoss = 22.957313477695354 \tAccuracy = 67.56756756756756\n",
            "Epoch 189: \tLoss = 22.95084712212509 \tAccuracy = 67.56756756756756\n",
            "Epoch 190: \tLoss = 22.94440783394393 \tAccuracy = 67.56756756756756\n",
            "Epoch 191: \tLoss = 22.937995284535674 \tAccuracy = 67.56756756756756\n",
            "Epoch 192: \tLoss = 22.931609152431044 \tAccuracy = 67.56756756756756\n",
            "Epoch 193: \tLoss = 22.925249123023384 \tAccuracy = 67.56756756756756\n",
            "Epoch 194: \tLoss = 22.9189148883011 \tAccuracy = 67.56756756756756\n",
            "Epoch 195: \tLoss = 22.912606146595678 \tAccuracy = 67.56756756756756\n",
            "Epoch 196: \tLoss = 22.906322602344055 \tAccuracy = 67.56756756756756\n",
            "Epoch 197: \tLoss = 22.9000639658644 \tAccuracy = 67.56756756756756\n",
            "Epoch 198: \tLoss = 22.89382995314446 \tAccuracy = 67.56756756756756\n",
            "Epoch 199: \tLoss = 22.887620285641468 \tAccuracy = 67.56756756756756\n",
            "Epoch 200: \tLoss = 22.88143469009293 \tAccuracy = 67.56756756756756\n",
            "Epoch 201: \tLoss = 22.87527289833756 \tAccuracy = 67.56756756756756\n",
            "Epoch 202: \tLoss = 22.86913464714562 \tAccuracy = 67.56756756756756\n",
            "Epoch 203: \tLoss = 22.8630196780581 \tAccuracy = 67.56756756756756\n",
            "Epoch 204: \tLoss = 22.856927737234194 \tAccuracy = 67.56756756756756\n",
            "Epoch 205: \tLoss = 22.850858575306397 \tAccuracy = 67.56756756756756\n",
            "Epoch 206: \tLoss = 22.844811947242896 \tAccuracy = 67.56756756756756\n",
            "Epoch 207: \tLoss = 22.838787612216695 \tAccuracy = 67.56756756756756\n",
            "Epoch 208: \tLoss = 22.832785333481134 \tAccuracy = 67.56756756756756\n",
            "Epoch 209: \tLoss = 22.82680487825118 \tAccuracy = 67.56756756756756\n",
            "Epoch 210: \tLoss = 22.820846017590565 \tAccuracy = 67.56756756756756\n",
            "Epoch 211: \tLoss = 22.814908526303867 \tAccuracy = 67.56756756756756\n",
            "Epoch 212: \tLoss = 22.80899218283375 \tAccuracy = 67.56756756756756\n",
            "Epoch 213: \tLoss = 22.80309676916265 \tAccuracy = 67.56756756756756\n",
            "Epoch 214: \tLoss = 22.797222070718956 \tAccuracy = 67.56756756756756\n",
            "Epoch 215: \tLoss = 22.791367876287136 \tAccuracy = 67.56756756756756\n",
            "Epoch 216: \tLoss = 22.785533977921865 \tAccuracy = 67.56756756756756\n",
            "Epoch 217: \tLoss = 22.779720170865666 \tAccuracy = 67.56756756756756\n",
            "Epoch 218: \tLoss = 22.773926253470066 \tAccuracy = 67.56756756756756\n",
            "Epoch 219: \tLoss = 22.768152027119925 \tAccuracy = 67.56756756756756\n",
            "Epoch 220: \tLoss = 22.762397296160863 \tAccuracy = 67.56756756756756\n",
            "Epoch 221: \tLoss = 22.756661867829518 \tAccuracy = 67.56756756756756\n",
            "Epoch 222: \tLoss = 22.750945552186604 \tAccuracy = 67.56756756756756\n",
            "Epoch 223: \tLoss = 22.745248162052466 \tAccuracy = 67.56756756756756\n",
            "Epoch 224: \tLoss = 22.73956951294513 \tAccuracy = 67.56756756756756\n",
            "Epoch 225: \tLoss = 22.73390942302069 \tAccuracy = 67.56756756756756\n",
            "Epoch 226: \tLoss = 22.728267713015768 \tAccuracy = 67.56756756756756\n",
            "Epoch 227: \tLoss = 22.7226442061922 \tAccuracy = 67.56756756756756\n",
            "Epoch 228: \tLoss = 22.717038728283587 \tAccuracy = 67.56756756756756\n",
            "Epoch 229: \tLoss = 22.71145110744375 \tAccuracy = 67.56756756756756\n",
            "Epoch 230: \tLoss = 22.70588117419699 \tAccuracy = 67.56756756756756\n",
            "Epoch 231: \tLoss = 22.700328761389997 \tAccuracy = 67.56756756756756\n",
            "Epoch 232: \tLoss = 22.694793704145322 \tAccuracy = 67.56756756756756\n",
            "Epoch 233: \tLoss = 22.68927583981653 \tAccuracy = 67.56756756756756\n",
            "Epoch 234: \tLoss = 22.683775007944632 \tAccuracy = 67.56756756756756\n",
            "Epoch 235: \tLoss = 22.678291050216004 \tAccuracy = 67.56756756756756\n",
            "Epoch 236: \tLoss = 22.67282381042159 \tAccuracy = 67.56756756756756\n",
            "Epoch 237: \tLoss = 22.667373134417375 \tAccuracy = 67.56756756756756\n",
            "Epoch 238: \tLoss = 22.66193887008606 \tAccuracy = 67.56756756756756\n",
            "Epoch 239: \tLoss = 22.656520867299896 \tAccuracy = 67.56756756756756\n",
            "Epoch 240: \tLoss = 22.65111897788453 \tAccuracy = 67.56756756756756\n",
            "Epoch 241: \tLoss = 22.64573305558406 \tAccuracy = 67.56756756756756\n",
            "Epoch 242: \tLoss = 22.640362956026905 \tAccuracy = 67.56756756756756\n",
            "Epoch 243: \tLoss = 22.635008536692766 \tAccuracy = 67.56756756756756\n",
            "Epoch 244: \tLoss = 22.629669656880452 \tAccuracy = 67.56756756756756\n",
            "Epoch 245: \tLoss = 22.624346177676564 \tAccuracy = 67.56756756756756\n",
            "Epoch 246: \tLoss = 22.619037961925077 \tAccuracy = 67.56756756756756\n",
            "Epoch 247: \tLoss = 22.613744874197668 \tAccuracy = 67.56756756756756\n",
            "Epoch 248: \tLoss = 22.608466780764843 \tAccuracy = 67.56756756756756\n",
            "Epoch 249: \tLoss = 22.603203549567816 \tAccuracy = 67.56756756756756\n",
            "Epoch 250: \tLoss = 22.597955050191075 \tAccuracy = 67.56756756756756\n",
            "Epoch 251: \tLoss = 22.59272115383567 \tAccuracy = 67.56756756756756\n",
            "Epoch 252: \tLoss = 22.587501733293067 \tAccuracy = 67.56756756756756\n",
            "Epoch 253: \tLoss = 22.58229666291981 \tAccuracy = 67.56756756756756\n",
            "Epoch 254: \tLoss = 22.57710581861257 \tAccuracy = 67.56756756756756\n",
            "Epoch 255: \tLoss = 22.57192907778395 \tAccuracy = 67.56756756756756\n",
            "Epoch 256: \tLoss = 22.56676631933879 \tAccuracy = 67.56756756756756\n",
            "Epoch 257: \tLoss = 22.561617423650993 \tAccuracy = 67.56756756756756\n",
            "Epoch 258: \tLoss = 22.556482272540933 \tAccuracy = 67.56756756756756\n",
            "Epoch 259: \tLoss = 22.551360749253295 \tAccuracy = 67.56756756756756\n",
            "Epoch 260: \tLoss = 22.54625273843549 \tAccuracy = 67.56756756756756\n",
            "Epoch 261: \tLoss = 22.54115812611645 \tAccuracy = 67.56756756756756\n",
            "Epoch 262: \tLoss = 22.53607679968593 \tAccuracy = 67.56756756756756\n",
            "Epoch 263: \tLoss = 22.531008647874245 \tAccuracy = 67.56756756756756\n",
            "Epoch 264: \tLoss = 22.52595356073241 \tAccuracy = 67.56756756756756\n",
            "Epoch 265: \tLoss = 22.520911429612752 \tAccuracy = 67.56756756756756\n",
            "Epoch 266: \tLoss = 22.515882147149767 \tAccuracy = 67.56756756756756\n",
            "Epoch 267: \tLoss = 22.510865607241563 \tAccuracy = 67.56756756756756\n",
            "Epoch 268: \tLoss = 22.50586170503154 \tAccuracy = 67.56756756756756\n",
            "Epoch 269: \tLoss = 22.500870336890436 \tAccuracy = 67.56756756756756\n",
            "Epoch 270: \tLoss = 22.495891400398843 \tAccuracy = 67.56756756756756\n",
            "Epoch 271: \tLoss = 22.49092479432983 \tAccuracy = 67.56756756756756\n",
            "Epoch 272: \tLoss = 22.485970418632174 \tAccuracy = 67.56756756756756\n",
            "Epoch 273: \tLoss = 22.481028174413673 \tAccuracy = 67.56756756756756\n",
            "Epoch 274: \tLoss = 22.476097963924936 \tAccuracy = 67.56756756756756\n",
            "Epoch 275: \tLoss = 22.47117969054334 \tAccuracy = 67.56756756756756\n",
            "Epoch 276: \tLoss = 22.46627325875739 \tAccuracy = 67.56756756756756\n",
            "Epoch 277: \tLoss = 22.46137857415131 \tAccuracy = 67.56756756756756\n",
            "Epoch 278: \tLoss = 22.4564955433899 \tAccuracy = 67.56756756756756\n",
            "Epoch 279: \tLoss = 22.45162407420365 \tAccuracy = 67.56756756756756\n",
            "Epoch 280: \tLoss = 22.44676407537422 \tAccuracy = 67.56756756756756\n",
            "Epoch 281: \tLoss = 22.44191545672004 \tAccuracy = 67.56756756756756\n",
            "Epoch 282: \tLoss = 22.437078129082206 \tAccuracy = 67.56756756756756\n",
            "Epoch 283: \tLoss = 22.43225200431067 \tAccuracy = 67.56756756756756\n",
            "Epoch 284: \tLoss = 22.427436995250588 \tAccuracy = 67.56756756756756\n",
            "Epoch 285: \tLoss = 22.42263301572894 \tAccuracy = 67.56756756756756\n",
            "Epoch 286: \tLoss = 22.417839980541352 \tAccuracy = 67.56756756756756\n",
            "Epoch 287: \tLoss = 22.413057805439188 \tAccuracy = 67.56756756756756\n",
            "Epoch 288: \tLoss = 22.408286407116744 \tAccuracy = 67.56756756756756\n",
            "Epoch 289: \tLoss = 22.4035257031988 \tAccuracy = 67.56756756756756\n",
            "Epoch 290: \tLoss = 22.398775612228235 \tAccuracy = 67.56756756756756\n",
            "Epoch 291: \tLoss = 22.394036053653934 \tAccuracy = 67.56756756756756\n",
            "Epoch 292: \tLoss = 22.389306947818838 \tAccuracy = 67.56756756756756\n",
            "Epoch 293: \tLoss = 22.384588215948213 \tAccuracy = 67.56756756756756\n",
            "Epoch 294: \tLoss = 22.37987978013809 \tAccuracy = 67.56756756756756\n",
            "Epoch 295: \tLoss = 22.375181563343883 \tAccuracy = 67.56756756756756\n",
            "Epoch 296: \tLoss = 22.37049348936919 \tAccuracy = 67.56756756756756\n",
            "Epoch 297: \tLoss = 22.365815482854735 \tAccuracy = 67.56756756756756\n",
            "Epoch 298: \tLoss = 22.361147469267596 \tAccuracy = 67.56756756756756\n",
            "Epoch 299: \tLoss = 22.356489374890423 \tAccuracy = 67.56756756756756\n",
            "Epoch 300: \tLoss = 22.351841126810974 \tAccuracy = 67.56756756756756\n",
            "Epoch 301: \tLoss = 22.347202652911683 \tAccuracy = 67.56756756756756\n",
            "Epoch 302: \tLoss = 22.342573881859508 \tAccuracy = 67.56756756756756\n",
            "Epoch 303: \tLoss = 22.33795474309583 \tAccuracy = 67.56756756756756\n",
            "Epoch 304: \tLoss = 22.33334516682656 \tAccuracy = 67.56756756756756\n",
            "Epoch 305: \tLoss = 22.328745084012375 \tAccuracy = 67.56756756756756\n",
            "Epoch 306: \tLoss = 22.324154426359083 \tAccuracy = 67.56756756756756\n",
            "Epoch 307: \tLoss = 22.31957312630818 \tAccuracy = 67.56756756756756\n",
            "Epoch 308: \tLoss = 22.315001117027464 \tAccuracy = 67.56756756756756\n",
            "Epoch 309: \tLoss = 22.31043833240187 \tAccuracy = 67.56756756756756\n",
            "Epoch 310: \tLoss = 22.30588470702437 \tAccuracy = 67.56756756756756\n",
            "Epoch 311: \tLoss = 22.30134017618706 \tAccuracy = 67.56756756756756\n",
            "Epoch 312: \tLoss = 22.296804675872337 \tAccuracy = 67.56756756756756\n",
            "Epoch 313: \tLoss = 22.292278142744202 \tAccuracy = 67.56756756756756\n",
            "Epoch 314: \tLoss = 22.287760514139745 \tAccuracy = 67.56756756756756\n",
            "Epoch 315: \tLoss = 22.283251728060645 \tAccuracy = 67.56756756756756\n",
            "Epoch 316: \tLoss = 22.278751723164895 \tAccuracy = 67.56756756756756\n",
            "Epoch 317: \tLoss = 22.274260438758596 \tAccuracy = 67.56756756756756\n",
            "Epoch 318: \tLoss = 22.269777814787872 \tAccuracy = 67.56756756756756\n",
            "Epoch 319: \tLoss = 22.26530379183087 \tAccuracy = 67.56756756756756\n",
            "Epoch 320: \tLoss = 22.260838311089962 \tAccuracy = 67.56756756756756\n",
            "Epoch 321: \tLoss = 22.256381314383923 \tAccuracy = 67.56756756756756\n",
            "Epoch 322: \tLoss = 22.251932744140326 \tAccuracy = 64.86486486486487\n",
            "Epoch 323: \tLoss = 22.24749254338803 \tAccuracy = 64.86486486486487\n",
            "Epoch 324: \tLoss = 22.243060655749726 \tAccuracy = 64.86486486486487\n",
            "Epoch 325: \tLoss = 22.238637025434578 \tAccuracy = 64.86486486486487\n",
            "Epoch 326: \tLoss = 22.234221597231056 \tAccuracy = 64.86486486486487\n",
            "Epoch 327: \tLoss = 22.229814316499763 \tAccuracy = 64.86486486486487\n",
            "Epoch 328: \tLoss = 22.225415129166436 \tAccuracy = 64.86486486486487\n",
            "Epoch 329: \tLoss = 22.221023981714985 \tAccuracy = 64.86486486486487\n",
            "Epoch 330: \tLoss = 22.216640821180693 \tAccuracy = 64.86486486486487\n",
            "Epoch 331: \tLoss = 22.21226559514343 \tAccuracy = 64.86486486486487\n",
            "Epoch 332: \tLoss = 22.20789825172102 \tAccuracy = 64.86486486486487\n",
            "Epoch 333: \tLoss = 22.203538739562703 \tAccuracy = 64.86486486486487\n",
            "Epoch 334: \tLoss = 22.199187007842596 \tAccuracy = 64.86486486486487\n",
            "Epoch 335: \tLoss = 22.18651330343284 \tAccuracy = 64.86486486486487\n",
            "Epoch 336: \tLoss = 22.177440598880892 \tAccuracy = 64.86486486486487\n",
            "Epoch 337: \tLoss = 22.167821431924253 \tAccuracy = 64.86486486486487\n",
            "Epoch 338: \tLoss = 22.15818508014147 \tAccuracy = 64.86486486486487\n",
            "Epoch 339: \tLoss = 22.148582227147294 \tAccuracy = 64.86486486486487\n",
            "Epoch 340: \tLoss = 22.139015679158298 \tAccuracy = 64.86486486486487\n",
            "Epoch 341: \tLoss = 22.12948360665562 \tAccuracy = 64.86486486486487\n",
            "Epoch 342: \tLoss = 22.119983824046276 \tAccuracy = 64.86486486486487\n",
            "Epoch 343: \tLoss = 22.11051421059547 \tAccuracy = 64.86486486486487\n",
            "Epoch 344: \tLoss = 22.101072747630916 \tAccuracy = 64.86486486486487\n",
            "Epoch 345: \tLoss = 22.09165751764108 \tAccuracy = 64.86486486486487\n",
            "Epoch 346: \tLoss = 22.082266699853093 \tAccuracy = 64.86486486486487\n",
            "Epoch 347: \tLoss = 22.072898565752446 \tAccuracy = 64.86486486486487\n",
            "Epoch 348: \tLoss = 22.06355147487261 \tAccuracy = 64.86486486486487\n",
            "Epoch 349: \tLoss = 22.05422387086655 \tAccuracy = 64.86486486486487\n",
            "Epoch 350: \tLoss = 22.04491427784143 \tAccuracy = 64.86486486486487\n",
            "Epoch 351: \tLoss = 22.035621296936476 \tAccuracy = 64.86486486486487\n",
            "Epoch 352: \tLoss = 22.02634360312501 \tAccuracy = 64.86486486486487\n",
            "Epoch 353: \tLoss = 22.01707994222319 \tAccuracy = 64.86486486486487\n",
            "Epoch 354: \tLoss = 22.00782912808932 \tAccuracy = 64.86486486486487\n",
            "Epoch 355: \tLoss = 21.998590039998835 \tAccuracy = 64.86486486486487\n",
            "Epoch 356: \tLoss = 21.989361620181164 \tAccuracy = 64.86486486486487\n",
            "Epoch 357: \tLoss = 21.980142871505684 \tAccuracy = 64.86486486486487\n",
            "Epoch 358: \tLoss = 21.97093285530508 \tAccuracy = 64.86486486486487\n",
            "Epoch 359: \tLoss = 21.961730689325034 \tAccuracy = 64.86486486486487\n",
            "Epoch 360: \tLoss = 21.95253554579025 \tAccuracy = 64.86486486486487\n",
            "Epoch 361: \tLoss = 21.943346649577418 \tAccuracy = 64.86486486486487\n",
            "Epoch 362: \tLoss = 21.933382845500944 \tAccuracy = 64.86486486486487\n",
            "Epoch 363: \tLoss = 21.925183444225432 \tAccuracy = 64.86486486486487\n",
            "Epoch 364: \tLoss = 21.916333761459242 \tAccuracy = 64.86486486486487\n",
            "Epoch 365: \tLoss = 21.90720088226753 \tAccuracy = 70.27027027027027\n",
            "Epoch 366: \tLoss = 21.89720796648997 \tAccuracy = 70.27027027027027\n",
            "Epoch 367: \tLoss = 21.88912566640469 \tAccuracy = 70.27027027027027\n",
            "Epoch 368: \tLoss = 21.880281204113967 \tAccuracy = 70.27027027027027\n",
            "Epoch 369: \tLoss = 21.871160268664166 \tAccuracy = 70.27027027027027\n",
            "Epoch 370: \tLoss = 21.861363811674718 \tAccuracy = 70.27027027027027\n",
            "Epoch 371: \tLoss = 21.853148388909837 \tAccuracy = 70.27027027027027\n",
            "Epoch 372: \tLoss = 21.844309583473425 \tAccuracy = 70.27027027027027\n",
            "Epoch 373: \tLoss = 21.834527945513532 \tAccuracy = 70.27027027027027\n",
            "Epoch 374: \tLoss = 21.82638140669271 \tAccuracy = 70.27027027027027\n",
            "Epoch 375: \tLoss = 21.817541853493942 \tAccuracy = 70.27027027027027\n",
            "Epoch 376: \tLoss = 21.810541484480765 \tAccuracy = 72.97297297297297\n",
            "Epoch 377: \tLoss = 21.806670084000682 \tAccuracy = 72.97297297297297\n",
            "Epoch 378: \tLoss = 21.801633792610424 \tAccuracy = 72.97297297297297\n",
            "Epoch 379: \tLoss = 21.798131995775236 \tAccuracy = 72.97297297297297\n",
            "Epoch 380: \tLoss = 21.79296961426927 \tAccuracy = 72.97297297297297\n",
            "Epoch 381: \tLoss = 21.789636971684153 \tAccuracy = 72.97297297297297\n",
            "Epoch 382: \tLoss = 21.78437076764547 \tAccuracy = 72.97297297297297\n",
            "Epoch 383: \tLoss = 21.781164112637516 \tAccuracy = 72.97297297297297\n",
            "Epoch 384: \tLoss = 21.776855087832036 \tAccuracy = 72.97297297297297\n",
            "Epoch 385: \tLoss = 21.77182870830261 \tAccuracy = 72.97297297297297\n",
            "Epoch 386: \tLoss = 21.768090149739884 \tAccuracy = 72.97297297297297\n",
            "Epoch 387: \tLoss = 21.763323824499402 \tAccuracy = 72.97297297297297\n",
            "Epoch 388: \tLoss = 21.759681130945744 \tAccuracy = 72.97297297297297\n",
            "Epoch 389: \tLoss = 21.754914833930847 \tAccuracy = 72.97297297297297\n",
            "Epoch 390: \tLoss = 21.751299921552622 \tAccuracy = 72.97297297297297\n",
            "Epoch 391: \tLoss = 21.7465587670849 \tAccuracy = 72.97297297297297\n",
            "Epoch 392: \tLoss = 21.74294234009029 \tAccuracy = 72.97297297297297\n",
            "Epoch 393: \tLoss = 21.7382533852865 \tAccuracy = 72.97297297297297\n",
            "Epoch 394: \tLoss = 21.73460909420502 \tAccuracy = 72.97297297297297\n",
            "Epoch 395: \tLoss = 21.729997310165572 \tAccuracy = 72.97297297297297\n",
            "Epoch 396: \tLoss = 21.72537429571807 \tAccuracy = 72.97297297297297\n",
            "Epoch 397: \tLoss = 21.72256088448535 \tAccuracy = 72.97297297297297\n",
            "Epoch 398: \tLoss = 21.717530363540416 \tAccuracy = 72.97297297297297\n",
            "Epoch 399: \tLoss = 21.714314761131355 \tAccuracy = 72.97297297297297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "70y0GY64zaAM",
        "outputId": "46f6097c-7c39-4bb6-fba1-d4e30bcfc7f0"
      },
      "source": [
        "plot_loss_and_accuracy(loss, acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU9Z3/8dd3enruiwEdUVAg4kGQAQc0nuHwiomCURON8VpXDCa6UeNK8ts1xrjmMObQ3f1Ff5uNhCCobIyu8ViVIRuDAiKHEu5L7mNmYO6je76/P6p66Jnpmekepo+aeT8fj35019nvKZpPVX+76lvGWouIiHhPWrIDiIhI76iAi4h4lAq4iIhHqYCLiHiUCriIiEelJ/LNhgwZYkeMGNGrZevq6sjNze3bQH1AuWKTqrkgdbMpV2z6Y64VK1YcstYe12mCtTZhj7KyMttb5eXlvV42npQrNqmay9rUzaZcsemPuYAPbYSaqiYUERGPUgEXEfEoFXAREY9SARcR8SgVcBERj1IBFxHxKBVwERGPSuiFPCIinrLhDdj9UZ+syh8Y2yfrCacCLiLSlVfvhboDgDnmVfkn/eux5+lABVxEJBJrob4CLnoApj18zKurX7z42DN1oDZwEZFImqrBBiF7ULKTdEkFXEQkkvpK5zm7OLk5uqECLiISSYNbwHNUwEVEvKWhynlWE4qIiMfUhwq4jsBFRLxFTSgiIh4VakLJKkpujm70eB64MeZ04IWwUaOAh4HfueNHANuBr1hrq/o+oohInDRWQ7A58rTqPZBZCL7UvVymx2TW2g3AeABjjA/YDbwMzAbetdb+2Bgz2x1+KI5ZRUT6zt7V8OxksK1dzzP41ITF6Y1Ydy3TgC3W2h3GmOnAZHf8HGAxKuAi4hWHdzrF+8L7oOCkyPOcOCGxmWJknPtlRjmzMf8JfGSt/VdjzGFrbZE73gBVoeEOy8wEZgKUlJSULViwoFdBa2trycvL69Wy8aRcsUnVXJC62ZQrNtHmOn7//zJm3ZMsm/Rv1OcOS5lckUyZMmWFtXZipwmR7nQc6QFkAIeAEnf4cIfpVT2tQ3elTxzlil2qZlOu2ESda8Uca79fYG3Vp3HNE5Lsu9J/Aefoe787vN8YMxTAfT7Qq12LiEgytDQ6z/7s5OY4BrEU8BuB+WHDrwK3uq9vBV7pq1AiInEXaHCe+3sBN8bkApcCfwgb/WPgUmPMJuASd1hExBta3AKe7t0CHtVZKNbaOmBwh3EVOGeliIh4T0sD+DIgzbvXM3o3uYjIsWhp8HTzCaiAi8hAFWjwdPMJ6JZq0Qu2wJuznVsshRlz4AAcfC7yMqMvg/Ffi3+2vrL+dfj4xbi+RbfbK8lSNVu/zTX+6zD6kj7LE7OWRs8fgauAR+vgBlj+H5B/ImQePRk/t74e9h/sPH/1XjiwzlsFfNkz8OlSKBoet7focnulgFTN1i9zVe2AQFOSC3i9CviAEeqZ7Jpfw6jPt41evngxkydP7jz/q/fAxrcSk62vNFTByIvhpvgdhXe5vVJAqmbrl7me+9LR/1PJEmiE9KzkZjhGagOPVqx9A2cXO/fUi6GrgqSrr0rpu49IP5I96Og9J5OlpQH8OcnNcIxUwKMV6w1Oc4qhtQWaa+OXqa81VKZ05/XSj+QUHz0oSpaWBvDrCHxgCH3di+UIPHy5VBdodnY2KXz7KOlHsoud/xvJ/IaqJpQBpKHS+ceO9kePUFNEsr8mRqutiUhNKJIA2YOgNQBNNcnL0FKvJpQBo74qtqPT0JF6sr8mRivWJiKRY5EK/z9aGtWEMmDE2j4cKoSeOQIP3YFbR+CSAKnw/0M/Yg4gDTGeoRGa1ytt4B64A7f0I6nw/yPQ4Pk2cJ0HHq6uAg5tiDyteg8MLY1+XaEP6L41sGPJsWeLUeHhtbAjI/oFdq9wntWEIokQOlDYtbzPL6aJ6rNvrXMzY13I048svB22/bnr6adfGf260jMg93j46HfOI8EmAKyKcSFfBuQOiUMakQ7yjgfjg8U/ch59KKbPfs7gnudJYSrg4ap3w4iL4OLvRJho4KSzY1vfHW/B4U/7JFqsVq1ezfjSGL4xAOSd4PkjEvGI7EHwjfegru9v5BX1Zz8tHYad0+fvn0gq4OHqK2Hk52HU5L5ZX/Eo55EEhz+l7/4OkXgoGQOM6fPVDqTPvn7EDGlthcbD+hFPRDxDBTyk8TDYVv2IJyKeoQIeovOgRcRjVMBDYu3rREQkyVTAQ3QpuYh4jAp4iI7ARcRjVMBDQpeSqw1cRDxC54G3BmHBTe6l5AayCpOdSEQkKjoCb6iCjW84l/Z+/h8hzZfsRCIiUdEReEu983zuN+Dsm5ObRUQkBjoCb2l0ntUHiIh4jAp4oMF5VgEXEY9RAW9xC7jHO3YXkYEnqgJujCkyxiw0xqw3xqwzxpxnjCk2xrxtjNnkPnvz/LsWHYGLiDdFewT+K+BNa+0ZQCmwDpgNvGutHQ286w57T0Bt4CLiTT0WcGNMIXAx8BsAa22ztfYwMB2Y4842B5gRr5BxFToLJV0FXES8xVhru5/BmPHAs8DfcI6+VwD/AOy21ha58xigKjTcYfmZwEyAkpKSsgULFvQqaG1tLXl5eb1atjsn7H2XMzY8xQfnPktjdknK5DpWyhW7VM2mXLHpj7mmTJmywlo7sdMEa223D2AiEADOdYd/BfwQONxhvqqe1lVWVmZ7q7y8vNfLRtRcb+2q+db+153Wfr/A2pr9qZGrjyhX7FI1m3LFpj/mAj60EWpqNBfy7AJ2WWuXusMLcdq79xtjhlpr9xpjhgJ9f3O7eFr/J3j5rqPDOgtFRDymxzZwa+0+YKcx5nR31DSc5pRXgVvdcbcCr8QlYbzUdtjf6EdMEfGYaC+lvweYZ4zJALYCt+MU/xeNMXcAO4CvxCdinIR6Hwzx+ZOTQ0Skl6Iq4NbaVTht4R1N69s4CVRf2fM8IiIpbOBeiRm6gYOIiEcN4AJeCWbg/vki4n0Dt4LVV8LgU5OdQkSk1wZuAW+oguLPJDuFiEivDewCPuiUZKcQEem1gVnAA83QXAs5Q5KdRESk1/rHLdX2roE5X3LurvO5b8Clj3aep74S/v089+wTt/+XnOKExhQR6Uv9o4Af2giNRyCzAHYuizxPxRao3QefvQaKTgFfBoyZDkNO053oRcST+kcBD92UYfCpXV+gE7ry8rxvwbCwa5JGXhTfbCIicdI/2sBDBbzgxM6XyIeECnu2N28cJCLSUf8o4KEbExec5LRxR+rjPHTlpdq9RaSf6B8FvMW9LVrBUGgNQFNN53lCV15mqr1bRPqHflLA650fJXOPc4YjNaPUV0JWEaT1jz9ZRKR/VLNAo3NPy2y3eSTSD5kNlWo+EZF+pX8U8JYG8GcdLdCRehpsqDpa4EVE+oF+VMCzj55hEqmA11fqDBQR6Ve8dx74rhWw9g9Hh08qc85CCW9CWTkX9qxsv1zVDij5bOJyiojEmfcK+F9/AeteA38OBJsgZzCcMO5oE0rJWbBzufMIZwwMPzc5mUVE4sB7Bby+Ek45H25/Hd6YDavmuU0oOZDmg1nvJTuhiEhCeK8NPLwt25/tnEIYaID0rOTmEhFJMO8V8PDTAf3ZRy/c8WcnN5eISIJ5q4Bb6x6BhxVwcM46UQEXkQHGWwW8uRZaW44egYeaTeor1YQiIgOOtwp46Pzu8DZwABvUEbiIDDjeKuBtXcJ2aELp+FpEZADwVgEPdVLV1oQSVrTTVcBFZGDxzHngvkADHNrpDLQdgYe1e/vVBi4iA4tnCvjED78NjfucgVC3sf6cozOEvxZJMS0tLezatYvGxsaYly0sLGTdunVxSHVslCs20eTKyspi2LBh+P3+qNbpmQKe2XQQTrsCzpkJuYOdkeFnnmQVJSeYSBR27dpFfn4+I0aMwBgT07I1NTXk5+fHKVnvKVdsesplraWiooJdu3YxcuTIqNbpjTbwYAtpNggnTYRTpx0dH37Urb6+JYU1NjYyePDgmIu3DBzGGAYPHhzTt7SojsCNMduBGiAIBKy1E40xxcALwAhgO/AVa22Eflz7QOimxR3bucOH1VWspDgVb+lJrJ+RWI7Ap1hrx1trJ7rDs4F3rbWjgXfd4fgIuHukjhfrhJ95ogIu0i2fz8f48eMpLS3l7LPPZsmSJQDs2bOH6667LsnpUs/27dt5/vnnkx2jW8fShDIdmOO+ngPMOPY4XWipd547/lAZfu63mlBEupWdnc2qVatYvXo1P/rRj/jud78LwIknnsjChQv75D2CwWCfrCcQCPTJeo5FdwU8FfJB9D9iWuB/jDEWeMZa+yxQYq3d607fB5REWtAYMxOYCVBSUsLixYtjDplT9ynnAGs3beXgkbDlbZDJ7svFH6x07jqfYLW1tb36m+JNuWIXz2yFhYXU1NT0atlgMNjrZTsKrWf//v3k5+dTU1PDjh07+MpXvsLSpUuZN28er7/+OvX19Wzbto2rrrqKH/7whwDcd999fPTRRzQ0NDB9+nRmz55NTU0NY8eO5ctf/jLl5eVcffXVvPrqq/zlL38BYPPmzdx+++1twyFbtmzhvvvu49ChQ/h8PubMmcPu3bt57LHHKCoqYuPGjbz//vvcd999rFy5kvT0dB5//HEuvvhi1q1bx6xZs2hpaaG1tZW5c+cydOhQbr31Vvbs2UMgEOChhx7i2muvbfeeW7du5YEHHqCiooLs7GyefvppTjvtNL7xjW+Qn5/PypUrOXDgAI8++igzZszgwQcfZOPGjYwbN44bb7yRQYMG8eqrr1JXV0cwGGTevHl885vfZPv27WRnZ/PUU08xduxYHn/8cbZt28bWrVupqKjg29/+Nrfddht33nkn06dP50tf+hIAd9xxB1/+8pf54he/2C5nY2Nj1J/DaAv4hdba3caY44G3jTHrwydaa61b3Dtxi/2zABMnTrSTJ0+O8i3D7FkJy+Gz48rgjA7L/9l5mjxlauzr7QOLFy+mV39TnClX7OKZbd26dW1nIPzgv9fytz3VUS8bDAbx+XzdzjPmxAK+f1X3d5xqaGjgoosuorGxkb1797Jo0SLy8/PJy8sjLS2N/Px8srKy+OSTT1i5ciWZmZmcfvrpPPDAAwwfPpyf/vSnFBcXEwwGmTZtGuvWreO8887DGMPQoUNZtWoVAH/5y1/YsmUL48eP56WXXuKOO+7odPbFXXfdxezZs7nmmmtobGyktbWVqqoqVq9ezSeffMLIkSN58sknycjIYO3ataxfv57LLruMjRs3MnfuXO6//35uuukmmpubCQaDvP7665x88sm89dZb1NTU0Nra2uk977//fn79618zevRoli5dyoMPPsiiRYvw+/1UVFTw/vvvs379eq6++mpuvvlmnnjiCX72s5/x2muvAfDcc8+xZs0a1qxZQ3FxMffccw+TJk3itddeY9GiRcyaNYtVq1aRmZnJunXr+OCDD6irq2PChAlce+213HrrrTzzzDPceOONHDlyhOXLl/P888+Tnt6+DGdlZTFhwoSoPhtRHbJaa3e7zweAl4FzgP3GmKEA7vOBqN6xN9p+xNTVliK9FWpCWb9+PW+++Sa33HIL1nY+7po2bRqFhYVkZWUxZswYduzYAcCLL77I2WefzYQJE9qKashXv/rVttd///d/z29/+1uCwSAvvPACX/va19qtv6amht27d3PNNdcATsHKyXGaR88555y2U+jee+89vv71rwNwxhlncMopp7Bx40bOO+88Hn/8cX7yk5+wY8cOsrOzOeuss3j77bd56KGHWLJkCYWFhe3es7a2liVLlnD99dczfvx47rrrLvbu3ds2fcaMGaSlpTFmzBj279/f5Ta89NJLKS4ubst38803AzB16lQqKiqornZ2zNOnTyc7O5shQ4YwZcoUli1bxoUXXsimTZs4ePAg8+fP59prr+1UvGPV49LGmFwgzVpb476+DHgUeBW4Ffix+/zKMSXpjgq49CM9HSl3FI/zms877zwOHTrEwYMHO03LzMxse+3z+QgEAmzbto2f/exnLF++nEGDBnHbbbfR1NTUNl9ubm7b62uvvZYf/OAHTJ06lbKyMgYPHhx1rvD1dOVrX/sa5557Ln/605+48soreeaZZ5g6dSofffQRr7/+Oj/84Q9ZunQpDz/8cNsyra2tFBUVtX1L6O5vjrRTiyUfdD6bJDR8yy238Pvf/54FCxbw29/+Nqp1dSeaI/AS4D1jzGpgGfAna+2bOIX7UmPMJuASdzg+ujoLRUR6Zf369QSDwaiLa3V1Nbm5uRQWFrJ//37eeOONLufNysri8ssvZ9asWdx+++2dpufn5zNs2DD++Mc/AtDU1ER9fX2n+S666CLmzZsHwMaNG/n00085/fTT2bp1K6NGjeLee+9l+vTprFmzhj179pCTk8PXv/517r33Xj766KN26yooKGDkyJG89NJLgFOkV69e3e3fHPqNoCvh+RYvXsyQIUMoKCgA4JVXXqGxsZGKigoWL17MpEmTALjtttv45S9/CcCYMWO6ff9o9HgEbq3dCpRGGF8BTOu8RBy0HYFHuFx+2sNQODwhMUS8rKGhgfHjxwNOAZszZ06PbeshpaWlTJgwgTPOOIPhw4dzwQUXdDv/TTfdxMsvv8xll10WcfrcuXO56667ePjhh/H7/W2FNdzdd9/NrFmzOOuss0hPT+e5554jMzOTF198kblz5+L3+znhhBP43ve+x/Lly3nwwQdJS0sjLS2NZ599ttP65s2bx6xZs3jsscdoaWnhhhtuoLS0U2lrM27cOHw+H6Wlpdx2220MGtT+VOVHHnmEv/u7v2PcuHHk5OQwZ86cdstOmTKFQ4cO8c///M+ceOKJ1NTUUFJSwplnnsmMGX100p61NmGPsrIy2ysrfmft9wusrdrRu+XjqLy8PNkRIlKu2MUz29/+9rdeL1tdXd2HSfpOd7meeOIJ+0//9E8JTHNUsrfX97//ffvEE090Gl9dXW3r6ursqFGj7OHDh7tcPtJnBfjQRqip3ugLJXQEri5jRVLeNddcw5YtW1i0aFGyo6SU8vJy7rnnHu67775OP7L2ljcKeEA/Yop4xcsvv5zsCEn1yCOPRBw/ZcqUtjN6+oo3OrNqcX/EVAEXEWnjkQJeT6tJh7TofnARERkIvFHAA420pmX2PJ+IyADijQLe0kDQl5HsFCIiKcUzBVxH4CLH7o9//CPGmHaXwYt3eaOABxpoTdMRuMixmj9/PhdeeCHz58+P23v0VZey0jNvFPCWRjWhiByj2tpa3nvvPX7zm9+wYMECwCm23/nOdxg7dizjxo3j6aefBmD58uWcf/75lJaWcs4551BTU8Nzzz3Ht771rbb1XX/99W3dnubl5fHAAw9QWlrK+++/z6OPPsqkSZMYO3YsM2fObOtfZPPmzVxyySVtN5XYsmULt9xyS9tl9eBcxfnKK/HrWqk/8cZ54Ff8iA0f/JVJyc4h0hfemA37Po569uxgAHw9/Fc94Sz4QvfdEb3yyitcccUVnHbaaQwePJgVK1awbNkytm/fzqpVq0hPT6eyspLm5ma++tWv8sILLzBp0iSqq6vJzu7+FN66ujrOPfdcnnzyScDp5yPUmdTNN9/Ma6+9xlVXXcVNN93UqRvZO+64g1/84hfMmDGDI0eOsGTJknaXpUvXvHEEPmQ0dXkjkp1CxNPmz5/PDTfcAMANN9zA/Pnzeeedd7jrrrvaujUtLi5mw4YNDB06tK0DpoKCgh67PfX5fO1uoFBeXs65557LWWedxaJFi1i7dm2X3ch+/vOf7/NuVgcKbSWRROvhSLmjhj7oTrayspJFixbx8ccfY4whGAxijGkr0tFIT0+ntbW1bTi8O9msrKy2jrEaGxu5++67+fDDDxk+fDiPPPJIj3da7+tuVgcKbxyBi8gxWbhwITfffDM7duxg+/bt7Ny5k5EjR1JaWsozzzzTdo/HyspKTj/9dPbu3cvy5csBpz/yQCDAiBEjWLVqFa2trezcuZMVK1ZEfK9QsR4yZAi1tbVt99vsrhvZvu5mdaBQARcZAObPn9/WdBFy7bXXsnfvXk4++WTGjRtHaWkpzz//PBkZGbzwwgvcc889lJaWcumll9LY2MgFF1zAyJEjGTNmDPfee2+XXbEWFRVx5513MnbsWC6//PJ2R/lz587lqaeeYty4cZx//vns27cPoK2b1Uj9h0vX1IQiMgCUl5d3Gnfvvfe2vf75z3/ebtqkSZP44IMPOi0TuoEBtL9TUG1tbbv5HnvsMR577LFOy48ePTpiL4X19fVs2rSJG2+8sYe/RMLpCFxEkuqdd97hzDPP5J577umzblYHCh2Bi0hSXXLJJX3ezepAoSNwERGPUgEXSZDQ1YgiXYn1M6ICLpIAWVlZVFRUqIhLl6y1VFRUkJWVFfUyagMXSYBhw4axa9cuDh48GPOyjY2NMf2nThTlik00ubKyshg2bFjU61QBF0kAv9/PyJEje7Xs4sWLmTBhQh8nOnbKFZt45FITioiIR6mAi4h4lAq4iIhHqYCLiHiUCriIiEepgIuIeFTUBdwY4zPGrDTGvOYOjzTGLDXGbDbGvGCM0U0rRUQSKJYj8H8A1oUN/wT4hbX2VKAKuKMvg4mISPeiKuDGmGHAF4H/cIcNMBVY6M4yB5gRj4AiIhKZiaZvBmPMQuBHQD7wHeA24AP36BtjzHDgDWvt2AjLzgRmApSUlJQtWLCgV0Fra2vJy8vr1bLxpFyxSdVckLrZlCs2/THXlClTVlhrJ3aaYK3t9gF8Cfh39/Vk4DVgCLA5bJ7hwCc9rausrMz2Vnl5ea+XjSflik2q5rI2dbMpV2z6Yy7gQxuhpkbTF8oFwNXGmCuBLKAA+BVQZIxJt9YGgGHA7l7tWkREpFd6bAO31n7XWjvMWjsCuAFYZK29CSgHrnNnuxV4JW4pRUSkk2M5D/wh4H5jzGZgMPCbvokkIiLRiKk7WWvtYmCx+3orcE7fRxIRkWjoSkwREY9SARcR8SgVcBERj1IBFxHxKBVwERGPUgEXEfEoFXAREY9SARcR8SgVcBERj1IBFxHxKBVwERGPUgEXEfEoFXAREY9SARcR8SgVcBERj1IBFxHxKBVwERGPUgEXEfEoFXAREY9SARcR8SgVcBERj1IBFxHxKBVwERGPUgEXEfEoFXAREY9SARcR8SgVcBERj1IBFxHxKBVwERGPUgEXEfGoHgu4MSbLGLPMGLPaGLPWGPMDd/xIY8xSY8xmY8wLxpiM+McVEZGQaI7Am4Cp1tpSYDxwhTHmc8BPgF9Ya08FqoA74hdTREQ66rGAW0etO+h3HxaYCix0x88BZsQloYiIRGSstT3PZIwPWAGcCvwb8ATwgXv0jTFmOPCGtXZshGVnAjMBSkpKyhYsWNCroLW1teTl5fVq2XhSrtikai5I3WzKFZv+mGvKlCkrrLUTO02w1kb9AIqAcuBCYHPY+OHAJz0tX1ZWZnurvLzcWmtta2ur/fOGA3b1zqper6svhXKlGuWKXapmU67Y9MdcwIc2Qk2N6SwUa+1ht4CfBxQZY9LdScOA3b3atcTIGMODC1fz3JLtiXg7EZGUFc1ZKMcZY4rc19nApcA6nEJ+nTvbrcAr8QrZ0Wkl+WzcX5OotxMRSUnRHIEPBcqNMWuA5cDb1trXgIeA+40xm4HBwG/iF7O90cfns/lALa2tPbffi4j0V+k9zWCtXQNMiDB+K3BOPEL15PQT8mhsaWVnVT2nDM5NRgQRkaTz5JWYo0vyAVi3V80oIjJwebKAjxlaQE6Gj//ddDDZUUREksaTBTzL72PqGcfz1if7CARbkx1HRCQpPFnAAa4qPZGKumbeWrs/2VFERJLCswX8kjNLGDUkl6cXbdJRuIgMSJ4t4L40w4OXn876fTX8a/nmZMcREUk4zxZwgCvGnsCM8Sfyy3c28cyftyQ7johIQvV4HngqM8bwxPWlBFotP3pjPRv31/KD6Z8lL9PTf5aISFQ8X+n8vjR++dXxfOa4PJ5etIm/bj7E/ZedxjUTTsLv8/QXDBGRbvWLCpfuS+O+S09j4azzKSnM4h8XruGin5Tz9Lub2HukIdnxRETiwvNH4OHOPnkQf7z7fBatP8BzS7bz5NsbefLtjZQOL+ILY09g8unHcdrx+aSlmWRHFRE5Zv2qgIPTLj7tzBKmnVnCtkN1vP7xXt78ZB8/fmM9P35jPYNy/Jw7cjDnjipm/PAizhxaQJbfl+zYIiIx63cFPNzIIbl8c8qpfHPKqew+3MCSzYf4YGslS7dV8ObafYBzOuLo4/M466RCzhpWyJlDCzj1uDwG5eoezSKS2vp1AQ93UlE2108czvUThwOw+3ADH+86zMe7j/Dx7mreXX+Al1bsapt/SF4Gnzkuj1OPdx6jj8/nlME5nFCYpR9HRSQlDJgC3tFJRdmcVJTNFWOHAs6t5fYeaWTDvho2H6hl0wHn+b9X76G6MdC2nDFQkp/FSYOyObEom2B1Mzszt1NSkMVx+ZkcX5DFkLwMMtPVLCMi8TVgC3hHxhhOLHKK8pQzjm8bb63lYE0Tmw/UsrOqnt2HG9ld1cCeww2s3nmY3VUtvL5tbaf1FeX4OS4vk+MLMjkuL9Mp7vlOkR+Um8Hg3AwG5WZQnJNBdoaKvYjETgW8B8YYji/I4viCrIjTF5WX89my8zhQ3cTB2kbnuaaJAzXO88HaJlZ8WsWB6iaaApH7bMnyp1Gc4xb03AwG5YQ/+xnkvi7I8lOQnU5htp/8LD8+nU0jMqCpgB+jNGMoKciipCALKOxyPmstNU0BDtY0cbi+mcq6Fqrqmqmsb6ayznmEhndW1lNZ19yu6SaSvMx0CrLSKcj2O48sP4XZTpGv3NfM1vRtFGT7ycv0kZuZTk5GOnmZ6eRm+tzndLXni3iYCniCGGOcI+gsf9TLtARbOVzfQlW9U9yrGwNUN7RwpKGF6sYWqhsCYa9b2FVVz7q9zrjapgCvbPlbj++R4Usj1y3woaKek3G0wIcK/tHin06eOxyanpPhI8vvI8ufRrbfR7p2CiIJoQKewvy+NI7Ldzq0vA0AAAnmSURBVNrPY/XuonLKPndBWzGvbw5S2xSgru0RpK4pQG2zM1zf5E5vDlDdGGDfkUZnelOAuuYgwRhuIJ2eZsj2+8gMK+pZfh/Zfh/1NY3M+/RDd9zRaZnu9PBxoZ1CVtu0o/OE5vf7DMaoKUkGJhXwfsqXZijKyaAo59jPZ7fW0hRoPVr43aJf6w7XNwdoDLTS1BKkoTlIYyBIQ3MrjYEgje5wY0srDc1BGgKWnZX1NAVaw+YNdvn7QE/SDN0W/M7j0sJ2Lj4y09PISE8jMz2NTfsC2PUHyAgb5zz7nHG+NDL97nN6mnYcknQq4NIjY0xbMRycd2zrWrx4MZMnX9xpfGurpTnYvqg3trTS0BKkqSVsp9ASpKElSGPbI3xca9v4hhZnx1JZ19xuXGidXVq1POq/JcPXsdCnhRV/X7uCH74jyIy0jM/5VtFxmYz0NDZVBSnedRi/Lw2/u/NwXhv87rIZvjR1ETEAqYBLSkhLM2Sl+RLSrUHoG0VjS5DmQCtN7mPJB0s5a/zZNAdaaQ620tTiPgec+cLnbW73HOxymfq6QLv5ndfON47mYCs22pappX/tcRZfmsHvM23FP1TwQ68zfKbdsPPamd/vSzu6M0h3dw6ddhjO+NAOZ/2BAGbjQXcZ0+79Mtq9t/u+2sn0ORVwGXDCv1GE21XgY8LJgxKWw1pLS9D55hG+I2i/Y7CsWLmSMz97VttOoiVoaXGXaQm64wKW5mDQWV9ovPsc/h7OcCt1zcF2wy3uup1xzvoD0fzu8dGymP7m9DQTuYkqvHkq7JtIZoTx2Rk+cjJ85Gakk53hIzfTR7Y/9GO7j4qGVg7XN5OTkU5Gev/+QV0FXCRJjDHOEXB6GnTzO3XTznQmn1mSuGCuYKttK/DhhT1U6D9Ytpxx4yfQHLDuTqS13fTQ/C1BZ6cUWk/HbyuhnVXoG0p1Q0v7byphO7XGQDC6by1/fhtwdhg5Gc5ZUzlugc/JSG+/A8jwkZ2R7j772s7ECs2X444PfYtI9xnS046+Dn0zScZvIirgIhKRL83g66ZZa3+hj7JTihOaKdT8Vd/s/MbR0Bykzn1d3xSkviXIyjVrGT7yVGdcc7Bt3rpm57eVuibnt5GdlfVtyzc0B2k+xpujp6cZp6CnOc1R6WlHi7vfl8adZ/T9zddVwEXEM8Kbv4q76DG0oGojky8cGfO6W4JHdwz1zUFnhxC2Ewi0hjUvBVtpDloCblNTc6C13XRnHhvWHNWKP+3Isf75naiAi4jgXHdRmJ1GYXb0F9vFYvHixX2+zv7dwi8i0o/1WMCNMcONMeXGmL8ZY9YaY/7BHV9sjHnbGLPJfU7cz/ciIhLVEXgAeMBaOwb4HPBNY8wYYDbwrrV2NPCuOywiIgnSYwG31u611n7kvq4B1gEnAdOBOe5sc4AZ8QopIiKdxdQGbowZAUwAlgIl1tq97qR9QOJPVBURGcCMjfJaXmNMHvBn4F+stX8wxhy21haFTa+y1nZqBzfGzARmApSUlJQtWLCgV0Fra2vJyzvGjjjiQLlik6q5IHWzKVds+mOuKVOmrLDWTuw0wVrb4wPwA28B94eN2wAMdV8PBTb0tJ6ysjLbW+Xl5b1eNp6UKzapmsva1M2mXLHpj7mAD22EmhrNWSgG+A2wzlr787BJrwK3uq9vBV7p1a5FRER6pccmFGPMhcBfgI+B0LWg38NpB38ROBnYAXzFWlvZw7oOuvP2xhDgUC+XjSflik2q5oLUzaZcsemPuU6x1h7XcWTUbeDJZoz50EZqA0oy5YpNquaC1M2mXLEZSLl0JaaIiEepgIuIeJSXCvizyQ7QBeWKTarmgtTNplyxGTC5PNMGLiIi7XnpCFxERMKogIuIeJQnCrgx5gpjzAZjzGZjTFJ7PTTGbDfGfGyMWWWM+dAdl/CudY0x/2mMOWCM+SRsXMQcxvGUu/3WGGPOTnCuR4wxu91ttsoYc2XYtO+6uTYYYy6PY66YukVO1DbrJldSt5kxJssYs8wYs9rN9QN3/EhjzFL3/V8wxmS44zPd4c3u9BEJzvWcMWZb2PYa745P2GfffT+fMWalMeY1dzi+2yvS5Zmp9AB8wBZgFJABrAbGJDHPdmBIh3E/BWa7r2cDP0lAjouBs4FPesoBXAm8ARicLoGXJjjXI8B3Isw7xv33zARGuv/OvjjlGgqc7b7OBza675/UbdZNrqRuM/fvznNf+3Eu3PsczsV7N7jjfw3Mcl/fDfzafX0D8EKctldXuZ4Droswf8I+++773Q88D7zmDsd1e3nhCPwcYLO1dqu1thlYgNOVbSpJeNe61tr/BTpe+dpVjunA76zjA6DIGDM0gbm6Mh1YYK1tstZuAzbj/HvHI1es3SInZJt1k6srCdlm7t9d6w763YcFpgIL3fEdt1doOy4EphnT97dp7yZXVxL22TfGDAO+CPyHO2yI8/byQgE/CdgZNryL7j/g8WaB/zHGrDBOT4uQOl3rdpUjFbbht9yvsP8Z1sSUlFwmum6RE56tQy5I8jZzmwNWAQeAt3GO9g9bawMR3rstlzv9CDA4EbmstaHt9S/u9vqFMSazY64ImfvaL4F/5GiXI4OJ8/byQgFPNRdaa88GvoBzd6KLwyda5ztR0s/NTJUcrv8LfAYYD+wFnkxWEON0i/xfwLettdXh05K5zSLkSvo2s9YGrbXjgWE4R/lnJDpDJB1zGWPGAt/FyTcJKAYeSmQmY8yXgAPW2hWJfF8vFPDdwPCw4WHuuKSw1u52nw8AL+N8sPeHvpa5zweSFK+rHEndhtba/e5/ulbg/3H0K39Ccxlj/DhFcp619g/u6KRvs0i5UmWbuVkOA+XAeThNEOkR3rstlzu9EKhIUK4r3KYoa61tAn5L4rfXBcDVxpjtOM28U4FfEeft5YUCvhwY7f6am4HT4P9qMoIYY3KNMfmh18BlwCekTte6XeV4FbjF/UX+c8CRsGaDuOvQ5ngNzjYL5brB/UV+JDAaWBanDLF2i5yQbdZVrmRvM2PMccaYIvd1NnApTvt8OXCdO1vH7RXajtcBi9xvNInItT5sJ2xw2pnDt1fc/x2ttd+11g6z1o7AqVGLrLU3Ee/t1Ze/wMbrgfNL8kacNrj/k8Qco3DOAFgNrA1lwWm7ehfYBLwDFCcgy3ycr9YtOG1rd3SVA+cX+H9zt9/HwMQE55rrvu8a94M7NGz+/+Pm2gB8IY65LsRpHlkDrHIfVyZ7m3WTK6nbDBgHrHTf/xPg4bD/A8twfjx9Cch0x2e5w5vd6aMSnGuRu70+AX7P0TNVEvbZD8s4maNnocR1e+lSehERj/JCE4qIiESgAi4i4lEq4CIiHqUCLiLiUSrgIiIepQIuIuJRKuAiIh71/wFtfL8INNBAwAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbOvOJ25zaAM"
      },
      "source": [
        "y_pred = mlp.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbXTcMMAzaAM",
        "outputId": "d75c4790-495f-4f7f-fe98-028ae6623503"
      },
      "source": [
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.80      1.00      0.89         8\n",
            "\n",
            "    accuracy                           0.85        13\n",
            "   macro avg       0.90      0.80      0.82        13\n",
            "weighted avg       0.88      0.85      0.84        13\n",
            "\n"
          ]
        }
      ]
    }
  ]
}