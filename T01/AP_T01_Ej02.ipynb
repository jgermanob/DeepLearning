{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retropropagación en red densa\n",
    "Programa el algoritmo de retropropagación usando NumPy para una tarea de clasificación binaria presuponiendo una red densa con dos capas ocultas y la función de pérdida de entropía cruzada\n",
    "binaria. Describe las fórmulas y reglas de actualización de los pesos y sesgos de cada capa y entrena\n",
    "y evalúa la red en algún conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una red densa con $x_1,\\dots x_n$ entradas, dos capas ocultas con $a$ neuronas cada una y una capa de salida con una neurona. Como funciones de activación es posible utilizar la función sigmoide o la función ReLU, las cuales se utilizan tanto en las capas ocultas como en la capa de salida. Para el ejemplo con el conjunto de datos de calificaciones se tienen 2 entradas y 5 neuronas en cada capa oculta.\n",
    "\n",
    "La función sigmoide se define como:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "La derivada de la función sigmoide se define como:\n",
    "$$\n",
    "\\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma(z) (1 - \\sigma(z))\n",
    "$$\n",
    "\n",
    "Por su parte, la función ReLU se define como:\n",
    "$$\n",
    "ReLU(z) = \\max\\{0,z\\}\n",
    "$$\n",
    "\n",
    "La derivada de la función ReLU se define como:\n",
    "$$\n",
    "\\frac{\\partial ReLU(z)}{\\partial z} = \\begin{cases} \n",
    "0 & \\text{if  }  x \\leq 0 \\\\\n",
    "1 & \\text{if  }  x > 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Se utiliza la entropía cruzada binaria como función de pérdida, la cual se define como:\n",
    "$$\n",
    "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_dim, hidden_units, activation='relu'):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        if activation=='sigmoid':\n",
    "            self.activation = self._sigmoid\n",
    "            self.derivative = self._derivative_sigmoid\n",
    "        else:\n",
    "            self.activation = self._relu\n",
    "            self.derivative = self._derivative_relu          \n",
    "    \n",
    "    def _weighted_sum(self, w, a, b):\n",
    "        return np.dot(w.T, a) + b\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _relu(self, z):\n",
    "        return np.maximum(0,z)\n",
    "    \n",
    "    def _derivative_relu(self, x):\n",
    "        return np.heaviside(x,0)\n",
    "    \n",
    "    def _derivative_sigmoid(self, x):\n",
    "        return np.multiply(self._sigmoid(x), (1.0 - self._sigmoid(x)))\n",
    "    \n",
    "    def _binary_crossEntropy(self, y, p):\n",
    "        p[p == 0] = np.nextafter(0., 1.)\n",
    "        p[p == 1] = np.nextafter(1., 0.)\n",
    "        return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())\n",
    "    \n",
    "    def _accuracy(self, y, y_predicted):\n",
    "        return (y == y_predicted).mean() * 100\n",
    "    \n",
    "    def _forward_pass(self, x, w1, b1, w2, b2, w3, b3):\n",
    "        a1 = x[:, np.newaxis]\n",
    "        z2 = self._weighted_sum(w1, a1, b1)\n",
    "        a2 = self.activation(z2)\n",
    "        z3 = self._weighted_sum(w2, a2, b2)\n",
    "        a3 = self.activation(z3)\n",
    "        z4 = self._weighted_sum(w3, a3, b3)\n",
    "        y_hat = self.activation(z4)\n",
    "        return z2, a2, z3, a3, z4, y_hat\n",
    "    \n",
    "    def _backpropagation(self, x, y, learning_rate, epochs):\n",
    "        # Capa oculta 1 #\n",
    "        self.w1 = np.sqrt(1.0 / self.input_dim) * np.random.randn(self.input_dim, self.hidden_units)\n",
    "        self.b1 = np.zeros((self.hidden_units, 1))\n",
    "        \n",
    "        # Capa oculta 2 #\n",
    "        self.w2 = np.sqrt(1.0 / self.hidden_units) * np.random.randn(self.hidden_units, self.hidden_units)\n",
    "        self.b2 = np.zeros((self.hidden_units, 1))\n",
    "        \n",
    "        # Capa de salida #\n",
    "        self.w3 = np.sqrt(1.0 / self.hidden_units) * np.random.randn(self.hidden_units, 1)\n",
    "        self.b3 = np.zeros((1, 1))\n",
    "        \n",
    "        losses = np.zeros((epochs))\n",
    "        accuracies = np.zeros((epochs))\n",
    "        y_predicted = np.zeros((y.shape))\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for j in range(x.shape[0]):\n",
    "                z2, a2, z3, a3, z4, y_hat = self._forward_pass(x[j], self.w1, self.b1, self.w2, self.b2, self.w3, self.b3)\n",
    "                # Gradientes para w3 y b3 por retropropagación #\n",
    "                dz4 = y_hat - y[j]\n",
    "                dw3 = np.outer(a3, dz4)\n",
    "                db3 = dz4\n",
    "                \n",
    "                # Gradiente para w2 y b2 por retropropagación #\n",
    "                dz3 = np.dot(self.w3, dz4) * self.derivative(z3)\n",
    "                dw2 = np.outer(a2, dz3)\n",
    "                db2 = dz3\n",
    "                \n",
    "                # Gradiente para w1 y b1 por retropropagación #\n",
    "                dz2 = np.dot(self.w2, dz3) * self.derivative(z2)\n",
    "                dw1 = np.outer(x[j], dz2)\n",
    "                db1 = dz2\n",
    "                \n",
    "                # Actualización de parámetros #\n",
    "                self.w3 = self.w3 - learning_rate * dw3\n",
    "                self.b3 = self.b3 - learning_rate * db3\n",
    "                \n",
    "                self.w2 = self.w2 - learning_rate * dw2\n",
    "                self.b2 = self.b2 - learning_rate * db2\n",
    "                \n",
    "                self.w1 = self.w1 - learning_rate * dw1\n",
    "                self.b1 = self.b1 - learning_rate * db1\n",
    "                \n",
    "                y_predicted[j] = y_hat\n",
    "            \n",
    "            losses[i] = self._binary_crossEntropy(y, y_predicted)\n",
    "            accuracies[i] = self._accuracy(y, np.round(y_predicted))\n",
    "            print('Epoch {}: \\tLoss = {} \\tAccuracy = {}'.format(i, losses[i], accuracies[i]))\n",
    "        return losses, accuracies\n",
    "        \n",
    "    def fit(self, x, y, learning_rate=0.01, epochs=200):\n",
    "        loss, acc = self._backpropagation(x, y, learning_rate, epochs)\n",
    "        return loss, acc\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_pred = []\n",
    "        for i in range(x.shape[0]):\n",
    "            _, _, _, _, _, y_hat = self._forward_pass(x[i], self.w1, self.b1, \n",
    "                                                           self.w2, self.b2, \n",
    "                                                           self.w3, self.b3)\n",
    "            y_pred.append(np.round(y_hat[0]))\n",
    "        return np.array(y_pred)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_accuracy(loss, accuracy):\n",
    "    plt.plot(np.arange(loss.size), loss, label='Binary cross entropy')\n",
    "    plt.plot(np.arange(accuracy.size), accuracy, label='Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba en conjunto de datos de calificaciones\n",
    "Para utilizar el conjunto de datos de calificaciones para resolver un problema de clasificación binaria, se agregó una nueva columna *PASS*, la cual indica si un estudiante aprobó el curso o no. Para determinar el valor de cada instancia se toma el valor de la columna *CALIF*, si tiene un valor mayor a 7.0, entonces el alumno aprobó el curso, en caso contrario el alumno no aprobó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/gibranfp/CursoAprendizajeProfundo/2022-1/data/califs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_ = []\n",
    "for calif in df['calif']:\n",
    "    if calif > 7.0:\n",
    "        pass_.append(1)\n",
    "    else:\n",
    "        pass_.append(0)\n",
    "df['pass'] = pass_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['prev', 'horas']].to_numpy()\n",
    "y = df['pass'].to_numpy().reshape(50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red densa con función de activación Sigmoide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(input_dim=X.shape[1], hidden_units=5, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \tLoss = 26.20191236756616 \tAccuracy = 54.054054054054056\n",
      "Epoch 1: \tLoss = 26.169308231508516 \tAccuracy = 54.054054054054056\n",
      "Epoch 2: \tLoss = 26.13830668213482 \tAccuracy = 54.054054054054056\n",
      "Epoch 3: \tLoss = 26.108830447465426 \tAccuracy = 54.054054054054056\n",
      "Epoch 4: \tLoss = 26.080805816136692 \tAccuracy = 54.054054054054056\n",
      "Epoch 5: \tLoss = 26.05416249006753 \tAccuracy = 54.054054054054056\n",
      "Epoch 6: \tLoss = 26.02883344149271 \tAccuracy = 54.054054054054056\n",
      "Epoch 7: \tLoss = 26.004754774426594 \tAccuracy = 54.054054054054056\n",
      "Epoch 8: \tLoss = 25.98186559059245 \tAccuracy = 54.054054054054056\n",
      "Epoch 9: \tLoss = 25.960107859827996 \tAccuracy = 54.054054054054056\n",
      "Epoch 10: \tLoss = 25.93942629495602 \tAccuracy = 54.054054054054056\n",
      "Epoch 11: \tLoss = 25.91976823109019 \tAccuracy = 54.054054054054056\n",
      "Epoch 12: \tLoss = 25.90108350932973 \tAccuracy = 54.054054054054056\n",
      "Epoch 13: \tLoss = 25.8833243647831 \tAccuracy = 54.054054054054056\n",
      "Epoch 14: \tLoss = 25.866445318848434 \tAccuracy = 54.054054054054056\n",
      "Epoch 15: \tLoss = 25.850403075669135 \tAccuracy = 54.054054054054056\n",
      "Epoch 16: \tLoss = 25.835156422674395 \tAccuracy = 54.054054054054056\n",
      "Epoch 17: \tLoss = 25.820666135107814 \tAccuracy = 54.054054054054056\n",
      "Epoch 18: \tLoss = 25.80689488444193 \tAccuracy = 54.054054054054056\n",
      "Epoch 19: \tLoss = 25.79380715057225 \tAccuracy = 54.054054054054056\n",
      "Epoch 20: \tLoss = 25.78136913768123 \tAccuracy = 54.054054054054056\n",
      "Epoch 21: \tLoss = 25.769548693660635 \tAccuracy = 54.054054054054056\n",
      "Epoch 22: \tLoss = 25.75831523297896 \tAccuracy = 54.054054054054056\n",
      "Epoch 23: \tLoss = 25.747639662880417 \tAccuracy = 54.054054054054056\n",
      "Epoch 24: \tLoss = 25.73749431280166 \tAccuracy = 54.054054054054056\n",
      "Epoch 25: \tLoss = 25.727852866892945 \tAccuracy = 54.054054054054056\n",
      "Epoch 26: \tLoss = 25.71869029953161 \tAccuracy = 54.054054054054056\n",
      "Epoch 27: \tLoss = 25.709982813716824 \tAccuracy = 54.054054054054056\n",
      "Epoch 28: \tLoss = 25.701707782236653 \tAccuracy = 54.054054054054056\n",
      "Epoch 29: \tLoss = 25.693843691500078 \tAccuracy = 54.054054054054056\n",
      "Epoch 30: \tLoss = 25.68637008792917 \tAccuracy = 54.054054054054056\n",
      "Epoch 31: \tLoss = 25.679267526808843 \tAccuracy = 54.054054054054056\n",
      "Epoch 32: \tLoss = 25.67251752349429 \tAccuracy = 54.054054054054056\n",
      "Epoch 33: \tLoss = 25.666102506878822 \tAccuracy = 54.054054054054056\n",
      "Epoch 34: \tLoss = 25.660005775027713 \tAccuracy = 54.054054054054056\n",
      "Epoch 35: \tLoss = 25.6542114528864 \tAccuracy = 54.054054054054056\n",
      "Epoch 36: \tLoss = 25.648704451974375 \tAccuracy = 54.054054054054056\n",
      "Epoch 37: \tLoss = 25.643470431978923 \tAccuracy = 54.054054054054056\n",
      "Epoch 38: \tLoss = 25.638495764165903 \tAccuracy = 54.054054054054056\n",
      "Epoch 39: \tLoss = 25.633767496527568 \tAccuracy = 54.054054054054056\n",
      "Epoch 40: \tLoss = 25.629273320590343 \tAccuracy = 54.054054054054056\n",
      "Epoch 41: \tLoss = 25.62500153980833 \tAccuracy = 54.054054054054056\n",
      "Epoch 42: \tLoss = 25.620941039471216 \tAccuracy = 54.054054054054056\n",
      "Epoch 43: \tLoss = 25.617081258057805 \tAccuracy = 54.054054054054056\n",
      "Epoch 44: \tLoss = 25.61341215996932 \tAccuracy = 54.054054054054056\n",
      "Epoch 45: \tLoss = 25.609924209579127 \tAccuracy = 54.054054054054056\n",
      "Epoch 46: \tLoss = 25.606608346538188 \tAccuracy = 54.054054054054056\n",
      "Epoch 47: \tLoss = 25.603455962277994 \tAccuracy = 54.054054054054056\n",
      "Epoch 48: \tLoss = 25.600458877655182 \tAccuracy = 54.054054054054056\n",
      "Epoch 49: \tLoss = 25.597609321684466 \tAccuracy = 54.054054054054056\n",
      "Epoch 50: \tLoss = 25.59489991130866 \tAccuracy = 54.054054054054056\n",
      "Epoch 51: \tLoss = 25.592323632156976 \tAccuracy = 54.054054054054056\n",
      "Epoch 52: \tLoss = 25.589873820244694 \tAccuracy = 54.054054054054056\n",
      "Epoch 53: \tLoss = 25.587544144569577 \tAccuracy = 54.054054054054056\n",
      "Epoch 54: \tLoss = 25.585328590562234 \tAccuracy = 54.054054054054056\n",
      "Epoch 55: \tLoss = 25.583221444349586 \tAccuracy = 54.054054054054056\n",
      "Epoch 56: \tLoss = 25.581217277792565 \tAccuracy = 54.054054054054056\n",
      "Epoch 57: \tLoss = 25.57931093426064 \tAccuracy = 54.054054054054056\n",
      "Epoch 58: \tLoss = 25.57749751510786 \tAccuracy = 54.054054054054056\n",
      "Epoch 59: \tLoss = 25.575772366816373 \tAccuracy = 54.054054054054056\n",
      "Epoch 60: \tLoss = 25.574131068775174 \tAccuracy = 54.054054054054056\n",
      "Epoch 61: \tLoss = 25.57256942166323 \tAccuracy = 54.054054054054056\n",
      "Epoch 62: \tLoss = 25.571083436407662 \tAccuracy = 54.054054054054056\n",
      "Epoch 63: \tLoss = 25.569669323688885 \tAccuracy = 54.054054054054056\n",
      "Epoch 64: \tLoss = 25.56832348396606 \tAccuracy = 54.054054054054056\n",
      "Epoch 65: \tLoss = 25.56704249799749 \tAccuracy = 54.054054054054056\n",
      "Epoch 66: \tLoss = 25.5658231178316 \tAccuracy = 54.054054054054056\n",
      "Epoch 67: \tLoss = 25.564662258245555 \tAccuracy = 54.054054054054056\n",
      "Epoch 68: \tLoss = 25.563556988609506 \tAccuracy = 54.054054054054056\n",
      "Epoch 69: \tLoss = 25.562504525155475 \tAccuracy = 54.054054054054056\n",
      "Epoch 70: \tLoss = 25.561502223631102 \tAccuracy = 54.054054054054056\n",
      "Epoch 71: \tLoss = 25.560547572319116 \tAccuracy = 54.054054054054056\n",
      "Epoch 72: \tLoss = 25.559638185404715 \tAccuracy = 54.054054054054056\n",
      "Epoch 73: \tLoss = 25.55877179667341 \tAccuracy = 54.054054054054056\n",
      "Epoch 74: \tLoss = 25.55794625352324 \tAccuracy = 54.054054054054056\n",
      "Epoch 75: \tLoss = 25.55715951127567 \tAccuracy = 54.054054054054056\n",
      "Epoch 76: \tLoss = 25.556409627770414 \tAccuracy = 54.054054054054056\n",
      "Epoch 77: \tLoss = 25.555694758230125 \tAccuracy = 54.054054054054056\n",
      "Epoch 78: \tLoss = 25.55501315038158 \tAccuracy = 54.054054054054056\n",
      "Epoch 79: \tLoss = 25.554363139820573 \tAccuracy = 54.054054054054056\n",
      "Epoch 80: \tLoss = 25.55374314560852 \tAccuracy = 54.054054054054056\n",
      "Epoch 81: \tLoss = 25.55315166608911 \tAccuracy = 54.054054054054056\n",
      "Epoch 82: \tLoss = 25.552587274914224 \tAccuracy = 54.054054054054056\n",
      "Epoch 83: \tLoss = 25.55204861726858 \tAccuracy = 54.054054054054056\n",
      "Epoch 84: \tLoss = 25.551534406283295 \tAccuracy = 54.054054054054056\n",
      "Epoch 85: \tLoss = 25.551043419628897 \tAccuracy = 54.054054054054056\n",
      "Epoch 86: \tLoss = 25.550574496278912 \tAccuracy = 54.054054054054056\n",
      "Epoch 87: \tLoss = 25.550126533435417 \tAccuracy = 54.054054054054056\n",
      "Epoch 88: \tLoss = 25.54969848360861 \tAccuracy = 54.054054054054056\n",
      "Epoch 89: \tLoss = 25.549289351842603 \tAccuracy = 54.054054054054056\n",
      "Epoch 90: \tLoss = 25.548898193080205 \tAccuracy = 54.054054054054056\n",
      "Epoch 91: \tLoss = 25.54852410965973 \tAccuracy = 54.054054054054056\n",
      "Epoch 92: \tLoss = 25.54816624893723 \tAccuracy = 54.054054054054056\n",
      "Epoch 93: \tLoss = 25.54782380102791 \tAccuracy = 54.054054054054056\n",
      "Epoch 94: \tLoss = 25.54749599666072 \tAccuracy = 54.054054054054056\n",
      "Epoch 95: \tLoss = 25.547182105140564 \tAccuracy = 54.054054054054056\n",
      "Epoch 96: \tLoss = 25.546881432412583 \tAccuracy = 54.054054054054056\n",
      "Epoch 97: \tLoss = 25.546593319223575 \tAccuracy = 54.054054054054056\n",
      "Epoch 98: \tLoss = 25.546317139375603 \tAccuracy = 54.054054054054056\n",
      "Epoch 99: \tLoss = 25.546052298067146 \tAccuracy = 54.054054054054056\n",
      "Epoch 100: \tLoss = 25.54579823031755 \tAccuracy = 54.054054054054056\n",
      "Epoch 101: \tLoss = 25.545554399470383 \tAccuracy = 54.054054054054056\n",
      "Epoch 102: \tLoss = 25.545320295772008 \tAccuracy = 54.054054054054056\n",
      "Epoch 103: \tLoss = 25.54509543502135 \tAccuracy = 54.054054054054056\n",
      "Epoch 104: \tLoss = 25.54487935728752 \tAccuracy = 54.054054054054056\n",
      "Epoch 105: \tLoss = 25.54467162569172 \tAccuracy = 54.054054054054056\n",
      "Epoch 106: \tLoss = 25.544471825250266 \tAccuracy = 54.054054054054056\n",
      "Epoch 107: \tLoss = 25.544279561775763 \tAccuracy = 54.054054054054056\n",
      "Epoch 108: \tLoss = 25.544094460833314 \tAccuracy = 54.054054054054056\n",
      "Epoch 109: \tLoss = 25.5439161667492 \tAccuracy = 54.054054054054056\n",
      "Epoch 110: \tLoss = 25.543744341669267 \tAccuracy = 54.054054054054056\n",
      "Epoch 111: \tLoss = 25.543578664664658 \tAccuracy = 54.054054054054056\n",
      "Epoch 112: \tLoss = 25.54341883088232 \tAccuracy = 54.054054054054056\n",
      "Epoch 113: \tLoss = 25.543264550738265 \tAccuracy = 54.054054054054056\n",
      "Epoch 114: \tLoss = 25.543115549151253 \tAccuracy = 54.054054054054056\n",
      "Epoch 115: \tLoss = 25.542971564815012 \tAccuracy = 54.054054054054056\n",
      "Epoch 116: \tLoss = 25.54283234950696 \tAccuracy = 54.054054054054056\n",
      "Epoch 117: \tLoss = 25.542697667431604 \tAccuracy = 54.054054054054056\n",
      "Epoch 118: \tLoss = 25.542567294597013 \tAccuracy = 54.054054054054056\n",
      "Epoch 119: \tLoss = 25.542441018222476 \tAccuracy = 54.054054054054056\n",
      "Epoch 120: \tLoss = 25.54231863617597 \tAccuracy = 54.054054054054056\n",
      "Epoch 121: \tLoss = 25.542199956439873 \tAccuracy = 54.054054054054056\n",
      "Epoch 122: \tLoss = 25.542084796603493 \tAccuracy = 54.054054054054056\n",
      "Epoch 123: \tLoss = 25.541972983381065 \tAccuracy = 54.054054054054056\n",
      "Epoch 124: \tLoss = 25.54186435215397 \tAccuracy = 54.054054054054056\n",
      "Epoch 125: \tLoss = 25.54175874653597 \tAccuracy = 54.054054054054056\n",
      "Epoch 126: \tLoss = 25.541656017960186 \tAccuracy = 54.054054054054056\n",
      "Epoch 127: \tLoss = 25.54155602528696 \tAccuracy = 54.054054054054056\n",
      "Epoch 128: \tLoss = 25.54145863443121 \tAccuracy = 54.054054054054056\n",
      "Epoch 129: \tLoss = 25.541363718008718 \tAccuracy = 54.054054054054056\n",
      "Epoch 130: \tLoss = 25.54127115500003 \tAccuracy = 54.054054054054056\n",
      "Epoch 131: \tLoss = 25.54118083043125 \tAccuracy = 54.054054054054056\n",
      "Epoch 132: \tLoss = 25.541092635070946 \tAccuracy = 54.054054054054056\n",
      "Epoch 133: \tLoss = 25.541006465142182 \tAccuracy = 54.054054054054056\n",
      "Epoch 134: \tLoss = 25.54092222204906 \tAccuracy = 54.054054054054056\n",
      "Epoch 135: \tLoss = 25.540839812116992 \tAccuracy = 54.054054054054056\n",
      "Epoch 136: \tLoss = 25.540759146345998 \tAccuracy = 54.054054054054056\n",
      "Epoch 137: \tLoss = 25.540680140176384 \tAccuracy = 54.054054054054056\n",
      "Epoch 138: \tLoss = 25.540602713266253 \tAccuracy = 54.054054054054056\n",
      "Epoch 139: \tLoss = 25.540526789280065 \tAccuracy = 54.054054054054056\n",
      "Epoch 140: \tLoss = 25.540452295687928 \tAccuracy = 54.054054054054056\n",
      "Epoch 141: \tLoss = 25.540379163574922 \tAccuracy = 54.054054054054056\n",
      "Epoch 142: \tLoss = 25.540307327459985 \tAccuracy = 54.054054054054056\n",
      "Epoch 143: \tLoss = 25.5402367251239 \tAccuracy = 54.054054054054056\n",
      "Epoch 144: \tLoss = 25.540167297445954 \tAccuracy = 54.054054054054056\n",
      "Epoch 145: \tLoss = 25.540098988248715 \tAccuracy = 54.054054054054056\n",
      "Epoch 146: \tLoss = 25.5400317441507 \tAccuracy = 54.054054054054056\n",
      "Epoch 147: \tLoss = 25.53996551442636 \tAccuracy = 54.054054054054056\n",
      "Epoch 148: \tLoss = 25.539900250873156 \tAccuracy = 54.054054054054056\n",
      "Epoch 149: \tLoss = 25.53983590768523 \tAccuracy = 54.054054054054056\n",
      "Epoch 150: \tLoss = 25.539772441333515 \tAccuracy = 54.054054054054056\n",
      "Epoch 151: \tLoss = 25.539709810451775 \tAccuracy = 54.054054054054056\n",
      "Epoch 152: \tLoss = 25.53964797572841 \tAccuracy = 54.054054054054056\n",
      "Epoch 153: \tLoss = 25.539586899803698 \tAccuracy = 54.054054054054056\n",
      "Epoch 154: \tLoss = 25.539526547172144 \tAccuracy = 54.054054054054056\n",
      "Epoch 155: \tLoss = 25.539466884089787 \tAccuracy = 54.054054054054056\n",
      "Epoch 156: \tLoss = 25.539407878486145 \tAccuracy = 54.054054054054056\n",
      "Epoch 157: \tLoss = 25.539349499880522 \tAccuracy = 54.054054054054056\n",
      "Epoch 158: \tLoss = 25.53929171930261 \tAccuracy = 54.054054054054056\n",
      "Epoch 159: \tLoss = 25.539234509216982 \tAccuracy = 54.054054054054056\n",
      "Epoch 160: \tLoss = 25.539177843451448 \tAccuracy = 54.054054054054056\n",
      "Epoch 161: \tLoss = 25.539121697128945 \tAccuracy = 54.054054054054056\n",
      "Epoch 162: \tLoss = 25.53906604660288 \tAccuracy = 54.054054054054056\n",
      "Epoch 163: \tLoss = 25.53901086939571 \tAccuracy = 54.054054054054056\n",
      "Epoch 164: \tLoss = 25.538956144140577 \tAccuracy = 54.054054054054056\n",
      "Epoch 165: \tLoss = 25.53890185052592 \tAccuracy = 54.054054054054056\n",
      "Epoch 166: \tLoss = 25.53884796924281 \tAccuracy = 54.054054054054056\n",
      "Epoch 167: \tLoss = 25.538794481934957 \tAccuracy = 54.054054054054056\n",
      "Epoch 168: \tLoss = 25.538741371151218 \tAccuracy = 54.054054054054056\n",
      "Epoch 169: \tLoss = 25.538688620300476 \tAccuracy = 54.054054054054056\n",
      "Epoch 170: \tLoss = 25.538636213608797 \tAccuracy = 54.054054054054056\n",
      "Epoch 171: \tLoss = 25.53858413607872 \tAccuracy = 54.054054054054056\n",
      "Epoch 172: \tLoss = 25.538532373450586 \tAccuracy = 54.054054054054056\n",
      "Epoch 173: \tLoss = 25.538480912165817 \tAccuracy = 54.054054054054056\n",
      "Epoch 174: \tLoss = 25.538429739332045 \tAccuracy = 54.054054054054056\n",
      "Epoch 175: \tLoss = 25.53837884268993 \tAccuracy = 54.054054054054056\n",
      "Epoch 176: \tLoss = 25.538328210581717 \tAccuracy = 54.054054054054056\n",
      "Epoch 177: \tLoss = 25.538277831921313 \tAccuracy = 54.054054054054056\n",
      "Epoch 178: \tLoss = 25.53822769616588 \tAccuracy = 54.054054054054056\n",
      "Epoch 179: \tLoss = 25.53817779328887 \tAccuracy = 54.054054054054056\n",
      "Epoch 180: \tLoss = 25.53812811375437 \tAccuracy = 54.054054054054056\n",
      "Epoch 181: \tLoss = 25.538078648492753 \tAccuracy = 54.054054054054056\n",
      "Epoch 182: \tLoss = 25.53802938887756 \tAccuracy = 54.054054054054056\n",
      "Epoch 183: \tLoss = 25.53798032670351 \tAccuracy = 54.054054054054056\n",
      "Epoch 184: \tLoss = 25.537931454165644 \tAccuracy = 54.054054054054056\n",
      "Epoch 185: \tLoss = 25.53788276383945 \tAccuracy = 54.054054054054056\n",
      "Epoch 186: \tLoss = 25.53783424866208 \tAccuracy = 54.054054054054056\n",
      "Epoch 187: \tLoss = 25.537785901914425 \tAccuracy = 54.054054054054056\n",
      "Epoch 188: \tLoss = 25.537737717204095 \tAccuracy = 54.054054054054056\n",
      "Epoch 189: \tLoss = 25.53768968844931 \tAccuracy = 54.054054054054056\n",
      "Epoch 190: \tLoss = 25.53764180986349 \tAccuracy = 54.054054054054056\n",
      "Epoch 191: \tLoss = 25.53759407594075 \tAccuracy = 54.054054054054056\n",
      "Epoch 192: \tLoss = 25.53754648144199 \tAccuracy = 54.054054054054056\n",
      "Epoch 193: \tLoss = 25.537499021381755 \tAccuracy = 54.054054054054056\n",
      "Epoch 194: \tLoss = 25.537451691015743 \tAccuracy = 54.054054054054056\n",
      "Epoch 195: \tLoss = 25.53740448582891 \tAccuracy = 54.054054054054056\n",
      "Epoch 196: \tLoss = 25.537357401524204 \tAccuracy = 54.054054054054056\n",
      "Epoch 197: \tLoss = 25.53731043401181 \tAccuracy = 54.054054054054056\n",
      "Epoch 198: \tLoss = 25.53726357939899 \tAccuracy = 54.054054054054056\n",
      "Epoch 199: \tLoss = 25.537216833980402 \tAccuracy = 54.054054054054056\n",
      "Epoch 200: \tLoss = 25.537170194228878 \tAccuracy = 54.054054054054056\n",
      "Epoch 201: \tLoss = 25.537123656786715 \tAccuracy = 54.054054054054056\n",
      "Epoch 202: \tLoss = 25.537077218457352 \tAccuracy = 54.054054054054056\n",
      "Epoch 203: \tLoss = 25.537030876197477 \tAccuracy = 54.054054054054056\n",
      "Epoch 204: \tLoss = 25.536984627109554 \tAccuracy = 54.054054054054056\n",
      "Epoch 205: \tLoss = 25.536938468434666 \tAccuracy = 54.054054054054056\n",
      "Epoch 206: \tLoss = 25.53689239754577 \tAccuracy = 54.054054054054056\n",
      "Epoch 207: \tLoss = 25.536846411941248 \tAccuracy = 54.054054054054056\n",
      "Epoch 208: \tLoss = 25.53680050923881 \tAccuracy = 54.054054054054056\n",
      "Epoch 209: \tLoss = 25.53675468716966 \tAccuracy = 54.054054054054056\n",
      "Epoch 210: \tLoss = 25.536708943573004 \tAccuracy = 54.054054054054056\n",
      "Epoch 211: \tLoss = 25.536663276390787 \tAccuracy = 54.054054054054056\n",
      "Epoch 212: \tLoss = 25.536617683662698 \tAccuracy = 54.054054054054056\n",
      "Epoch 213: \tLoss = 25.53657216352146 \tAccuracy = 54.054054054054056\n",
      "Epoch 214: \tLoss = 25.536526714188287 \tAccuracy = 54.054054054054056\n",
      "Epoch 215: \tLoss = 25.536481333968645 \tAccuracy = 54.054054054054056\n",
      "Epoch 216: \tLoss = 25.536436021248157 \tAccuracy = 54.054054054054056\n",
      "Epoch 217: \tLoss = 25.53639077448873 \tAccuracy = 54.054054054054056\n",
      "Epoch 218: \tLoss = 25.536345592224908 \tAccuracy = 54.054054054054056\n",
      "Epoch 219: \tLoss = 25.536300473060365 \tAccuracy = 54.054054054054056\n",
      "Epoch 220: \tLoss = 25.53625541566457 \tAccuracy = 54.054054054054056\n",
      "Epoch 221: \tLoss = 25.53621041876966 \tAccuracy = 54.054054054054056\n",
      "Epoch 222: \tLoss = 25.536165481167394 \tAccuracy = 54.054054054054056\n",
      "Epoch 223: \tLoss = 25.536120601706354 \tAccuracy = 54.054054054054056\n",
      "Epoch 224: \tLoss = 25.53607577928921 \tAccuracy = 54.054054054054056\n",
      "Epoch 225: \tLoss = 25.53603101287011 \tAccuracy = 54.054054054054056\n",
      "Epoch 226: \tLoss = 25.53598630145231 \tAccuracy = 54.054054054054056\n",
      "Epoch 227: \tLoss = 25.535941644085753 \tAccuracy = 54.054054054054056\n",
      "Epoch 228: \tLoss = 25.535897039864906 \tAccuracy = 54.054054054054056\n",
      "Epoch 229: \tLoss = 25.535852487926643 \tAccuracy = 54.054054054054056\n",
      "Epoch 230: \tLoss = 25.535807987448244 \tAccuracy = 54.054054054054056\n",
      "Epoch 231: \tLoss = 25.535763537645494 \tAccuracy = 54.054054054054056\n",
      "Epoch 232: \tLoss = 25.53571913777086 \tAccuracy = 54.054054054054056\n",
      "Epoch 233: \tLoss = 25.535674787111773 \tAccuracy = 54.054054054054056\n",
      "Epoch 234: \tLoss = 25.535630484988992 \tAccuracy = 54.054054054054056\n",
      "Epoch 235: \tLoss = 25.535586230755065 \tAccuracy = 54.054054054054056\n",
      "Epoch 236: \tLoss = 25.53554202379281 \tAccuracy = 54.054054054054056\n",
      "Epoch 237: \tLoss = 25.535497863513942 \tAccuracy = 54.054054054054056\n",
      "Epoch 238: \tLoss = 25.535453749357707 \tAccuracy = 54.054054054054056\n",
      "Epoch 239: \tLoss = 25.53540968078963 \tAccuracy = 54.054054054054056\n",
      "Epoch 240: \tLoss = 25.53536565730029 \tAccuracy = 54.054054054054056\n",
      "Epoch 241: \tLoss = 25.535321678404166 \tAccuracy = 54.054054054054056\n",
      "Epoch 242: \tLoss = 25.53527774363854 \tAccuracy = 54.054054054054056\n",
      "Epoch 243: \tLoss = 25.535233852562467 \tAccuracy = 54.054054054054056\n",
      "Epoch 244: \tLoss = 25.535190004755766 \tAccuracy = 54.054054054054056\n",
      "Epoch 245: \tLoss = 25.535146199818072 \tAccuracy = 54.054054054054056\n",
      "Epoch 246: \tLoss = 25.535102437367964 \tAccuracy = 54.054054054054056\n",
      "Epoch 247: \tLoss = 25.53505871704208 \tAccuracy = 54.054054054054056\n",
      "Epoch 248: \tLoss = 25.535015038494315 \tAccuracy = 54.054054054054056\n",
      "Epoch 249: \tLoss = 25.534971401395055 \tAccuracy = 54.054054054054056\n",
      "Epoch 250: \tLoss = 25.53492780543042 \tAccuracy = 54.054054054054056\n",
      "Epoch 251: \tLoss = 25.534884250301577 \tAccuracy = 54.054054054054056\n",
      "Epoch 252: \tLoss = 25.53484073572408 \tAccuracy = 54.054054054054056\n",
      "Epoch 253: \tLoss = 25.5347972614272 \tAccuracy = 54.054054054054056\n",
      "Epoch 254: \tLoss = 25.534753827153367 \tAccuracy = 54.054054054054056\n",
      "Epoch 255: \tLoss = 25.53471043265755 \tAccuracy = 54.054054054054056\n",
      "Epoch 256: \tLoss = 25.534667077706743 \tAccuracy = 54.054054054054056\n",
      "Epoch 257: \tLoss = 25.534623762079406 \tAccuracy = 54.054054054054056\n",
      "Epoch 258: \tLoss = 25.534580485565016 \tAccuracy = 54.054054054054056\n",
      "Epoch 259: \tLoss = 25.53453724796355 \tAccuracy = 54.054054054054056\n",
      "Epoch 260: \tLoss = 25.534494049085048 \tAccuracy = 54.054054054054056\n",
      "Epoch 261: \tLoss = 25.534450888749188 \tAccuracy = 54.054054054054056\n",
      "Epoch 262: \tLoss = 25.534407766784874 \tAccuracy = 54.054054054054056\n",
      "Epoch 263: \tLoss = 25.534364683029857 \tAccuracy = 54.054054054054056\n",
      "Epoch 264: \tLoss = 25.53432163733032 \tAccuracy = 54.054054054054056\n",
      "Epoch 265: \tLoss = 25.53427862954059 \tAccuracy = 54.054054054054056\n",
      "Epoch 266: \tLoss = 25.534235659522757 \tAccuracy = 54.054054054054056\n",
      "Epoch 267: \tLoss = 25.53419272714634 \tAccuracy = 54.054054054054056\n",
      "Epoch 268: \tLoss = 25.53414983228803 \tAccuracy = 54.054054054054056\n",
      "Epoch 269: \tLoss = 25.534106974831364 \tAccuracy = 54.054054054054056\n",
      "Epoch 270: \tLoss = 25.53406415466644 \tAccuracy = 54.054054054054056\n",
      "Epoch 271: \tLoss = 25.53402137168966 \tAccuracy = 54.054054054054056\n",
      "Epoch 272: \tLoss = 25.53397862580351 \tAccuracy = 54.054054054054056\n",
      "Epoch 273: \tLoss = 25.53393591691626 \tAccuracy = 54.054054054054056\n",
      "Epoch 274: \tLoss = 25.533893244941765 \tAccuracy = 54.054054054054056\n",
      "Epoch 275: \tLoss = 25.533850609799263 \tAccuracy = 54.054054054054056\n",
      "Epoch 276: \tLoss = 25.533808011413125 \tAccuracy = 54.054054054054056\n",
      "Epoch 277: \tLoss = 25.533765449712675 \tAccuracy = 54.054054054054056\n",
      "Epoch 278: \tLoss = 25.533722924632016 \tAccuracy = 54.054054054054056\n",
      "Epoch 279: \tLoss = 25.53368043610981 \tAccuracy = 54.054054054054056\n",
      "Epoch 280: \tLoss = 25.533637984089133 \tAccuracy = 54.054054054054056\n",
      "Epoch 281: \tLoss = 25.533595568517306 \tAccuracy = 54.054054054054056\n",
      "Epoch 282: \tLoss = 25.533553189345724 \tAccuracy = 54.054054054054056\n",
      "Epoch 283: \tLoss = 25.53351084652971 \tAccuracy = 54.054054054054056\n",
      "Epoch 284: \tLoss = 25.533468540028363 \tAccuracy = 54.054054054054056\n",
      "Epoch 285: \tLoss = 25.53342626980445 \tAccuracy = 54.054054054054056\n",
      "Epoch 286: \tLoss = 25.53338403582424 \tAccuracy = 54.054054054054056\n",
      "Epoch 287: \tLoss = 25.533341838057385 \tAccuracy = 54.054054054054056\n",
      "Epoch 288: \tLoss = 25.533299676476815 \tAccuracy = 54.054054054054056\n",
      "Epoch 289: \tLoss = 25.53325755105859 \tAccuracy = 54.054054054054056\n",
      "Epoch 290: \tLoss = 25.533215461781836 \tAccuracy = 54.054054054054056\n",
      "Epoch 291: \tLoss = 25.533173408628606 \tAccuracy = 54.054054054054056\n",
      "Epoch 292: \tLoss = 25.533131391583765 \tAccuracy = 54.054054054054056\n",
      "Epoch 293: \tLoss = 25.533089410634958 \tAccuracy = 54.054054054054056\n",
      "Epoch 294: \tLoss = 25.533047465772437 \tAccuracy = 54.054054054054056\n",
      "Epoch 295: \tLoss = 25.53300555698902 \tAccuracy = 54.054054054054056\n",
      "Epoch 296: \tLoss = 25.532963684280013 \tAccuracy = 54.054054054054056\n",
      "Epoch 297: \tLoss = 25.53292184764309 \tAccuracy = 54.054054054054056\n",
      "Epoch 298: \tLoss = 25.53288004707825 \tAccuracy = 54.054054054054056\n",
      "Epoch 299: \tLoss = 25.53283828258772 \tAccuracy = 54.054054054054056\n",
      "Epoch 300: \tLoss = 25.532796554175903 \tAccuracy = 54.054054054054056\n",
      "Epoch 301: \tLoss = 25.53275486184929 \tAccuracy = 54.054054054054056\n",
      "Epoch 302: \tLoss = 25.532713205616403 \tAccuracy = 54.054054054054056\n",
      "Epoch 303: \tLoss = 25.532671585487744 \tAccuracy = 54.054054054054056\n",
      "Epoch 304: \tLoss = 25.532630001475702 \tAccuracy = 54.054054054054056\n",
      "Epoch 305: \tLoss = 25.532588453594535 \tAccuracy = 54.054054054054056\n",
      "Epoch 306: \tLoss = 25.532546941860282 \tAccuracy = 54.054054054054056\n",
      "Epoch 307: \tLoss = 25.53250546629073 \tAccuracy = 54.054054054054056\n",
      "Epoch 308: \tLoss = 25.532464026905338 \tAccuracy = 54.054054054054056\n",
      "Epoch 309: \tLoss = 25.532422623725218 \tAccuracy = 54.054054054054056\n",
      "Epoch 310: \tLoss = 25.53238125677307 \tAccuracy = 54.054054054054056\n",
      "Epoch 311: \tLoss = 25.532339926073124 \tAccuracy = 54.054054054054056\n",
      "Epoch 312: \tLoss = 25.53229863165114 \tAccuracy = 54.054054054054056\n",
      "Epoch 313: \tLoss = 25.5322573735343 \tAccuracy = 54.054054054054056\n",
      "Epoch 314: \tLoss = 25.53221615175122 \tAccuracy = 54.054054054054056\n",
      "Epoch 315: \tLoss = 25.5321749663319 \tAccuracy = 54.054054054054056\n",
      "Epoch 316: \tLoss = 25.532133817307667 \tAccuracy = 54.054054054054056\n",
      "Epoch 317: \tLoss = 25.53209270471115 \tAccuracy = 54.054054054054056\n",
      "Epoch 318: \tLoss = 25.532051628576248 \tAccuracy = 54.054054054054056\n",
      "Epoch 319: \tLoss = 25.532010588938096 \tAccuracy = 54.054054054054056\n",
      "Epoch 320: \tLoss = 25.531969585833018 \tAccuracy = 54.054054054054056\n",
      "Epoch 321: \tLoss = 25.531928619298522 \tAccuracy = 54.054054054054056\n",
      "Epoch 322: \tLoss = 25.531887689373228 \tAccuracy = 54.054054054054056\n",
      "Epoch 323: \tLoss = 25.53184679609688 \tAccuracy = 54.054054054054056\n",
      "Epoch 324: \tLoss = 25.5318059395103 \tAccuracy = 54.054054054054056\n",
      "Epoch 325: \tLoss = 25.531765119655354 \tAccuracy = 54.054054054054056\n",
      "Epoch 326: \tLoss = 25.531724336574932 \tAccuracy = 54.054054054054056\n",
      "Epoch 327: \tLoss = 25.53168359031292 \tAccuracy = 54.054054054054056\n",
      "Epoch 328: \tLoss = 25.531642880914177 \tAccuracy = 54.054054054054056\n",
      "Epoch 329: \tLoss = 25.531602208424506 \tAccuracy = 54.054054054054056\n",
      "Epoch 330: \tLoss = 25.531561572890638 \tAccuracy = 54.054054054054056\n",
      "Epoch 331: \tLoss = 25.53152097436019 \tAccuracy = 54.054054054054056\n",
      "Epoch 332: \tLoss = 25.531480412881677 \tAccuracy = 54.054054054054056\n",
      "Epoch 333: \tLoss = 25.53143988850445 \tAccuracy = 54.054054054054056\n",
      "Epoch 334: \tLoss = 25.531399401278705 \tAccuracy = 54.054054054054056\n",
      "Epoch 335: \tLoss = 25.531358951255438 \tAccuracy = 54.054054054054056\n",
      "Epoch 336: \tLoss = 25.531318538486452 \tAccuracy = 54.054054054054056\n",
      "Epoch 337: \tLoss = 25.531278163024325 \tAccuracy = 54.054054054054056\n",
      "Epoch 338: \tLoss = 25.531237824922364 \tAccuracy = 54.054054054054056\n",
      "Epoch 339: \tLoss = 25.531197524234646 \tAccuracy = 54.054054054054056\n",
      "Epoch 340: \tLoss = 25.531157261015938 \tAccuracy = 54.054054054054056\n",
      "Epoch 341: \tLoss = 25.53111703532172 \tAccuracy = 54.054054054054056\n",
      "Epoch 342: \tLoss = 25.531076847208155 \tAccuracy = 54.054054054054056\n",
      "Epoch 343: \tLoss = 25.531036696732063 \tAccuracy = 54.054054054054056\n",
      "Epoch 344: \tLoss = 25.53099658395091 \tAccuracy = 54.054054054054056\n",
      "Epoch 345: \tLoss = 25.530956508922813 \tAccuracy = 54.054054054054056\n",
      "Epoch 346: \tLoss = 25.53091647170649 \tAccuracy = 54.054054054054056\n",
      "Epoch 347: \tLoss = 25.530876472361264 \tAccuracy = 54.054054054054056\n",
      "Epoch 348: \tLoss = 25.530836510947047 \tAccuracy = 54.054054054054056\n",
      "Epoch 349: \tLoss = 25.530796587524314 \tAccuracy = 54.054054054054056\n",
      "Epoch 350: \tLoss = 25.530756702154108 \tAccuracy = 54.054054054054056\n",
      "Epoch 351: \tLoss = 25.530716854898014 \tAccuracy = 54.054054054054056\n",
      "Epoch 352: \tLoss = 25.53067704581813 \tAccuracy = 54.054054054054056\n",
      "Epoch 353: \tLoss = 25.530637274977096 \tAccuracy = 54.054054054054056\n",
      "Epoch 354: \tLoss = 25.530597542438016 \tAccuracy = 54.054054054054056\n",
      "Epoch 355: \tLoss = 25.53055784826452 \tAccuracy = 54.054054054054056\n",
      "Epoch 356: \tLoss = 25.530518192520688 \tAccuracy = 54.054054054054056\n",
      "Epoch 357: \tLoss = 25.530478575271076 \tAccuracy = 54.054054054054056\n",
      "Epoch 358: \tLoss = 25.530438996580674 \tAccuracy = 54.054054054054056\n",
      "Epoch 359: \tLoss = 25.530399456514928 \tAccuracy = 54.054054054054056\n",
      "Epoch 360: \tLoss = 25.5303599551397 \tAccuracy = 54.054054054054056\n",
      "Epoch 361: \tLoss = 25.530320492521263 \tAccuracy = 54.054054054054056\n",
      "Epoch 362: \tLoss = 25.53028106872629 \tAccuracy = 54.054054054054056\n",
      "Epoch 363: \tLoss = 25.530241683821842 \tAccuracy = 54.054054054054056\n",
      "Epoch 364: \tLoss = 25.530202337875377 \tAccuracy = 54.054054054054056\n",
      "Epoch 365: \tLoss = 25.530163030954686 \tAccuracy = 54.054054054054056\n",
      "Epoch 366: \tLoss = 25.530123763127946 \tAccuracy = 54.054054054054056\n",
      "Epoch 367: \tLoss = 25.530084534463658 \tAccuracy = 54.054054054054056\n",
      "Epoch 368: \tLoss = 25.530045345030672 \tAccuracy = 54.054054054054056\n",
      "Epoch 369: \tLoss = 25.530006194898146 \tAccuracy = 54.054054054054056\n",
      "Epoch 370: \tLoss = 25.529967084135553 \tAccuracy = 54.054054054054056\n",
      "Epoch 371: \tLoss = 25.529928012812675 \tAccuracy = 54.054054054054056\n",
      "Epoch 372: \tLoss = 25.529888980999573 \tAccuracy = 54.054054054054056\n",
      "Epoch 373: \tLoss = 25.5298499887666 \tAccuracy = 54.054054054054056\n",
      "Epoch 374: \tLoss = 25.529811036184366 \tAccuracy = 54.054054054054056\n",
      "Epoch 375: \tLoss = 25.529772123323752 \tAccuracy = 54.054054054054056\n",
      "Epoch 376: \tLoss = 25.529733250255887 \tAccuracy = 54.054054054054056\n",
      "Epoch 377: \tLoss = 25.529694417052127 \tAccuracy = 54.054054054054056\n",
      "Epoch 378: \tLoss = 25.52965562378408 \tAccuracy = 54.054054054054056\n",
      "Epoch 379: \tLoss = 25.529616870523558 \tAccuracy = 54.054054054054056\n",
      "Epoch 380: \tLoss = 25.52957815734258 \tAccuracy = 54.054054054054056\n",
      "Epoch 381: \tLoss = 25.529539484313382 \tAccuracy = 54.054054054054056\n",
      "Epoch 382: \tLoss = 25.52950085150838 \tAccuracy = 54.054054054054056\n",
      "Epoch 383: \tLoss = 25.52946225900018 \tAccuracy = 54.054054054054056\n",
      "Epoch 384: \tLoss = 25.529423706861543 \tAccuracy = 54.054054054054056\n",
      "Epoch 385: \tLoss = 25.52938519516542 \tAccuracy = 54.054054054054056\n",
      "Epoch 386: \tLoss = 25.529346723984894 \tAccuracy = 54.054054054054056\n",
      "Epoch 387: \tLoss = 25.529308293393207 \tAccuracy = 54.054054054054056\n",
      "Epoch 388: \tLoss = 25.529269903463724 \tAccuracy = 54.054054054054056\n",
      "Epoch 389: \tLoss = 25.52923155426995 \tAccuracy = 54.054054054054056\n",
      "Epoch 390: \tLoss = 25.529193245885494 \tAccuracy = 54.054054054054056\n",
      "Epoch 391: \tLoss = 25.529154978384092 \tAccuracy = 54.054054054054056\n",
      "Epoch 392: \tLoss = 25.529116751839563 \tAccuracy = 54.054054054054056\n",
      "Epoch 393: \tLoss = 25.52907856632583 \tAccuracy = 54.054054054054056\n",
      "Epoch 394: \tLoss = 25.52904042191689 \tAccuracy = 54.054054054054056\n",
      "Epoch 395: \tLoss = 25.529002318686818 \tAccuracy = 54.054054054054056\n",
      "Epoch 396: \tLoss = 25.528964256709756 \tAccuracy = 54.054054054054056\n",
      "Epoch 397: \tLoss = 25.528926236059903 \tAccuracy = 54.054054054054056\n",
      "Epoch 398: \tLoss = 25.52888825681151 \tAccuracy = 54.054054054054056\n",
      "Epoch 399: \tLoss = 25.528850319038852 \tAccuracy = 54.054054054054056\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "loss, acc = mlp.fit(X_train, y_train, learning_rate=0.001, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_and_accuracy(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.62      1.00      0.76         8\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.31      0.50      0.38        13\n",
      "weighted avg       0.38      0.62      0.47        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red densa con función de activación ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(input_dim=X.shape[1], hidden_units=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \tLoss = nan \tAccuracy = 45.94594594594595\n",
      "Epoch 1: \tLoss = nan \tAccuracy = 51.35135135135135\n",
      "Epoch 2: \tLoss = nan \tAccuracy = 51.35135135135135\n",
      "Epoch 3: \tLoss = nan \tAccuracy = 51.35135135135135\n",
      "Epoch 4: \tLoss = nan \tAccuracy = 54.054054054054056\n",
      "Epoch 5: \tLoss = 29.360052973300384 \tAccuracy = 54.054054054054056\n",
      "Epoch 6: \tLoss = 28.19240665317441 \tAccuracy = 54.054054054054056\n",
      "Epoch 7: \tLoss = 27.58902802248641 \tAccuracy = 54.054054054054056\n",
      "Epoch 8: \tLoss = 27.177969848346944 \tAccuracy = 54.054054054054056\n",
      "Epoch 9: \tLoss = 26.869391058262053 \tAccuracy = 48.64864864864865\n",
      "Epoch 10: \tLoss = 26.661263891123895 \tAccuracy = 51.35135135135135\n",
      "Epoch 11: \tLoss = 26.48159286165557 \tAccuracy = 56.75675675675676\n",
      "Epoch 12: \tLoss = 26.32890129916718 \tAccuracy = 56.75675675675676\n",
      "Epoch 13: \tLoss = 26.196840423873375 \tAccuracy = 56.75675675675676\n",
      "Epoch 14: \tLoss = 26.08095127875802 \tAccuracy = 54.054054054054056\n",
      "Epoch 15: \tLoss = 25.977982167763223 \tAccuracy = 54.054054054054056\n",
      "Epoch 16: \tLoss = 25.88549484865814 \tAccuracy = 54.054054054054056\n",
      "Epoch 17: \tLoss = 25.801620839009217 \tAccuracy = 54.054054054054056\n",
      "Epoch 18: \tLoss = 25.724903090495904 \tAccuracy = 54.054054054054056\n",
      "Epoch 19: \tLoss = 25.65418902243545 \tAccuracy = 54.054054054054056\n",
      "Epoch 20: \tLoss = 25.588555910626248 \tAccuracy = 54.054054054054056\n",
      "Epoch 21: \tLoss = 25.52725745459167 \tAccuracy = 54.054054054054056\n",
      "Epoch 22: \tLoss = 25.469684660158798 \tAccuracy = 54.054054054054056\n",
      "Epoch 23: \tLoss = 25.415336665634605 \tAccuracy = 56.75675675675676\n",
      "Epoch 24: \tLoss = 25.36379863755612 \tAccuracy = 56.75675675675676\n",
      "Epoch 25: \tLoss = 25.314724794283624 \tAccuracy = 56.75675675675676\n",
      "Epoch 26: \tLoss = 25.26782521398569 \tAccuracy = 56.75675675675676\n",
      "Epoch 27: \tLoss = 25.22285547793453 \tAccuracy = 56.75675675675676\n",
      "Epoch 28: \tLoss = 25.17960846623388 \tAccuracy = 59.45945945945946\n",
      "Epoch 29: \tLoss = 25.137907806624092 \tAccuracy = 59.45945945945946\n",
      "Epoch 30: \tLoss = 25.09760260593721 \tAccuracy = 56.75675675675676\n",
      "Epoch 31: \tLoss = 25.058563185889227 \tAccuracy = 62.16216216216216\n",
      "Epoch 32: \tLoss = 25.02067761171149 \tAccuracy = 62.16216216216216\n",
      "Epoch 33: \tLoss = 24.983848851253537 \tAccuracy = 62.16216216216216\n",
      "Epoch 34: \tLoss = 24.947992438759776 \tAccuracy = 64.86486486486487\n",
      "Epoch 35: \tLoss = 24.91303454504952 \tAccuracy = 64.86486486486487\n",
      "Epoch 36: \tLoss = 24.878910376757595 \tAccuracy = 64.86486486486487\n",
      "Epoch 37: \tLoss = 24.845562843349793 \tAccuracy = 64.86486486486487\n",
      "Epoch 38: \tLoss = 24.81294144304959 \tAccuracy = 64.86486486486487\n",
      "Epoch 39: \tLoss = 24.773214251224676 \tAccuracy = 64.86486486486487\n",
      "Epoch 40: \tLoss = 24.74332553454476 \tAccuracy = 64.86486486486487\n",
      "Epoch 41: \tLoss = 24.723955957285433 \tAccuracy = 64.86486486486487\n",
      "Epoch 42: \tLoss = 24.68833034659285 \tAccuracy = 64.86486486486487\n",
      "Epoch 43: \tLoss = 24.661179566461207 \tAccuracy = 64.86486486486487\n",
      "Epoch 44: \tLoss = 24.634908263105444 \tAccuracy = 67.56756756756756\n",
      "Epoch 45: \tLoss = 24.609453248195514 \tAccuracy = 67.56756756756756\n",
      "Epoch 46: \tLoss = 24.58474016461988 \tAccuracy = 67.56756756756756\n",
      "Epoch 47: \tLoss = 24.56070387654013 \tAccuracy = 67.56756756756756\n",
      "Epoch 48: \tLoss = 24.537287280040573 \tAccuracy = 67.56756756756756\n",
      "Epoch 49: \tLoss = 24.51444018092724 \tAccuracy = 67.56756756756756\n",
      "Epoch 50: \tLoss = 24.49211834279216 \tAccuracy = 67.56756756756756\n",
      "Epoch 51: \tLoss = 24.470282678029474 \tAccuracy = 67.56756756756756\n",
      "Epoch 52: \tLoss = 24.44889855862282 \tAccuracy = 67.56756756756756\n",
      "Epoch 53: \tLoss = 24.42793522757664 \tAccuracy = 67.56756756756756\n",
      "Epoch 54: \tLoss = 24.407365295153596 \tAccuracy = 67.56756756756756\n",
      "Epoch 55: \tLoss = 24.387164306760404 \tAccuracy = 67.56756756756756\n",
      "Epoch 56: \tLoss = 24.367310371515565 \tAccuracy = 67.56756756756756\n",
      "Epoch 57: \tLoss = 24.347783842332447 \tAccuracy = 67.56756756756756\n",
      "Epoch 58: \tLoss = 24.328567039833302 \tAccuracy = 67.56756756756756\n",
      "Epoch 59: \tLoss = 24.309644013636255 \tAccuracy = 67.56756756756756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d0c7cfc7bc88>:30: RuntimeWarning: invalid value encountered in log\n",
      "  return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: \tLoss = 24.29100033557347 \tAccuracy = 64.86486486486487\n",
      "Epoch 61: \tLoss = 24.272622920245723 \tAccuracy = 64.86486486486487\n",
      "Epoch 62: \tLoss = 24.25449986902301 \tAccuracy = 64.86486486486487\n",
      "Epoch 63: \tLoss = 24.236620334192406 \tAccuracy = 64.86486486486487\n",
      "Epoch 64: \tLoss = 24.218974400448516 \tAccuracy = 64.86486486486487\n",
      "Epoch 65: \tLoss = 24.20155298133846 \tAccuracy = 64.86486486486487\n",
      "Epoch 66: \tLoss = 24.184347728623514 \tAccuracy = 64.86486486486487\n",
      "Epoch 67: \tLoss = 24.167350952815944 \tAccuracy = 64.86486486486487\n",
      "Epoch 68: \tLoss = 24.150555553399258 \tAccuracy = 64.86486486486487\n",
      "Epoch 69: \tLoss = 24.13395495745307 \tAccuracy = 64.86486486486487\n",
      "Epoch 70: \tLoss = 24.1175430655833 \tAccuracy = 64.86486486486487\n",
      "Epoch 71: \tLoss = 24.101314204212255 \tAccuracy = 64.86486486486487\n",
      "Epoch 72: \tLoss = 24.085263083413615 \tAccuracy = 64.86486486486487\n",
      "Epoch 73: \tLoss = 24.069384759588736 \tAccuracy = 64.86486486486487\n",
      "Epoch 74: \tLoss = 24.053674602376486 \tAccuracy = 64.86486486486487\n",
      "Epoch 75: \tLoss = 24.03812826527003 \tAccuracy = 64.86486486486487\n",
      "Epoch 76: \tLoss = 24.02274165948443 \tAccuracy = 64.86486486486487\n",
      "Epoch 77: \tLoss = 24.00751093067889 \tAccuracy = 64.86486486486487\n",
      "Epoch 78: \tLoss = 23.992432438189354 \tAccuracy = 64.86486486486487\n",
      "Epoch 79: \tLoss = 23.97750273647172 \tAccuracy = 64.86486486486487\n",
      "Epoch 80: \tLoss = 23.962718558494437 \tAccuracy = 64.86486486486487\n",
      "Epoch 81: \tLoss = 23.948076800852476 \tAccuracy = 64.86486486486487\n",
      "Epoch 82: \tLoss = 23.933574510403417 \tAccuracy = 64.86486486486487\n",
      "Epoch 83: \tLoss = 23.919208872251318 \tAccuracy = 64.86486486486487\n",
      "Epoch 84: \tLoss = 23.9049771989255 \tAccuracy = 64.86486486486487\n",
      "Epoch 85: \tLoss = 23.890876920620478 \tAccuracy = 64.86486486486487\n",
      "Epoch 86: \tLoss = 23.876905576379016 \tAccuracy = 64.86486486486487\n",
      "Epoch 87: \tLoss = 23.863060806115108 \tAccuracy = 64.86486486486487\n",
      "Epoch 88: \tLoss = 23.849340343385407 \tAccuracy = 64.86486486486487\n",
      "Epoch 89: \tLoss = 23.835742008829065 \tAccuracy = 64.86486486486487\n",
      "Epoch 90: \tLoss = 23.822263704204794 \tAccuracy = 64.86486486486487\n",
      "Epoch 91: \tLoss = 23.808903406962592 \tAccuracy = 64.86486486486487\n",
      "Epoch 92: \tLoss = 23.79565916529471 \tAccuracy = 64.86486486486487\n",
      "Epoch 93: \tLoss = 23.785338328662867 \tAccuracy = 64.86486486486487\n",
      "Epoch 94: \tLoss = 23.771705197265703 \tAccuracy = 64.86486486486487\n",
      "Epoch 95: \tLoss = 23.760103158358397 \tAccuracy = 64.86486486486487\n",
      "Epoch 96: \tLoss = 23.746838902885457 \tAccuracy = 64.86486486486487\n",
      "Epoch 97: \tLoss = 23.735566510711692 \tAccuracy = 64.86486486486487\n",
      "Epoch 98: \tLoss = 23.722500941365922 \tAccuracy = 64.86486486486487\n",
      "Epoch 99: \tLoss = 23.71169093621549 \tAccuracy = 64.86486486486487\n",
      "Epoch 100: \tLoss = 23.69864932251041 \tAccuracy = 64.86486486486487\n",
      "Epoch 101: \tLoss = 23.68841716210119 \tAccuracy = 64.86486486486487\n",
      "Epoch 102: \tLoss = 23.675248428454132 \tAccuracy = 64.86486486486487\n",
      "Epoch 103: \tLoss = 23.665694778640724 \tAccuracy = 64.86486486486487\n",
      "Epoch 104: \tLoss = 23.65498581365661 \tAccuracy = 64.86486486486487\n",
      "Epoch 105: \tLoss = 23.64155866024213 \tAccuracy = 64.86486486486487\n",
      "Epoch 106: \tLoss = 23.63183931825545 \tAccuracy = 64.86486486486487\n",
      "Epoch 107: \tLoss = 23.621589124286018 \tAccuracy = 64.86486486486487\n",
      "Epoch 108: \tLoss = 23.608771615359828 \tAccuracy = 64.86486486486487\n",
      "Epoch 109: \tLoss = 23.599206047848963 \tAccuracy = 64.86486486486487\n",
      "Epoch 110: \tLoss = 23.58934000612128 \tAccuracy = 64.86486486486487\n",
      "Epoch 111: \tLoss = 23.57682028836835 \tAccuracy = 64.86486486486487\n",
      "Epoch 112: \tLoss = 23.567645941124063 \tAccuracy = 64.86486486486487\n",
      "Epoch 113: \tLoss = 23.5581043285554 \tAccuracy = 64.86486486486487\n",
      "Epoch 114: \tLoss = 23.545627510545195 \tAccuracy = 64.86486486486487\n",
      "Epoch 115: \tLoss = 23.537039986755662 \tAccuracy = 64.86486486486487\n",
      "Epoch 116: \tLoss = 23.527775173199984 \tAccuracy = 64.86486486486487\n",
      "Epoch 117: \tLoss = 23.517533588769723 \tAccuracy = 64.86486486486487\n",
      "Epoch 118: \tLoss = 23.50558370408765 \tAccuracy = 67.56756756756756\n",
      "Epoch 119: \tLoss = 23.497206760970744 \tAccuracy = 67.56756756756756\n",
      "Epoch 120: \tLoss = 23.488323356292693 \tAccuracy = 67.56756756756756\n",
      "Epoch 121: \tLoss = 23.478473224283 \tAccuracy = 67.56756756756756\n",
      "Epoch 122: \tLoss = 23.466691144811158 \tAccuracy = 67.56756756756756\n",
      "Epoch 123: \tLoss = 23.45884180579447 \tAccuracy = 67.56756756756756\n",
      "Epoch 124: \tLoss = 23.450271528888948 \tAccuracy = 67.56756756756756\n",
      "Epoch 125: \tLoss = 23.440763277455037 \tAccuracy = 67.56756756756756\n",
      "Epoch 126: \tLoss = 23.43131983269916 \tAccuracy = 67.56756756756756\n",
      "Epoch 127: \tLoss = 23.419906056773172 \tAccuracy = 67.56756756756756\n",
      "Epoch 128: \tLoss = 23.412471525469844 \tAccuracy = 67.56756756756756\n",
      "Epoch 129: \tLoss = 23.404266589699148 \tAccuracy = 67.56756756756756\n",
      "Epoch 130: \tLoss = 23.395150727093977 \tAccuracy = 67.56756756756756\n",
      "Epoch 131: \tLoss = 23.386085492063543 \tAccuracy = 67.56756756756756\n",
      "Epoch 132: \tLoss = 23.377103484662783 \tAccuracy = 67.56756756756756\n",
      "Epoch 133: \tLoss = 23.36820277520648 \tAccuracy = 67.56756756756756\n",
      "Epoch 134: \tLoss = 23.357476445200838 \tAccuracy = 67.56756756756756\n",
      "Epoch 135: \tLoss = 23.350315707808424 \tAccuracy = 67.56756756756756\n",
      "Epoch 136: \tLoss = 23.342571435079847 \tAccuracy = 67.56756756756756\n",
      "Epoch 137: \tLoss = 23.333944379830196 \tAccuracy = 67.56756756756756\n",
      "Epoch 138: \tLoss = 23.325351437327704 \tAccuracy = 67.56756756756756\n",
      "Epoch 139: \tLoss = 23.31682726172179 \tAccuracy = 67.56756756756756\n",
      "Epoch 140: \tLoss = 23.30837100551668 \tAccuracy = 67.56756756756756\n",
      "Epoch 141: \tLoss = 23.299980529018598 \tAccuracy = 67.56756756756756\n",
      "Epoch 142: \tLoss = 23.291653774661178 \tAccuracy = 67.56756756756756\n",
      "Epoch 143: \tLoss = 23.283388812044088 \tAccuracy = 67.56756756756756\n",
      "Epoch 144: \tLoss = 23.273318640839975 \tAccuracy = 67.56756756756756\n",
      "Epoch 145: \tLoss = 23.266661844068835 \tAccuracy = 67.56756756756756\n",
      "Epoch 146: \tLoss = 23.259449570047096 \tAccuracy = 67.56756756756756\n",
      "Epoch 147: \tLoss = 23.25140496705103 \tAccuracy = 67.56756756756756\n",
      "Epoch 148: \tLoss = 23.24337797046149 \tAccuracy = 67.56756756756756\n",
      "Epoch 149: \tLoss = 23.23540500665292 \tAccuracy = 67.56756756756756\n",
      "Epoch 150: \tLoss = 23.22748626042605 \tAccuracy = 67.56756756756756\n",
      "Epoch 151: \tLoss = 23.219620377017577 \tAccuracy = 67.56756756756756\n",
      "Epoch 152: \tLoss = 23.211806007926462 \tAccuracy = 67.56756756756756\n",
      "Epoch 153: \tLoss = 23.204041874856955 \tAccuracy = 67.56756756756756\n",
      "Epoch 154: \tLoss = 23.196326767329076 \tAccuracy = 67.56756756756756\n",
      "Epoch 155: \tLoss = 23.188659537730203 \tAccuracy = 67.56756756756756\n",
      "Epoch 156: \tLoss = 23.181039096666108 \tAccuracy = 67.56756756756756\n",
      "Epoch 157: \tLoss = 23.173464408703545 \tAccuracy = 67.56756756756756\n",
      "Epoch 158: \tLoss = 23.16593448847378 \tAccuracy = 67.56756756756756\n",
      "Epoch 159: \tLoss = 23.158448397103765 \tAccuracy = 67.56756756756756\n",
      "Epoch 160: \tLoss = 23.15100523894533 \tAccuracy = 67.56756756756756\n",
      "Epoch 161: \tLoss = 23.14360415857503 \tAccuracy = 67.56756756756756\n",
      "Epoch 162: \tLoss = 23.13624433804022 \tAccuracy = 67.56756756756756\n",
      "Epoch 163: \tLoss = 23.128924994329303 \tAccuracy = 67.56756756756756\n",
      "Epoch 164: \tLoss = 23.12164537704618 \tAccuracy = 67.56756756756756\n",
      "Epoch 165: \tLoss = 23.11440476627066 \tAccuracy = 67.56756756756756\n",
      "Epoch 166: \tLoss = 23.10720247058869 \tAccuracy = 67.56756756756756\n",
      "Epoch 167: \tLoss = 23.100037825277322 \tAccuracy = 67.56756756756756\n",
      "Epoch 168: \tLoss = 23.09291019063121 \tAccuracy = 67.56756756756756\n",
      "Epoch 169: \tLoss = 23.085818950418172 \tAccuracy = 67.56756756756756\n",
      "Epoch 170: \tLoss = 23.07876351045305 \tAccuracy = 67.56756756756756\n",
      "Epoch 171: \tLoss = 23.071743297279504 \tAccuracy = 67.56756756756756\n",
      "Epoch 172: \tLoss = 23.064757756950943 \tAccuracy = 67.56756756756756\n",
      "Epoch 173: \tLoss = 23.057806353901917 \tAccuracy = 67.56756756756756\n",
      "Epoch 174: \tLoss = 23.05088856990279 \tAccuracy = 67.56756756756756\n",
      "Epoch 175: \tLoss = 23.04400390309045 \tAccuracy = 67.56756756756756\n",
      "Epoch 176: \tLoss = 23.037151867069174 \tAccuracy = 67.56756756756756\n",
      "Epoch 177: \tLoss = 23.030331990075574 \tAccuracy = 67.56756756756756\n",
      "Epoch 178: \tLoss = 23.023543814202732 \tAccuracy = 67.56756756756756\n",
      "Epoch 179: \tLoss = 23.016786894678525 \tAccuracy = 67.56756756756756\n",
      "Epoch 180: \tLoss = 23.01006079919403 \tAccuracy = 67.56756756756756\n",
      "Epoch 181: \tLoss = 23.003365107277805 \tAccuracy = 67.56756756756756\n",
      "Epoch 182: \tLoss = 22.996699409712697 \tAccuracy = 67.56756756756756\n",
      "Epoch 183: \tLoss = 22.99006330799169 \tAccuracy = 67.56756756756756\n",
      "Epoch 184: \tLoss = 22.983456413809733 \tAccuracy = 67.56756756756756\n",
      "Epoch 185: \tLoss = 22.97687834858901 \tAccuracy = 67.56756756756756\n",
      "Epoch 186: \tLoss = 22.970328743034827 \tAccuracy = 67.56756756756756\n",
      "Epoch 187: \tLoss = 22.96380723671996 \tAccuracy = 67.56756756756756\n",
      "Epoch 188: \tLoss = 22.957313477695358 \tAccuracy = 67.56756756756756\n",
      "Epoch 189: \tLoss = 22.950847122125083 \tAccuracy = 67.56756756756756\n",
      "Epoch 190: \tLoss = 22.944407833943927 \tAccuracy = 67.56756756756756\n",
      "Epoch 191: \tLoss = 22.937995284535674 \tAccuracy = 67.56756756756756\n",
      "Epoch 192: \tLoss = 22.93160915243105 \tAccuracy = 67.56756756756756\n",
      "Epoch 193: \tLoss = 22.925249123023384 \tAccuracy = 67.56756756756756\n",
      "Epoch 194: \tLoss = 22.918914888301096 \tAccuracy = 67.56756756756756\n",
      "Epoch 195: \tLoss = 22.912606146595678 \tAccuracy = 67.56756756756756\n",
      "Epoch 196: \tLoss = 22.906322602344048 \tAccuracy = 67.56756756756756\n",
      "Epoch 197: \tLoss = 22.900063965864405 \tAccuracy = 67.56756756756756\n",
      "Epoch 198: \tLoss = 22.89382995314446 \tAccuracy = 67.56756756756756\n",
      "Epoch 199: \tLoss = 22.887620285641464 \tAccuracy = 67.56756756756756\n",
      "Epoch 200: \tLoss = 22.881434690092924 \tAccuracy = 67.56756756756756\n",
      "Epoch 201: \tLoss = 22.875272898337563 \tAccuracy = 67.56756756756756\n",
      "Epoch 202: \tLoss = 22.869134647145618 \tAccuracy = 67.56756756756756\n",
      "Epoch 203: \tLoss = 22.863019678058095 \tAccuracy = 67.56756756756756\n",
      "Epoch 204: \tLoss = 22.856927737234194 \tAccuracy = 67.56756756756756\n",
      "Epoch 205: \tLoss = 22.850858575306393 \tAccuracy = 67.56756756756756\n",
      "Epoch 206: \tLoss = 22.84481194724289 \tAccuracy = 67.56756756756756\n",
      "Epoch 207: \tLoss = 22.83878761221669 \tAccuracy = 67.56756756756756\n",
      "Epoch 208: \tLoss = 22.832785333481127 \tAccuracy = 67.56756756756756\n",
      "Epoch 209: \tLoss = 22.82680487825118 \tAccuracy = 67.56756756756756\n",
      "Epoch 210: \tLoss = 22.82084601759056 \tAccuracy = 67.56756756756756\n",
      "Epoch 211: \tLoss = 22.814908526303867 \tAccuracy = 67.56756756756756\n",
      "Epoch 212: \tLoss = 22.808992182833748 \tAccuracy = 67.56756756756756\n",
      "Epoch 213: \tLoss = 22.80309676916265 \tAccuracy = 67.56756756756756\n",
      "Epoch 214: \tLoss = 22.797222070718952 \tAccuracy = 67.56756756756756\n",
      "Epoch 215: \tLoss = 22.791367876287143 \tAccuracy = 67.56756756756756\n",
      "Epoch 216: \tLoss = 22.785533977921855 \tAccuracy = 67.56756756756756\n",
      "Epoch 217: \tLoss = 22.779720170865662 \tAccuracy = 67.56756756756756\n",
      "Epoch 218: \tLoss = 22.77392625347006 \tAccuracy = 67.56756756756756\n",
      "Epoch 219: \tLoss = 22.768152027119925 \tAccuracy = 67.56756756756756\n",
      "Epoch 220: \tLoss = 22.762397296160856 \tAccuracy = 67.56756756756756\n",
      "Epoch 221: \tLoss = 22.75666186782952 \tAccuracy = 67.56756756756756\n",
      "Epoch 222: \tLoss = 22.750945552186607 \tAccuracy = 67.56756756756756\n",
      "Epoch 223: \tLoss = 22.745248162052462 \tAccuracy = 67.56756756756756\n",
      "Epoch 224: \tLoss = 22.739569512945128 \tAccuracy = 67.56756756756756\n",
      "Epoch 225: \tLoss = 22.73390942302069 \tAccuracy = 67.56756756756756\n",
      "Epoch 226: \tLoss = 22.728267713015768 \tAccuracy = 67.56756756756756\n",
      "Epoch 227: \tLoss = 22.7226442061922 \tAccuracy = 67.56756756756756\n",
      "Epoch 228: \tLoss = 22.71703872828359 \tAccuracy = 67.56756756756756\n",
      "Epoch 229: \tLoss = 22.71145110744375 \tAccuracy = 67.56756756756756\n",
      "Epoch 230: \tLoss = 22.705881174196996 \tAccuracy = 67.56756756756756\n",
      "Epoch 231: \tLoss = 22.700328761389994 \tAccuracy = 67.56756756756756\n",
      "Epoch 232: \tLoss = 22.69479370414532 \tAccuracy = 67.56756756756756\n",
      "Epoch 233: \tLoss = 22.689275839816535 \tAccuracy = 67.56756756756756\n",
      "Epoch 234: \tLoss = 22.683775007944636 \tAccuracy = 67.56756756756756\n",
      "Epoch 235: \tLoss = 22.678291050216 \tAccuracy = 67.56756756756756\n",
      "Epoch 236: \tLoss = 22.67282381042159 \tAccuracy = 67.56756756756756\n",
      "Epoch 237: \tLoss = 22.667373134417375 \tAccuracy = 67.56756756756756\n",
      "Epoch 238: \tLoss = 22.66193887008606 \tAccuracy = 67.56756756756756\n",
      "Epoch 239: \tLoss = 22.656520867299896 \tAccuracy = 67.56756756756756\n",
      "Epoch 240: \tLoss = 22.651118977884533 \tAccuracy = 67.56756756756756\n",
      "Epoch 241: \tLoss = 22.64573305558406 \tAccuracy = 67.56756756756756\n",
      "Epoch 242: \tLoss = 22.640362956026905 \tAccuracy = 67.56756756756756\n",
      "Epoch 243: \tLoss = 22.635008536692762 \tAccuracy = 67.56756756756756\n",
      "Epoch 244: \tLoss = 22.629669656880445 \tAccuracy = 67.56756756756756\n",
      "Epoch 245: \tLoss = 22.62434617767656 \tAccuracy = 67.56756756756756\n",
      "Epoch 246: \tLoss = 22.619037961925073 \tAccuracy = 67.56756756756756\n",
      "Epoch 247: \tLoss = 22.613744874197668 \tAccuracy = 67.56756756756756\n",
      "Epoch 248: \tLoss = 22.608466780764843 \tAccuracy = 67.56756756756756\n",
      "Epoch 249: \tLoss = 22.603203549567812 \tAccuracy = 67.56756756756756\n",
      "Epoch 250: \tLoss = 22.597955050191075 \tAccuracy = 67.56756756756756\n",
      "Epoch 251: \tLoss = 22.592721153835665 \tAccuracy = 67.56756756756756\n",
      "Epoch 252: \tLoss = 22.587501733293067 \tAccuracy = 67.56756756756756\n",
      "Epoch 253: \tLoss = 22.58229666291981 \tAccuracy = 67.56756756756756\n",
      "Epoch 254: \tLoss = 22.57710581861257 \tAccuracy = 67.56756756756756\n",
      "Epoch 255: \tLoss = 22.57192907778395 \tAccuracy = 67.56756756756756\n",
      "Epoch 256: \tLoss = 22.566766319338786 \tAccuracy = 67.56756756756756\n",
      "Epoch 257: \tLoss = 22.561617423651 \tAccuracy = 67.56756756756756\n",
      "Epoch 258: \tLoss = 22.55648227254093 \tAccuracy = 67.56756756756756\n",
      "Epoch 259: \tLoss = 22.551360749253295 \tAccuracy = 67.56756756756756\n",
      "Epoch 260: \tLoss = 22.546252738435495 \tAccuracy = 67.56756756756756\n",
      "Epoch 261: \tLoss = 22.54115812611645 \tAccuracy = 67.56756756756756\n",
      "Epoch 262: \tLoss = 22.53607679968593 \tAccuracy = 67.56756756756756\n",
      "Epoch 263: \tLoss = 22.531008647874245 \tAccuracy = 67.56756756756756\n",
      "Epoch 264: \tLoss = 22.525953560732418 \tAccuracy = 67.56756756756756\n",
      "Epoch 265: \tLoss = 22.520911429612745 \tAccuracy = 67.56756756756756\n",
      "Epoch 266: \tLoss = 22.51588214714977 \tAccuracy = 67.56756756756756\n",
      "Epoch 267: \tLoss = 22.51086560724156 \tAccuracy = 67.56756756756756\n",
      "Epoch 268: \tLoss = 22.505861705031535 \tAccuracy = 67.56756756756756\n",
      "Epoch 269: \tLoss = 22.500870336890436 \tAccuracy = 67.56756756756756\n",
      "Epoch 270: \tLoss = 22.495891400398847 \tAccuracy = 67.56756756756756\n",
      "Epoch 271: \tLoss = 22.49092479432983 \tAccuracy = 67.56756756756756\n",
      "Epoch 272: \tLoss = 22.485970418632167 \tAccuracy = 67.56756756756756\n",
      "Epoch 273: \tLoss = 22.481028174413677 \tAccuracy = 67.56756756756756\n",
      "Epoch 274: \tLoss = 22.476097963924936 \tAccuracy = 67.56756756756756\n",
      "Epoch 275: \tLoss = 22.471179690543337 \tAccuracy = 67.56756756756756\n",
      "Epoch 276: \tLoss = 22.466273258757397 \tAccuracy = 67.56756756756756\n",
      "Epoch 277: \tLoss = 22.461378574151315 \tAccuracy = 67.56756756756756\n",
      "Epoch 278: \tLoss = 22.456495543389888 \tAccuracy = 67.56756756756756\n",
      "Epoch 279: \tLoss = 22.451624074203647 \tAccuracy = 67.56756756756756\n",
      "Epoch 280: \tLoss = 22.44676407537422 \tAccuracy = 67.56756756756756\n",
      "Epoch 281: \tLoss = 22.441915456720032 \tAccuracy = 67.56756756756756\n",
      "Epoch 282: \tLoss = 22.437078129082202 \tAccuracy = 67.56756756756756\n",
      "Epoch 283: \tLoss = 22.43225200431067 \tAccuracy = 67.56756756756756\n",
      "Epoch 284: \tLoss = 22.427436995250588 \tAccuracy = 67.56756756756756\n",
      "Epoch 285: \tLoss = 22.422633015728938 \tAccuracy = 67.56756756756756\n",
      "Epoch 286: \tLoss = 22.417839980541352 \tAccuracy = 67.56756756756756\n",
      "Epoch 287: \tLoss = 22.41305780543918 \tAccuracy = 67.56756756756756\n",
      "Epoch 288: \tLoss = 22.40828640711674 \tAccuracy = 67.56756756756756\n",
      "Epoch 289: \tLoss = 22.403525703198795 \tAccuracy = 67.56756756756756\n",
      "Epoch 290: \tLoss = 22.398775612228228 \tAccuracy = 67.56756756756756\n",
      "Epoch 291: \tLoss = 22.394036053653938 \tAccuracy = 67.56756756756756\n",
      "Epoch 292: \tLoss = 22.389306947818834 \tAccuracy = 67.56756756756756\n",
      "Epoch 293: \tLoss = 22.384588215948213 \tAccuracy = 67.56756756756756\n",
      "Epoch 294: \tLoss = 22.37987978013809 \tAccuracy = 67.56756756756756\n",
      "Epoch 295: \tLoss = 22.375181563343883 \tAccuracy = 67.56756756756756\n",
      "Epoch 296: \tLoss = 22.370493489369174 \tAccuracy = 67.56756756756756\n",
      "Epoch 297: \tLoss = 22.36581548285474 \tAccuracy = 67.56756756756756\n",
      "Epoch 298: \tLoss = 22.3611474692676 \tAccuracy = 67.56756756756756\n",
      "Epoch 299: \tLoss = 22.35648937489042 \tAccuracy = 67.56756756756756\n",
      "Epoch 300: \tLoss = 22.351841126810974 \tAccuracy = 67.56756756756756\n",
      "Epoch 301: \tLoss = 22.34720265291168 \tAccuracy = 67.56756756756756\n",
      "Epoch 302: \tLoss = 22.342573881859504 \tAccuracy = 67.56756756756756\n",
      "Epoch 303: \tLoss = 22.337954743095835 \tAccuracy = 67.56756756756756\n",
      "Epoch 304: \tLoss = 22.333345166826554 \tAccuracy = 67.56756756756756\n",
      "Epoch 305: \tLoss = 22.32874508401237 \tAccuracy = 67.56756756756756\n",
      "Epoch 306: \tLoss = 22.324154426359073 \tAccuracy = 67.56756756756756\n",
      "Epoch 307: \tLoss = 22.31957312630818 \tAccuracy = 67.56756756756756\n",
      "Epoch 308: \tLoss = 22.315001117027464 \tAccuracy = 67.56756756756756\n",
      "Epoch 309: \tLoss = 22.310438332401873 \tAccuracy = 67.56756756756756\n",
      "Epoch 310: \tLoss = 22.305884707024372 \tAccuracy = 67.56756756756756\n",
      "Epoch 311: \tLoss = 22.30134017618706 \tAccuracy = 67.56756756756756\n",
      "Epoch 312: \tLoss = 22.296804675872337 \tAccuracy = 67.56756756756756\n",
      "Epoch 313: \tLoss = 22.29227814274421 \tAccuracy = 67.56756756756756\n",
      "Epoch 314: \tLoss = 22.28776051413974 \tAccuracy = 67.56756756756756\n",
      "Epoch 315: \tLoss = 22.28325172806064 \tAccuracy = 67.56756756756756\n",
      "Epoch 316: \tLoss = 22.27875172316489 \tAccuracy = 67.56756756756756\n",
      "Epoch 317: \tLoss = 22.274260438758596 \tAccuracy = 67.56756756756756\n",
      "Epoch 318: \tLoss = 22.269777814787872 \tAccuracy = 67.56756756756756\n",
      "Epoch 319: \tLoss = 22.265303791830867 \tAccuracy = 67.56756756756756\n",
      "Epoch 320: \tLoss = 22.26083831108996 \tAccuracy = 67.56756756756756\n",
      "Epoch 321: \tLoss = 22.256381314383923 \tAccuracy = 67.56756756756756\n",
      "Epoch 322: \tLoss = 22.251932744140316 \tAccuracy = 64.86486486486487\n",
      "Epoch 323: \tLoss = 22.247492543388034 \tAccuracy = 64.86486486486487\n",
      "Epoch 324: \tLoss = 22.243060655749726 \tAccuracy = 64.86486486486487\n",
      "Epoch 325: \tLoss = 22.23863702543457 \tAccuracy = 64.86486486486487\n",
      "Epoch 326: \tLoss = 22.23422159723105 \tAccuracy = 64.86486486486487\n",
      "Epoch 327: \tLoss = 22.229814316499763 \tAccuracy = 64.86486486486487\n",
      "Epoch 328: \tLoss = 22.225415129166432 \tAccuracy = 64.86486486486487\n",
      "Epoch 329: \tLoss = 22.221023981714985 \tAccuracy = 64.86486486486487\n",
      "Epoch 330: \tLoss = 22.21664082118069 \tAccuracy = 64.86486486486487\n",
      "Epoch 331: \tLoss = 22.21226559514342 \tAccuracy = 64.86486486486487\n",
      "Epoch 332: \tLoss = 22.20789825172102 \tAccuracy = 64.86486486486487\n",
      "Epoch 333: \tLoss = 22.203538739562703 \tAccuracy = 64.86486486486487\n",
      "Epoch 334: \tLoss = 22.199187007842596 \tAccuracy = 64.86486486486487\n",
      "Epoch 335: \tLoss = 22.18651330343284 \tAccuracy = 64.86486486486487\n",
      "Epoch 336: \tLoss = 22.177440598880885 \tAccuracy = 64.86486486486487\n",
      "Epoch 337: \tLoss = 22.167821431924253 \tAccuracy = 64.86486486486487\n",
      "Epoch 338: \tLoss = 22.15818508014147 \tAccuracy = 64.86486486486487\n",
      "Epoch 339: \tLoss = 22.148582227147294 \tAccuracy = 64.86486486486487\n",
      "Epoch 340: \tLoss = 22.1390156791583 \tAccuracy = 64.86486486486487\n",
      "Epoch 341: \tLoss = 22.129483606655626 \tAccuracy = 64.86486486486487\n",
      "Epoch 342: \tLoss = 22.11998382404628 \tAccuracy = 64.86486486486487\n",
      "Epoch 343: \tLoss = 22.11051421059546 \tAccuracy = 64.86486486486487\n",
      "Epoch 344: \tLoss = 22.101072747630916 \tAccuracy = 64.86486486486487\n",
      "Epoch 345: \tLoss = 22.091657517641085 \tAccuracy = 64.86486486486487\n",
      "Epoch 346: \tLoss = 22.082266699853097 \tAccuracy = 64.86486486486487\n",
      "Epoch 347: \tLoss = 22.07289856575244 \tAccuracy = 64.86486486486487\n",
      "Epoch 348: \tLoss = 22.06355147487261 \tAccuracy = 64.86486486486487\n",
      "Epoch 349: \tLoss = 22.05422387086655 \tAccuracy = 64.86486486486487\n",
      "Epoch 350: \tLoss = 22.04491427784143 \tAccuracy = 64.86486486486487\n",
      "Epoch 351: \tLoss = 22.03562129693648 \tAccuracy = 64.86486486486487\n",
      "Epoch 352: \tLoss = 22.026343603125007 \tAccuracy = 64.86486486486487\n",
      "Epoch 353: \tLoss = 22.01707994222319 \tAccuracy = 64.86486486486487\n",
      "Epoch 354: \tLoss = 22.00782912808932 \tAccuracy = 64.86486486486487\n",
      "Epoch 355: \tLoss = 21.99859003999884 \tAccuracy = 64.86486486486487\n",
      "Epoch 356: \tLoss = 21.98936162018117 \tAccuracy = 64.86486486486487\n",
      "Epoch 357: \tLoss = 21.980142871505684 \tAccuracy = 64.86486486486487\n",
      "Epoch 358: \tLoss = 21.97093285530508 \tAccuracy = 64.86486486486487\n",
      "Epoch 359: \tLoss = 21.96173068932503 \tAccuracy = 64.86486486486487\n",
      "Epoch 360: \tLoss = 21.952535545790248 \tAccuracy = 64.86486486486487\n",
      "Epoch 361: \tLoss = 21.943346649577414 \tAccuracy = 64.86486486486487\n",
      "Epoch 362: \tLoss = 21.933382845500944 \tAccuracy = 64.86486486486487\n",
      "Epoch 363: \tLoss = 21.925183444225432 \tAccuracy = 64.86486486486487\n",
      "Epoch 364: \tLoss = 21.916333761459242 \tAccuracy = 64.86486486486487\n",
      "Epoch 365: \tLoss = 21.90720088226753 \tAccuracy = 70.27027027027027\n",
      "Epoch 366: \tLoss = 21.897207966489972 \tAccuracy = 70.27027027027027\n",
      "Epoch 367: \tLoss = 21.889125666404695 \tAccuracy = 70.27027027027027\n",
      "Epoch 368: \tLoss = 21.88028120411397 \tAccuracy = 70.27027027027027\n",
      "Epoch 369: \tLoss = 21.871160268664156 \tAccuracy = 70.27027027027027\n",
      "Epoch 370: \tLoss = 21.861363811674707 \tAccuracy = 70.27027027027027\n",
      "Epoch 371: \tLoss = 21.853148388909837 \tAccuracy = 70.27027027027027\n",
      "Epoch 372: \tLoss = 21.844309583473425 \tAccuracy = 70.27027027027027\n",
      "Epoch 373: \tLoss = 21.834527945513535 \tAccuracy = 70.27027027027027\n",
      "Epoch 374: \tLoss = 21.826381406692715 \tAccuracy = 70.27027027027027\n",
      "Epoch 375: \tLoss = 21.81754185349395 \tAccuracy = 70.27027027027027\n",
      "Epoch 376: \tLoss = 21.81054148448076 \tAccuracy = 72.97297297297297\n",
      "Epoch 377: \tLoss = 21.806670084000686 \tAccuracy = 72.97297297297297\n",
      "Epoch 378: \tLoss = 21.80163379261043 \tAccuracy = 72.97297297297297\n",
      "Epoch 379: \tLoss = 21.798131995775236 \tAccuracy = 72.97297297297297\n",
      "Epoch 380: \tLoss = 21.79296961426927 \tAccuracy = 72.97297297297297\n",
      "Epoch 381: \tLoss = 21.78963697168416 \tAccuracy = 72.97297297297297\n",
      "Epoch 382: \tLoss = 21.78437076764547 \tAccuracy = 72.97297297297297\n",
      "Epoch 383: \tLoss = 21.78116411263752 \tAccuracy = 72.97297297297297\n",
      "Epoch 384: \tLoss = 21.776855087832033 \tAccuracy = 72.97297297297297\n",
      "Epoch 385: \tLoss = 21.771828708302614 \tAccuracy = 72.97297297297297\n",
      "Epoch 386: \tLoss = 21.768090149739884 \tAccuracy = 72.97297297297297\n",
      "Epoch 387: \tLoss = 21.76332382449941 \tAccuracy = 72.97297297297297\n",
      "Epoch 388: \tLoss = 21.759681130945744 \tAccuracy = 72.97297297297297\n",
      "Epoch 389: \tLoss = 21.754914833930844 \tAccuracy = 72.97297297297297\n",
      "Epoch 390: \tLoss = 21.751299921552615 \tAccuracy = 72.97297297297297\n",
      "Epoch 391: \tLoss = 21.746558767084906 \tAccuracy = 72.97297297297297\n",
      "Epoch 392: \tLoss = 21.742942340090295 \tAccuracy = 72.97297297297297\n",
      "Epoch 393: \tLoss = 21.738253385286505 \tAccuracy = 72.97297297297297\n",
      "Epoch 394: \tLoss = 21.734609094205023 \tAccuracy = 72.97297297297297\n",
      "Epoch 395: \tLoss = 21.729997310165576 \tAccuracy = 72.97297297297297\n",
      "Epoch 396: \tLoss = 21.72537429571807 \tAccuracy = 72.97297297297297\n",
      "Epoch 397: \tLoss = 21.72256088448535 \tAccuracy = 72.97297297297297\n",
      "Epoch 398: \tLoss = 21.71753036354042 \tAccuracy = 72.97297297297297\n",
      "Epoch 399: \tLoss = 21.71431476113136 \tAccuracy = 72.97297297297297\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "loss, acc = mlp.fit(X_train, y_train, learning_rate=0.001, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAp50lEQVR4nO3deZwU9Z3/8dd3enruiwEdUVAg4kGQAQc0nuHwiomCURON8VpXDCa6UeNK8ts1xrjmMObQ3f1Ff5uNhCCobIyu8ViVIRuDAiKHEu5L7mNmYO6je76/P6p66Jnpmekepo+aeT8fj35019nvKZpPVX+76lvGWouIiHhPWrIDiIhI76iAi4h4lAq4iIhHqYCLiHiUCriIiEelJ/LNhgwZYkeMGNGrZevq6sjNze3bQH1AuWKTqrkgdbMpV2z6Y64VK1YcstYe12mCtTZhj7KyMttb5eXlvV42npQrNqmay9rUzaZcsemPuYAPbYSaqiYUERGPUgEXEfEoFXAREY9SARcR8SgVcBERj1IBFxHxKBVwERGPSuiFPCIinrLhDdj9UZ+syh8Y2yfrCacCLiLSlVfvhboDgDnmVfkn/eux5+lABVxEJBJrob4CLnoApj18zKurX7z42DN1oDZwEZFImqrBBiF7ULKTdEkFXEQkkvpK5zm7OLk5uqECLiISSYNbwHNUwEVEvKWhynlWE4qIiMfUhwq4jsBFRLxFTSgiIh4VakLJKkpqjO70eB64MeZ04IWwUaOAh4HfueNHANuBr1hrq/o+oohInDRWQ7A58rTqPZBZCL7UvVymx2TW2g3AeABjjA/YDbwMzAbetdb+2Bgz2x1+KH5RRUT60N7V8OxksK1dzzP41ITF6Y1Ydy3TgC3W2h3GmOnAZHf8HGAxKuAi4hWHdzrF+8L7oOCkyPOcOCGxmWJknPtlRjmzMf8JfGSt/VdjzGFrbZE73gBVoeEOy8wEZgKUlJSULViwoFdBa2trycvL69Wy8aRcsUnVXJC62ZQrNtHmOn7//zJm3ZMsm/Rv1OcOS5lckUyZMmWFtXZipwmR7nQc6QFkAIeAEnf4cIfpVT2tQ3elTxzlil2qZlOu2ESda8Uca79fYG3Vp3HNE5Lsu9J/Aefoe787vN8YMxTAfT7Qq12LiEgytDQ6z/7s5OY4BrEU8BuB+WHDrwK3uq9vBV7pq1AiInEXaHCe+3sBN8bkApcCfwgb/WPgUmPMJuASd1hExBta3AKe7t0CHtVZKNbaOmBwh3EVOGeliIh4T0sD+DIgzbvXM3o3uYjIsWhp8HTzCaiAi8hAFWjwdPMJ6JZq0Qu2wJuznVsshRlz4AAcfC7yMqMvg/Ffi3+2vrL+dfj4xbi+RbfbK8lSNVu/zTX+6zD6kj7LE7OWRs8fgauAR+vgBlj+H5B/ImQePRk/t74e9h/sPH/1XjiwzlsFfNkz8OlSKBoet7focnulgFTN1i9zVe2AQFOSC3i9CviAEeqZ7Jpfw6jPt41evngxkydP7jz/q/fAxrcSk62vNFTByIvhpvgdhXe5vVJAqmbrl7me+9LR/1PJEmiE9KzkZjhGagOPVqx9A2cXO/fUi6GrgqSrr0rpu49IP5I96Og9J5OlpQH8OcnNcIxUwKMV6w1Oc4qhtQWaa+OXqa81VKZ05/XSj+QUHz0oSpaWBvDrCHxgCH3di+UIPHy5VBdodnY2KXz7KOlHsoud/xvJ/IaqJpQBpKHS+ceO9kePUFNEsr8mRqutiUhNKJIA2YOgNQBNNcnL0FKvJpQBo74qtqPT0JF6sr8mRivWJiKRY5EK/z9aGtWEMmDE2j4cKoSeOQIP3YFbR+CSAKnw/0M/Yg4gDTGeoRGa1ytt4B64A7f0I6nw/yPQ4Pk2cJ0HHq6uAg5tiDyteg8MLY1+XaEP6L41sGPJsWeLUeHhtbAjI/oFdq9wntWEIokQOlDYtbzPL6aJ6rNvrXMzY13I048svB22/bnr6adfGf260jMg93j46HfOI8EmAKyKcSFfBuQO6fswIh3lHQ/GB4t/5Dz6UEyf/ZzBPc+TwlTAw1XvhhEXwcXfiTDRwElnx7a+O96Cw5/2SbRYrVq9mvGlMXxjAMg7wfNHJOIR2YPgG+9BXd/fyCvqz35aOgw7p8/fP5FUwMPVV8LIz8OoyX2zvuJRziMJDn9K3/0dIvFQMgYY0+erHUifff2IGdLaCo2H9SOeiHiGCnhI42GwrfoRT0Q8QwU8ROdBi4jHqICHxNrXiYhIkqmAh+hSchHxGBXwEB2Bi4jHqICHhC4lVxu4iHiEzgNvDcKCm9xLyQ1kFSY7kYhIVHQE3lAFG99wLu39/D9Cmi/ZiUREoqIj8JZ65/ncb8DZNyc3i4hIDHQE3tLoPKsPEBHxGBXwQIPzrAIuIh6jAt7iFnCPd+wuIgNPVAXcGFNkjFlojFlvjFlnjDnPGFNsjHnbGLPJffbm+XctOgIXEW+K9gj8V8Cb1tozgFJgHTAbeNdaOxp41x32noDawEXEm3os4MaYQuBi4DcA1tpma+1hYDowx51tDjAjPhHjLHQWSroKuIh4i7HWdj+DMeOBZ4G/4Rx9rwD+AdhtrS1y5zFAVWi4w/IzgZkAJSUlZQsWLOhV0NraWvLy8nq1bHdO2PsuZ2x4ig/OfZbG7JKUyXWslCt2qZpNuWLTH3NNmTJlhbV2YqcJ1tpuH8BEIACc6w7/CvghcLjDfFU9rausrMz2Vnl5ea+Xjai53tpV8639rzut/X6BtTX7UyNXH1Gu2KVqNuWKTX/MBXxoI9TUaC7k2QXsstYudYcX4rR37zfGDLXW7jXGDAX6/uZ28bT+T/DyXUeHdRaKiHhMj23g1tp9wE5jzOnuqGk4zSmvAre6424FXolLwnip7bC/0Y+YIuIx0V5Kfw8wzxiTAWwFbscp/i8aY+4AdgBfiU/EOAn1Phji8ycnh4hIL0VVwK21q3Dawjua1qdpEqm+sud5RERS2MC9EjN0AwcREY8awAW8EszA/fNFxPsGbgWrr4TBpyY7hYhIrw3cAt5QBcWfSXYKEZFeG9gFfNApyU4hItJrA7OAB5qhuRZyhiQ7iYhIr/WPW6rtXQNzvuTcXedz34BLH+08T30l/Pt57tknbv8vOcUJjSki0pf6RwE/tBEaj0BmAexcFnmeii1Quw8+ew0UnQK+DBgzHYacpjvRi4gn9Y8CHropw+BTu75AJ3Tl5XnfgmFh1ySNvCi+2URE4qR/tIGHCnjBiZ0vkQ8JFfZsb944SESko/5RwEM3Ji44yWnjjtTHeejKS7V7i0g/0T8KeIt7W7SCodAagKaazvOErrzMVHu3iPQP/aSA1zs/SuYe5wxHakapr4SsIkjrH3+yiEj/qGaBRueeltlu80ikHzIbKtV8IiL9Sv8o4C0N4M86WqAj9TTYUHW0wIuI9AP9qIBnHz3DJFIBr6/UGSgi0q947zzwXStg7R+ODp9U5pyFEt6EsnIu7FnZfrmqHVDy2cTlFBGJM+8V8L/+Ata9Bv4cCDZBzmA4YdzRJpSSs2DncucRzhgYfm5yMouIxIH3Cnh9JZxyPtz+OrwxG1bNc5tQciDNB7PeS3ZCEZGE8F4beHhbtj/bOYUw0ADpWcnNJSKSYN4r4OGnA/qzj164489Obi4RkQTzVgG31j0CDyvg4Jx1ogIuIgOMtwp4cy20thw9Ag81m9RXqglFRAYcbxXw0Pnd4W3gADaoI3ARGXC8VcDbuoTt0ITS8bWIyADgrQIe6qSqrQklrGinq4CLyMDimfPAfYEGOLTTGWg7Ag9r9/arDVxEBhbPFPCJH34bGvc5A6FuY/05R2cIfy2SYlpaWti1axeNjY0xL1tYWMi6devikOrYKFdsosmVlZXFsGHD8Pv9Ua3TMwU8s+kgnHYFnDMTcgc7I8PPPMkqSkoukWjs2rWL/Px8RowYgTEmpmVramrIz8+PU7LeU67Y9JTLWktFRQW7du1i5MiRUa3TG23gwRbSbBBOmginTjs6PvyoW319SwprbGxk8ODBMRdvGTiMMQwePDimb2lRHYEbY7YDNUAQCFhrJxpjioEXgBHAduAr1toI/bj2gdBNizu2c4cPq6tYSXEq3tKTWD8jsRyBT7HWjrfWTnSHZwPvWmtHA++6w/ERcPdIHS/WCT/zRAVcpFs+n4/x48dTWlrK2WefzZIlSwDYs2cP1113XZLTpZ7t27fz/PPPJztGt46lCWU6MMd9PQeYccxputJS7zx3/KEy/NxvNaGIdCs7O5tVq1axevVqfvSjH/Hd734XgBNPPJGFCxf2yXsEg8E+WU8gEOiT9RyL7gp4KuSD6H/EtMD/GGMs8Iy19lmgxFq7152+DyiJtKAxZiYwE6CkpITFixfHHDKn7lPOAdZu2srBI2HL2yCT3ZeLP1jp3HU+wWpra3v1N8WbcsUuntkKCwupqanp1bLBYLDXy3YUWs/+/fvJz8+npqaGHTt28JWvfIWlS5cyb948Xn/9derr69m2bRtXXXUVP/zhDwG47777+Oijj2hoaGD69OnMnj2bmpoaxo4dy5e//GXKy8u5+uqrefXVV/nLX/4CwObNm7n99tvbhkO2bNnCfffdx6FDh/D5fMyZM4fdu3fz2GOPUVRUxMaNG3n//fe57777WLlyJenp6Tz++ONcfPHFrFu3jlmzZtHS0kJraytz585l6NCh3HrrrezZs4dAIMBDDz3Etdde2+49t27dygMPPEBFRQXZ2dk8/fTTnHbaaXzjG98gPz+flStXcuDAAR599FFmzJjBgw8+yMaNGxk3bhw33ngjgwYN4tVXX6Wuro5gMMi8efP45je/yfbt28nOzuapp55i7NixPP7442zbto2tW7dSUVHBt7/9bW677TbuvPNOpk+fzpe+9CUA7rjjDr785S/zxS9+sV3OxsbGqD+H0RbwC621u40xxwNvG2PWh0+01lq3uHfiFvtnASZOnGgnT54c5VuG2bMSlsNnx5XBGR2W/7PzNHnK1NjX2wcWL15Mr/6mOFOu2MUz27p169rOQPjBf6/lb3uqo142GAzi8/m6nWfMiQV8/6ru7zjV0NDARRddRGNjI3v37mXRokXk5+eTl5dHWloa+fn5ZGVl8cknn7By5UoyMzM5/fTTeeCBBxg+fDg//elPKS4uJhgMMm3aNNatW8d5552HMYahQ4eyatUqAP7yl7+wZcsWxo8fz0svvcQdd9zR6eyLu+66i9mzZ3PNNdfQ2NhIa2srVVVVrF69mk8++YSRI0fy5JNPkpGRwdq1a1m/fj2XXXYZGzduZO7cudx///3cdNNNNDc3EwwGef311zn55JN56623qKmpobW1tdN73n///fz6179m9OjRLF26lAcffJBFixbh9/upqKjg/fffZ/369Vx99dXcfPPNPPHEE/zsZz/jtddeA+C5555jzZo1rFmzhuLiYu655x4mTZrEa6+9xqJFi5g1axarVq0iMzOTdevW8cEHH1BXV8eECRO49tprufXWW3nmmWe48cYbOXLkCMuXL+f5558nPb19Gc7KymLChAnRfDSia0Kx1u52nw8ALwPnAPuNMUMB3OcDUb1jb7T9iKmrLUV6K9SEsn79et58801uueUWrO183DVt2jQKCwvJyspizJgx7NixA4AXX3yRs88+mwkTJrQV1ZCvfvWrba///u//nt/+9rcEg0FeeOEFvva1r7Vbf01NDbt37+aaa64BnIKVk+M0j55zzjltp9C99957fP3rXwfgjDPO4JRTTmHjxo2cd955PP744/zkJz9hx44dZGdnc9ZZZ/H222/z0EMPsWTJEgoLC9u9Z21tLUuWLOH6669n/Pjx3HXXXezdu7dt+owZM0hLS2PMmDHs37+/y2146aWXUlxc3Jbv5ptvBmDq1KlUVFRQXe3smKdPn052djZDhgxhypQpLFu2jAsvvJBNmzZx8OBB5s+fz7XXXtupeMeqx6WNMblAmrW2xn19GfAo8CpwK/Bj9/mVY0rSHRVw6Ud6OlLuKB7nNZ933nkcOnSIgwcPdpqWmZnZ9trn8xEIBNi2bRs/+9nPWL58OYMGDeK2226jqampbb7c3Ny219deey0/+MEPmDp1KmVlZQwePDjqXOHr6crXvvY1zj33XP70pz9x5ZVX8swzzzB16lQ++ugjXn/9dX74wx+ydOlSHn744bZlWltbKSoqavuW0N3fHGmnFks+6Hw2SWj4lltu4fe//z0LFizgt7/9bVTr6k40R+AlwHvGmNXAMuBP1to3cQr3pcaYTcAl7nB8dHUWioj0yvr16wkGg1EX1+rqanJzcyksLGT//v288cYbXc6blZXF5ZdfzqxZs7j99ts7Tc/Pz2fYsGH88Y9/BKCpqYn6+vpO81100UXMmzcPgI0bN/Lpp59y+umns3XrVkaNGsW9997L9OnTWbNmDXv27CEnJ4evf/3r3HvvvXz00Uft1lVQUMDIkSN56aWXAKdIr169utu/OfQbQVfC8y1evJghQ4ZQUFAAwCuvvEJjYyMVFRUsXryYSZMmAXDbbbfxy1/+EoAxY8Z0+/7R6PEI3Fq7FSiNML4CmNZ5iThoOwKPcLn8tIehcHhCYoh4WUNDA+PHjwecAjZnzpwe29ZDSktLmTBhAmeccQbDhw/nggsu6Hb+m266iZdffpnLLrss4vS5c+dy11138fDDD+P3+9sKa7i7776bWbNmcdZZZ5Gens5zzz1HZmYmL774InPnzsXv93PCCSfwve99j+XLl/Pggw+SlpZGWloazz77bKf1zZs3j1mzZvHYY4/R0tLCDTfcQGlpp9LWZty4cfh8PkpLS7ntttsYNKj9qcqPPPIIf/d3f8e4cePIyclhzpw57ZadMmUKhw4d4p//+Z858cQTqampoaSkhDPPPJMZM2Z0u/2iZq1N2KOsrMz2yorfWfv9AmurdvRu+TgqLy9PdoSIlCt28cz2t7/9rdfLVldX92GSvtNdrieeeML+0z/9UwLTHJXs7fX973/fPvHEE53GV1dX27q6Ojtq1Ch7+PDhLpeP9FkBPrQRaqo3+kIJHYGry1iRlHfNNdewZcsWFi1alOwoKaW8vJx77rmH++67r9OPrL3ljQIe0I+YIl7x8ssvJztCUj3yyCMRx0+ZMqXtjJ6+4o3OrFrcHzFVwEVE2nikgNfTatIhLbofXEREBgJvFPBAI61pmT3PJyIygHijgLc0EPRlJDuFiEhK8UwB1xG4yLH74x//iDGm3WXw4l3eKOCBBlrTdAQucqzmz5/PhRdeyPz58+P2Hn3Vpaz0zBsFvKVRTSgix6i2tpb33nuP3/zmNyxYsABwiu13vvMdxo4dy7hx43j66acBWL58Oeeffz6lpaWcc8451NTU8Nxzz/Gtb32rbX3XX399W7eneXl5PPDAA5SWlvL+++/z6KOPMmnSJMaOHcvMmTPb+hfZvHkzl1xySdtNJbZs2cItt9zSdlk9OFdxvvJK/LpW6k+8cR74FT9iwwd/ZVKyc4j0hTdmw76Po549OxgAXw//VU84C77QfXdEr7zyCldccQWnnXYagwcPZsWKFSxbtozt27ezatUq0tPTqayspLm5ma9+9au88MILTJo0ierqarKzuz+Ft66ujnPPPZcnn3wScPr5CHUmdfPNN/Paa69x1VVXcdNNN3XqRvaOO+7gF7/4BTNmzODIkSMsWbKk3WXp0jVvHIEPGU1d3ohkpxDxtPnz53PDDTcAcMMNNzB//nzeeecd7rrrrrZuTYuLi9mwYQNDhw5t64CpoKCgx25PfT5fuxsolJeXc+6553LWWWexaNEi1q5d22U3sp///Of7vJvVgUJbSSTRejhS7qihD7qTraysZNGiRXz88ccYYwgGgxhj2op0NNLT02ltbW0bDu9ONisrq61jrMbGRu6++24+/PBDhg8fziOPPNLjndb7upvVgcIbR+AickwWLlzIzTffzI4dO9i+fTs7d+5k5MiRlJaW8swzz7Td47GyspLTTz+dvXv3snz5csDpjzwQCDBixAhWrVpFa2srO3fuZMWKFRHfK1SshwwZQm1tbdv9NrvrRravu1kdKFTARQaA+fPntzVdhFx77bXs3buXk08+mXHjxlFaWsrzzz9PRkYGL7zwAvfccw+lpaVceumlNDY2csEFFzBy5EjGjBnDvffe22VXrEVFRdx5552MHTuWyy+/vN1R/ty5c3nqqacYN24c559/Pvv27QNo62Y1Uv/h0jU1oYgMAOXl5Z3G3XvvvW2vf/7zn7ebNmnSJD744INOy4RuYADt7xRUW1vbbr7HHnuMxx57rNPyo0ePjthLYX19PZs2beLGG2/s4S+RcDoCF5GkeueddzjzzDO55557+qyb1YFCR+AiklSXXHJJn3ezOlDoCFxExKNUwEUSJHQ1okhXYv2MqICLJEBWVhYVFRUq4tIlay0VFRVkZWVFvYzawEUSYNiwYezatYuDBw/GvGxjY2NM/6kTRbliE02urKwshg0bFvU6VcBFEsDv9zNy5MheLbt48WImTJjQx4mOnXLFJh651IQiIuJRKuAiIh6lAi4i4lEq4CIiHqUCLiLiUSrgIiIeFXUBN8b4jDErjTGvucMjjTFLjTGbjTEvGGN000oRkQSK5Qj8H4B1YcM/AX5hrT0VqALu6MtgIiLSvagKuDFmGPBF4D/cYQNMBRa6s8wBZsQhn4iIdMFE0zeDMWYh8CMgH/gOcBvwgXv0jTFmOPCGtXZshGVnAjMBSkpKyhYsWNCroLW1teTl5fVq2XhSrtikai5I3WzKFZv+mGvKlCkrrLUTO02w1nb7AL4E/Lv7ejLwGjAE2Bw2z3Dgk57WVVZWZnurvLy818vGk3LFJlVzWZu62ZQrNv0xF/ChjVBTo+kL5QLgamPMlUAWUAD8CigyxqRbawPAMGB3r3YtIiLSKz22gVtrv2utHWatHQHcACyy1t4ElAPXubPdCrwSt5QiItLJsZwH/hBwvzFmMzAY+E3fRBIRkWjE1J2stXYxsNh9vRU4p+8jiYhINHQlpoiIR6mAi4h4lAq4iIhHqYCLiHiUCriIiEepgIuIeJQKuIiIR6mAi4h4lAq4iIhHqYCLiHiUCriIiEepgIuIeJQKuIiIR6mAi4h4lAq4iIhHqYCLiHiUCriIiEepgIuIeJQKuIiIR6mAi4h4lAq4iIhHqYCLiHiUCriIiEepgIuIeJQKuIiIR6mAi4h4lAq4iIhHqYCLiHiUCriIiEepgIuIeFSPBdwYk2WMWWaMWW2MWWuM+YE7fqQxZqkxZrMx5gVjTEb844qISEg0R+BNwFRrbSkwHrjCGPM54CfAL6y1pwJVwB1xSykiIp30WMCto9Yd9LsPC0wFFrrj5wAz4hFQREQiM9banmcyxgesAE4F/g14AvjAPfrGGDMceMNaOzbCsjOBmQAlJSVlCxYs6FXQ2tpa8vLyerVsPClXbFI1F6RuNuWKTX/MNWXKlBXW2omdJlhro34ARUA5cCGwOWz8cOCTnpYvKyuzvVVeXm6ttba1tdX+ecMBu3pnVa/X1ZdCuVKNcsUuVbMpV2z6Yy7gQxuhpsZ0Foq19rBbwM8Diowx6e6kYcDuXu1aYmSM4cGFq3luyfZEvJ2ISMqK5iyU44wxRe7rbOBSYB1OIb/One1W4JU4ZezktJJ8Nu6vSdTbiYikpGiOwIcC5caYNcBy4G1r7WvAQ8D9xpjNwGDgN/GL2d7o4/PZfKCW1tae2+9FRPqr9J5msNauASZEGL8VOCceoXpy+gl5NLa0srOqnlMG5yYjgohI0nnySszRJfkArNurZhQRGbg8WcDHDC0gJ8PH/246mOwoIiJJ48kCnuX3MfWM43nrk30Egq3JjiMikhSeLOAAV5WeSEVdM2+t3Z/sKCIiSeHZAn7JmSWMGpLL04s26ShcRAYkzxZwX5rhwctPZ/2+Gv61fHOy44iIJJxnCzjAFWNPYMb4E/nlO5t45s9bkh1HRCShejwPPJUZY3ji+lICrZYfvbGejftr+cH0z5KX6ek/S0QkKp6vdH5fGr/86ng+c1weTy/axF83H+L+y07jmgkn4fd5+guGiEi3+kWFS/elcd+lp7Fw1vmUFGbxjwvXcNFPynn63U3sPdKQ7HgiInHh+SPwcGefPIg/3n0+i9Yf4Lkl23ny7Y08+fZGSocX8YWxJzD59OM47fh80tJMsqOKiByzflXAwWkXn3ZmCdPOLGHboTpe/3gvb36yjx+/sZ4fv7GeQTl+zh05mHNHFTN+eBFnDi0gy+9LdmwRkZj1uwIebuSQXL455VS+OeVUdh9uYMnmQ3ywtZKl2yp4c+0+wDkdcfTxeZx1UiFnDSvkzKEFnHpcHoNydY9mEUlt/bqAhzupKJvrJw7n+onDAdh9uIGPdx3m491H+Hh3Ne+uP8BLK3a1zT8kL4PPHJfHqcc7j9HH53PK4BxOKMzSj6MikhIGTAHv6KSibE4qyuaKsUMB59Zye480smFfDZsP1LLpgPP836v3UN0YaFvOGCjJz+KkQdmcWJRNsLqZnZnbKSnI4rj8TI4vyGJIXgaZ6WqWEZH4GrAFvCNjDCcWOUV5yhnHt4231nKwponNB2rZWVXP7sON7K5qYM/hBlbvPMzuqhZe37a20/qKcvwcl5fJ8QWZHJeX6RT3fKfID8rNYHBuBoNyMyjOySA7Q8VeRGKnAt4DYwzHF2RxfEFWxOmLysv5bNl5HKhu4mBto/Nc08SBGuf5YG0TKz6t4kB1E02ByH22ZPnTKM5xC3puBoNywp/9DHJfF2T5KchOpzDbT36WH5/OphEZ0FTAj1GaMZQUZFFSkAUUdjmftZaapgAHa5o4XN9MZV0LVXXNVNY3U1nnPELDOyvrqaxrbtd0E0leZjoFWekUZPudR5afwmynyFfua2Zr+jYKsv3kZfrIzUwnJyOdvMx0cjN97nO62vNFPEwFPEGMMc4RdJY/6mVagq0crm+hqt4p7tWNAaobWjjS0EJ1YwvVDYGw1y3sqqpn3V5nXG1TgFe2/K3H98jwpZHrFvhQUc/JOFrgQwX/aPFPJ88dDk3PyfCR5feR5U8j2+8jXTsFkYRQAU9hfl8ax+U77eexendROWWfu6CtmNc3B6ltClDX9ghS1xSgttkZrm9ypzcHqG4MsO9IozO9KUBdc5BgDDeQTk8zZPt9ZIYV9Sy/j2y/j/qaRuZ9+qE77ui0THd6+LjQTiGrbdrReULz+30GY9SUJAOTCng/5UszFOVkUJRz7OezW2tpCrQeLfxu0a91h+ubAzQGWmlqCdLQHKQxEKShuZXGQJBGd7ixpZWG5iANAcvOynqaAq1h8wa7/H2gJ2mGbgt+53FpYTsXH5npaWSkp5GZnsamfQHs+gNkhI1znn3OOF8amX73OT1NOw5JOhVw6ZExpq0YDs47tnUtXryYyZMv7jS+tdXSHGxf1BtbWmloCdLUErZTaAnS0BKkse0RPq61bXxDi7NjqaxrbjcutM4urVoe9d+S4etY6NPCir+vXcEP3xFkRlrG53yr6LhMRnoam6qCFO86jN+Xht/deTivDX532QxfmrqIGIBUwCUlpKUZstJ8CenWIPSNorElSHOglSb3seSDpZw1/myaA600B1tpanGfA8584fM2t3sOdrlMfV2g3fzOa+cbR3OwFRtty9TSv/Y4iy/N4PeZtuIfKvih1xk+027Yee3M7/elHd0ZpLs7h047DGd8aIez/kAAs/Ggu4xp934Z7d7bfV/tZPqcCrgMOOHfKMLtKvAx4eRBCcthraUl6HzzCN8RtN8xWFasXMmZnz2rbSfRErS0uMu0BN1xAUtzMOisLzTefQ5/D2e4lbrmYLvhFnfdzjhn/YFofvf4aFlMf3N6moncRBXePBX2TSQzwvjsDB85GT5yM9LJzvCRm+kj2x/6sd1HRUMrh+ubyclIJyO9f/+grgIukiTGGOcIOD0NuvmdumlnOpPPLElcMFew1bYV+PDCHir0HyxbzrjxE2gOWHcn0tpuemj+lqCzUwqtp+O3ldDOKvQNpbqhpf03lbCdWmMgGN23lj+/DTg7jJwM56ypHLfA52Skt98BZPjIzkh3n31tZ2KF5stxx4e+RaT7DOlpR1+Hvpkk4zcRFXARiciXZvB106y1v9BH2SnFCc0Uav6qb3Z+42hoDlLnvq5vClLfEmTlmrUMH3mqM6452DZvXbPz20pdk/PbyM7K+rblG5qDNB/jzdHT04xT0NOc5qj0tKPF3e9L484z+v7m6yrgIuIZ4c1fxV30GFpQtZHJF46Med0twaM7hvrmoLNDCNsJBFrDmpeCrTQHLQG3qak50NpuujOPDWuOasWfduRY//xOVMBFRHCuuyjMTqMwO/qL7WKxePHiPl9n/27hFxHpx3os4MaY4caYcmPM34wxa40x/+COLzbGvG2M2eQ+J+7nexERieoIPAA8YK0dA3wO+KYxZgwwG3jXWjsaeNcdFhGRBOmxgFtr91prP3Jf1wDrgJOA6cAcd7Y5wIw4ZRQRkQhiagM3xowAJgBLgRJr7V530j4g8SeqiogMYMZGeS2vMSYP+DPwL9baPxhjDltri8KmV1lrO7WDG2NmAjMBSkpKyhYsWNCroLW1teTlHWNHHHGgXLFJ1VyQutmUKzb9MdeUKVNWWGsndppgre3xAfiBt4D7w8ZtAIa6r4cCG3paT1lZme2t8vLyXi8bT8oVm1TNZW3qZlOu2PTHXMCHNkJNjeYsFAP8Blhnrf152KRXgVvd17cCr/Rq1yIiIr3SYxOKMeZC4C/Ax0DoWtDv4bSDvwicDOwAvmKtrexhXQfdeXtjCHCol8vGk3LFJlVzQepmU67Y9Mdcp1hrj+s4Muo28GQzxnxoI7UBJZlyxSZVc0HqZlOu2AykXLoSU0TEo1TARUQ8yksF/NlkB+iCcsUmVXNB6mZTrtgMmFyeaQMXEZH2vHQELiIiYVTARUQ8yhMF3BhzhTFmgzFmszEmqb0eGmO2G2M+NsasMsZ86I5LeNe6xpj/NMYcMMZ8EjYuYg7jeMrdfmuMMWcnONcjxpjd7jZbZYy5Mmzad91cG4wxl8cxV0zdIidqm3WTK6nbzBiTZYxZZoxZ7eb6gTt+pDFmqfv+LxhjMtzxme7wZnf6iATnes4Ysy1se413xyfss+++n88Ys9IY85o7HN/tFenyzFR6AD5gCzAKyABWA2OSmGc7MKTDuJ8Cs93Xs4GfJCDHxcDZwCc95QCuBN4ADE6XwEsTnOsR4DsR5h3j/ntmAiPdf2dfnHINBc52X+cDG933T+o26yZXUreZ+3fnua/9OBfufQ7n4r0b3PG/Bma5r+8Gfu2+vgF4IU7bq6tczwHXRZg/YZ999/3uB54HXnOH47q9vHAEfg6w2Vq71VrbDCzA6co2lSS8a11r7f8CHa987SrHdOB31vEBUGSMGZrAXF2ZDiyw1jZZa7cBm3H+veORK9ZukROyzbrJ1ZWEbDP37651B/3uwwJTgYXu+I7bK7QdFwLTjOn727R3k6srCfvsG2OGAV8E/sMdNsR5e3mhgJ8E7Awb3kX3H/B4s8D/GGNWGKenRUidrnW7ypEK2/Bb7lfY/wxrYkpKLhNdt8gJz9YhFyR5m7nNAauAA8DbOEf7h621gQjv3ZbLnX4EGJyIXNba0Pb6F3d7/cIYk9kxV4TMfe2XwD9ytMuRwcR5e3mhgKeaC621ZwNfwLk70cXhE63znSjp52amSg7X/wU+A4wH9gJPJiuIcbpF/i/g29ba6vBpydxmEXIlfZtZa4PW2vHAMJyj/DMSnSGSjrmMMWOB7+LkmwQUAw8lMpMx5kvAAWvtikS+rxcK+G5geNjwMHdcUlhrd7vPB4CXcT7Y+0Nfy9znA0mK11WOpG5Da+1+9z9dK/D/OPqVP6G5jDF+nCI5z1r7B3d00rdZpFypss3cLIeBcuA8nCaI9Ajv3ZbLnV4IVCQo1xVuU5S11jYBvyXx2+sC4GpjzHacZt6pwK+I8/byQgFfDox2f83NwGnwfzUZQYwxucaY/NBr4DLgE1Kna92ucrwK3OL+Iv854EhYs0HcdWhzvAZnm4Vy3eD+Ij8SGA0si1OGWLtFTsg26ypXsreZMeY4Y0yR+zobuBSnfb4cuM6dreP2Cm3H64BF7jeaRORaH7YTNjjtzOHbK+7/jtba71prh1lrR+DUqEXW2puI9/bqy19g4/XA+SV5I04b3P9JYo5ROGcArAbWhrLgtF29C2wC3gGKE5BlPs5X6xactrU7usqB8wv8v7nb72NgYoJzzXXfd437wR0aNv//cXNtAL4Qx1wX4jSPrAFWuY8rk73NusmV1G0GjANWuu//CfBw2P+BZTg/nr4EZLrjs9zhze70UQnOtcjdXp8Av+fomSoJ++yHZZzM0bNQ4rq9dCm9iIhHeaEJRUREIlABFxHxKBVwERGPUgEXEfEoFXAREY9SARcR8SgVcBERj/r/bXy/CEOMWYwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_and_accuracy(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75         5\n",
      "           1       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.90      0.80      0.82        13\n",
      "weighted avg       0.88      0.85      0.84        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
